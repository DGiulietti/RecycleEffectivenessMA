{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file\n",
    "df_for_regression = pd.read_csv('data/data_for_regression.csv', index_col='Municipality Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, BaggingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach:\n",
    "\n",
    "NEW ANALYTICS: \n",
    "* score of the TRAIN and test set\n",
    "* plot all the residuals between y_test and y_preds, not just looking at the averages in MAE and RMSE\n",
    "* Test all models with cv\n",
    "\n",
    "NEW MODELS:\n",
    "* Repeat ever model with outliers removed\n",
    "* Try a large test split\n",
    "* Emphasis on all models with bootstraping \n",
    "* Jeff kept suggest gradboost even though that one sucked\n",
    "* NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "\n",
    "X0 = df_for_regression.drop(columns=['%recycle/hh'])\n",
    "y0 = df_for_regression['%recycle/hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data w/o outliers\n",
    "df_for_regression1 = df_for_regression[df_for_regression['%recycle/hh'] < 0.5]\n",
    "X1 = df_for_regression1.drop(columns=['%recycle/hh'])\n",
    "y1 = df_for_regression1['%recycle/hh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First** just going to look at fast models, (no grad boost) and just the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  0   1   2   5   6   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  21  24  27  28  29  31  32  33  35  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  54  55  57  58  59  60  61  63  64  65  66\n",
      "  67  68  69  70  72  73  74  75  76  81  83  84  85  86  88  89  90  91\n",
      "  92  95  96  97  98  99 101 102 104 105 106 107 108 109 112 115 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n",
      " 137 138 140 141 142 143 144 145 146 147 149 150 151 152 153 154 155 156\n",
      " 157 159 160 161 162 164 166 167 168 169 170 171 172 173 174 175 176 179\n",
      " 181 183 184 186 188 189 190 191 194 195 196 197 199 200 201 202 203 205\n",
      " 206 207 208 210 211 213 214 215 216 217 218 220 223 224 225 226 227 228\n",
      " 229 231 234 235 236 237 238 239 240 241 242 243 245 246 247 248 249 250\n",
      " 251 252 253 254 255 257 258 259 261 262 263 264 265 266 267 268 269 270]\n",
      "TEST: [  3   4  13  22  23  25  26  30  34  52  53  56  62  71  77  78  79  80\n",
      "  82  87  93  94 100 103 110 111 113 114 116 139 148 158 163 165 177 178\n",
      " 180 182 185 187 192 193 198 204 209 212 219 221 222 230 232 233 244 256\n",
      " 260]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  2   3   4   6   7   8   9  10  11  13  14  15  16  18  19  20  21  22\n",
      "  23  24  25  26  28  29  30  31  32  34  35  36  37  38  40  41  43  44\n",
      "  46  47  48  49  51  52  53  54  56  58  59  60  61  62  63  64  66  67\n",
      "  68  70  71  73  74  75  77  78  79  80  81  82  83  85  86  87  89  91\n",
      "  93  94  95  97  98  99 100 101 102 103 104 105 106 107 108 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 130 131\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 147 148 150 152 154\n",
      " 155 156 158 159 160 161 162 163 164 165 166 167 169 170 171 173 174 175\n",
      " 177 178 179 180 181 182 183 184 185 187 188 190 191 192 193 194 195 196\n",
      " 198 199 200 203 204 205 207 209 210 211 212 213 214 216 217 219 220 221\n",
      " 222 223 224 229 230 231 232 233 235 237 238 239 242 243 244 245 246 247\n",
      " 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 264 266 267\n",
      " 270]\n",
      "TEST: [  0   1   5  12  17  27  33  39  42  45  50  55  57  65  69  72  76  84\n",
      "  88  90  92  96 109 129 132 146 149 151 153 157 168 172 176 186 189 197\n",
      " 201 202 206 208 215 218 225 226 227 228 234 236 240 241 263 265 268 269]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  12  13  15  16  17  18  19  20\n",
      "  21  22  23  25  26  27  28  30  31  33  34  36  37  38  39  42  43  45\n",
      "  46  47  48  50  51  52  53  54  55  56  57  58  59  61  62  63  64  65\n",
      "  66  69  71  72  73  74  75  76  77  78  79  80  81  82  84  85  86  87\n",
      "  88  90  91  92  93  94  95  96  98  99 100 102 103 104 105 107 108 109\n",
      " 110 111 112 113 114 115 116 118 119 120 122 123 124 125 126 129 132 133\n",
      " 134 135 136 137 138 139 142 143 144 146 147 148 149 151 152 153 155 156\n",
      " 157 158 160 161 163 165 166 167 168 170 172 173 174 176 177 178 180 182\n",
      " 183 184 185 186 187 188 189 191 192 193 194 196 197 198 199 200 201 202\n",
      " 203 204 206 207 208 209 210 212 213 215 216 217 218 219 220 221 222 223\n",
      " 224 225 226 227 228 229 230 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 248 249 250 251 253 254 256 257 259 260 261 263 265 267 268 269\n",
      " 270]\n",
      "TEST: [  8  10  14  24  29  32  35  40  41  44  49  60  67  68  70  83  89  97\n",
      " 101 106 117 121 127 128 130 131 140 141 145 150 154 159 162 164 169 171\n",
      " 175 179 181 190 195 205 211 214 231 245 246 247 252 255 258 262 264 266]\n",
      "CV_KF set:  3\n",
      "TRAIN: [  0   1   2   3   4   5   8   9  10  12  13  14  15  17  18  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  39  40  41\n",
      "  42  44  45  47  48  49  50  51  52  53  55  56  57  60  61  62  63  64\n",
      "  65  67  68  69  70  71  72  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  96  97 100 101 102 103 106 107 108 109\n",
      " 110 111 113 114 115 116 117 120 121 123 125 127 128 129 130 131 132 133\n",
      " 135 136 138 139 140 141 143 145 146 148 149 150 151 153 154 155 157 158\n",
      " 159 162 163 164 165 166 168 169 170 171 172 173 175 176 177 178 179 180\n",
      " 181 182 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200\n",
      " 201 202 204 205 206 208 209 211 212 214 215 217 218 219 220 221 222 223\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 240 241 242 244\n",
      " 245 246 247 248 249 251 252 255 256 258 259 260 262 263 264 265 266 268\n",
      " 269]\n",
      "TEST: [  6   7  11  16  19  38  43  46  54  58  59  66  73  74  75  95  98  99\n",
      " 104 105 112 118 119 122 124 126 134 137 142 144 147 152 156 160 161 167\n",
      " 174 183 184 203 207 210 213 216 224 239 243 250 253 254 257 261 267 270]\n",
      "CV_KF set:  4\n",
      "TRAIN: [  0   1   3   4   5   6   7   8  10  11  12  13  14  16  17  19  22  23\n",
      "  24  25  26  27  29  30  32  33  34  35  38  39  40  41  42  43  44  45\n",
      "  46  49  50  52  53  54  55  56  57  58  59  60  62  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  82  83  84  87  88  89  90\n",
      "  92  93  94  95  96  97  98  99 100 101 103 104 105 106 109 110 111 112\n",
      " 113 114 116 117 118 119 121 122 124 126 127 128 129 130 131 132 134 137\n",
      " 139 140 141 142 144 145 146 147 148 149 150 151 152 153 154 156 157 158\n",
      " 159 160 161 162 163 164 165 167 168 169 171 172 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 189 190 192 193 195 197 198 201 202 203\n",
      " 204 205 206 207 208 209 210 211 212 213 214 215 216 218 219 221 222 224\n",
      " 225 226 227 228 230 231 232 233 234 236 239 240 241 243 244 245 246 247\n",
      " 250 252 253 254 255 256 257 258 260 261 262 263 264 265 266 267 268 269\n",
      " 270]\n",
      "TEST: [  2   9  15  18  20  21  28  31  36  37  47  48  51  61  63  64  81  85\n",
      "  86  91 102 107 108 115 120 123 125 133 135 136 138 143 155 166 170 173\n",
      " 188 191 194 196 199 200 217 220 223 229 235 237 238 242 248 249 251 259]\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "cv_kf = KFold(n_splits=5, shuffle=True, random_state=8)\n",
    "\n",
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X0):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00262471, -0.01296429, -0.03149499, -0.03040279, -0.074853  ])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08579309, -0.42197651,  0.12508735, -0.01904092, -0.46782195])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02700948, -0.38914783,  0.13313634,  0.00084912, -0.44299328])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02981099,  0.02036987, -0.01632682, -0.04080895, -0.30929207])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03086535,  0.19833803,  0.11729076, -0.17294445,  0.21163409])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0169631 , -0.08887127,  0.04728323, -0.211642  ,  0.03888159])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.085793</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>0.029811</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>-0.016963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.012964</td>\n",
       "      <td>-0.421977</td>\n",
       "      <td>-0.389148</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>-0.088871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.031495</td>\n",
       "      <td>0.125087</td>\n",
       "      <td>0.133136</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.047283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold4</th>\n",
       "      <td>-0.030403</td>\n",
       "      <td>-0.019041</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>-0.040809</td>\n",
       "      <td>-0.172944</td>\n",
       "      <td>-0.211642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold5</th>\n",
       "      <td>-0.074853</td>\n",
       "      <td>-0.467822</td>\n",
       "      <td>-0.442993</td>\n",
       "      <td>-0.309292</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.038882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.030468</td>\n",
       "      <td>-0.173909</td>\n",
       "      <td>-0.145033</td>\n",
       "      <td>-0.063249</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>-0.046262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging\n",
       "Fold1   -0.002625 -0.085793 -0.027009  0.029811  0.030865   -0.016963\n",
       "Fold2   -0.012964 -0.421977 -0.389148  0.020370  0.198338   -0.088871\n",
       "Fold3   -0.031495  0.125087  0.133136 -0.016327  0.117291    0.047283\n",
       "Fold4   -0.030403 -0.019041  0.000849 -0.040809 -0.172944   -0.211642\n",
       "Fold5   -0.074853 -0.467822 -0.442993 -0.309292  0.211634    0.038882\n",
       "CV_mean -0.030468 -0.173909 -0.145033 -0.063249  0.077037   -0.046262"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3','Fold4','Fold5','CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, looks like Random Forest did best. However, if I used the train test split in fold 3, I could potentially get away with using linear regressions. **Next**, let's look at the same models but on the data with no outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  0   1   2   5   6   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  21  24  27  28  29  31  32  33  35  36  37  38  39  40  41  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  57  58  59  60  61  63  64  65  66\n",
      "  67  68  70  71  72  73  74  75  76  79  81  83  85  86  88  89  90  91\n",
      "  93  95  97  98  99 100 101 102 104 105 106 107 108 112 113 114 115 118\n",
      " 119 120 121 122 123 124 125 126 127 129 130 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 146 147 148 150 151 152 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 170 171 173 174 177 178 179 180 181 182\n",
      " 183 184 185 188 190 191 192 193 194 195 196 199 200 201 202 203 204 205\n",
      " 206 208 209 211 212 213 214 215 216 217 219 220 221 222 223 224 225 226\n",
      " 227 228 229 230 231 232 233 234 235 236 237 240 241 242 243 244 245 248\n",
      " 249 250 251 252 254 255 256 257 258 260 262 263 264 265 266]\n",
      "TEST: [  3   4  13  22  23  25  26  30  34  42  55  56  62  69  77  78  80  82\n",
      "  84  87  92  94  96 103 109 110 111 116 117 128 131 132 145 149 153 169\n",
      " 172 175 176 186 187 189 197 198 207 210 218 238 239 246 247 253 259 261]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  2   3   4   6   7   8   9  10  11  13  14  15  16  18  19  20  21  22\n",
      "  23  24  25  26  28  29  30  31  32  34  35  36  37  38  40  41  42  43\n",
      "  44  46  47  48  49  50  51  52  53  54  55  56  58  59  60  61  62  63\n",
      "  64  66  67  68  69  70  71  73  74  75  77  78  80  81  82  83  84  85\n",
      "  86  87  91  92  93  94  95  96  97  98  99 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 115 116 117 118 119 120 122 123 124 125 126 127 128\n",
      " 130 131 132 133 134 135 136 137 138 142 143 144 145 147 148 149 150 152\n",
      " 153 154 155 156 160 162 163 165 166 167 168 169 170 172 173 174 175 176\n",
      " 179 180 181 183 184 185 186 187 188 189 190 191 192 194 196 197 198 199\n",
      " 200 202 203 205 207 208 210 211 215 216 217 218 219 220 221 223 227 228\n",
      " 229 230 231 232 233 234 235 236 237 238 239 240 241 243 244 245 246 247\n",
      " 249 250 251 252 253 254 255 257 258 259 260 261 262 263 266]\n",
      "TEST: [  0   1   5  12  17  27  33  39  45  57  65  72  76  79  88  89  90 100\n",
      " 113 114 121 129 139 140 141 146 151 157 158 159 161 164 171 177 178 182\n",
      " 193 195 201 204 206 209 212 213 214 222 224 225 226 242 248 256 264 265]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  30  31  33  34  36  37  38  39  42  43\n",
      "  45  46  47  48  51  53  54  55  56  57  58  59  61  62  63  64  65  66\n",
      "  69  71  72  73  75  76  77  78  79  80  81  82  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  98 100 102 103 104 105 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 128 129 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 145 146 147 149 151 152\n",
      " 153 154 155 156 157 158 159 160 161 164 166 167 169 170 171 172 173 174\n",
      " 175 176 177 178 181 182 183 184 185 186 187 188 189 191 192 193 194 195\n",
      " 196 197 198 199 200 201 202 204 206 207 209 210 212 213 214 215 218 220\n",
      " 222 224 225 226 227 228 229 232 233 235 237 238 239 240 241 242 243 244\n",
      " 245 246 247 248 249 251 253 254 256 257 259 261 263 264 265 266]\n",
      "TEST: [  8  10  24  29  32  35  40  41  44  49  50  52  60  67  68  70  74  83\n",
      "  97  99 101 106 127 130 144 148 150 162 163 165 168 179 180 190 203 205\n",
      " 208 211 216 217 219 221 223 230 231 234 236 250 252 255 258 260 262]\n",
      "CV_KF set:  3\n",
      "TRAIN: [  0   1   2   3   4   5   8   9  10  12  13  14  15  17  18  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  39  40  41  42\n",
      "  44  45  47  48  49  50  51  52  53  55  56  57  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  74  76  77  78  79  80  81  82  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  96  97  99 100 101 102 103 105\n",
      " 106 107 108 109 110 111 113 114 115 116 117 121 125 127 128 129 130 131\n",
      " 132 133 135 136 138 139 140 141 143 144 145 146 148 149 150 151 153 154\n",
      " 155 157 158 159 161 162 163 164 165 166 168 169 170 171 172 173 175 176\n",
      " 177 178 179 180 181 182 184 186 187 189 190 191 193 195 196 197 198 199\n",
      " 200 201 203 204 205 206 207 208 209 210 211 212 213 214 216 217 218 219\n",
      " 220 221 222 223 224 225 226 227 229 230 231 233 234 236 238 239 242 246\n",
      " 247 248 250 251 252 253 254 255 256 258 259 260 261 262 264 265]\n",
      "TEST: [  6   7  11  16  19  37  38  43  46  54  58  73  75  95  98 104 112 118\n",
      " 119 120 122 123 124 126 134 137 142 147 152 156 160 167 174 183 185 188\n",
      " 192 194 202 215 228 232 235 237 240 241 243 244 245 249 257 263 266]\n",
      "CV_KF set:  4\n",
      "TRAIN: [  0   1   3   4   5   6   7   8  10  11  12  13  16  17  19  22  23  24\n",
      "  25  26  27  29  30  32  33  34  35  37  38  39  40  41  42  43  44  45\n",
      "  46  49  50  52  54  55  56  57  58  60  62  65  67  68  69  70  72  73\n",
      "  74  75  76  77  78  79  80  82  83  84  87  88  89  90  92  94  95  96\n",
      "  97  98  99 100 101 103 104 106 109 110 111 112 113 114 116 117 118 119\n",
      " 120 121 122 123 124 126 127 128 129 130 131 132 134 137 139 140 141 142\n",
      " 144 145 146 147 148 149 150 151 152 153 156 157 158 159 160 161 162 163\n",
      " 164 165 167 168 169 171 172 174 175 176 177 178 179 180 182 183 185 186\n",
      " 187 188 189 190 192 193 194 195 197 198 201 202 203 204 205 206 207 208\n",
      " 209 210 211 212 213 214 215 216 217 218 219 221 222 223 224 225 226 228\n",
      " 230 231 232 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248\n",
      " 249 250 252 253 255 256 257 258 259 260 261 262 263 264 265 266]\n",
      "TEST: [  2   9  14  15  18  20  21  28  31  36  47  48  51  53  59  61  63  64\n",
      "  66  71  81  85  86  91  93 102 105 107 108 115 125 133 135 136 138 143\n",
      " 154 155 166 170 173 181 184 191 196 199 200 220 227 229 233 251 254]\n"
     ]
    }
   ],
   "source": [
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X1):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05338701, -0.03622173, -0.07998282, -0.00190992, -0.00161515])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11681536, -0.02302504, -0.60246096,  0.14584508,  0.16238194])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2425074 ,  0.00398809, -0.63989767,  0.19700119,  0.18435423])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03725743, -0.00609516, -0.42253981,  0.02625488,  0.00080746])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2165107 , 0.14495103, 0.09073038, 0.30272136, 0.23477095])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32835449, 0.08558503, 0.06803691, 0.34382283, 0.18444288])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X1, y1, cv=cv_kf)\n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "      <th>X1_dummy</th>\n",
       "      <th>X1_lr</th>\n",
       "      <th>X1_ridge</th>\n",
       "      <th>X1_lasso</th>\n",
       "      <th>X1_RF</th>\n",
       "      <th>X1_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.085793</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>0.029811</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>-0.016963</td>\n",
       "      <td>-0.053387</td>\n",
       "      <td>0.116815</td>\n",
       "      <td>0.242507</td>\n",
       "      <td>-0.037257</td>\n",
       "      <td>0.216511</td>\n",
       "      <td>0.328354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.012964</td>\n",
       "      <td>-0.421977</td>\n",
       "      <td>-0.389148</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>-0.088871</td>\n",
       "      <td>-0.036222</td>\n",
       "      <td>-0.023025</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>0.144951</td>\n",
       "      <td>0.085585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.031495</td>\n",
       "      <td>0.125087</td>\n",
       "      <td>0.133136</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.047283</td>\n",
       "      <td>-0.079983</td>\n",
       "      <td>-0.602461</td>\n",
       "      <td>-0.639898</td>\n",
       "      <td>-0.422540</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold4</th>\n",
       "      <td>-0.030403</td>\n",
       "      <td>-0.019041</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>-0.040809</td>\n",
       "      <td>-0.172944</td>\n",
       "      <td>-0.211642</td>\n",
       "      <td>-0.001910</td>\n",
       "      <td>0.145845</td>\n",
       "      <td>0.197001</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.302721</td>\n",
       "      <td>0.343823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold5</th>\n",
       "      <td>-0.074853</td>\n",
       "      <td>-0.467822</td>\n",
       "      <td>-0.442993</td>\n",
       "      <td>-0.309292</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>-0.001615</td>\n",
       "      <td>0.162382</td>\n",
       "      <td>0.184354</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.234771</td>\n",
       "      <td>0.184443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.030468</td>\n",
       "      <td>-0.173909</td>\n",
       "      <td>-0.145033</td>\n",
       "      <td>-0.063249</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>-0.046262</td>\n",
       "      <td>-0.034623</td>\n",
       "      <td>-0.040089</td>\n",
       "      <td>-0.002409</td>\n",
       "      <td>-0.087766</td>\n",
       "      <td>0.197937</td>\n",
       "      <td>0.202048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging  \\\n",
       "Fold1   -0.002625 -0.085793 -0.027009  0.029811  0.030865   -0.016963   \n",
       "Fold2   -0.012964 -0.421977 -0.389148  0.020370  0.198338   -0.088871   \n",
       "Fold3   -0.031495  0.125087  0.133136 -0.016327  0.117291    0.047283   \n",
       "Fold4   -0.030403 -0.019041  0.000849 -0.040809 -0.172944   -0.211642   \n",
       "Fold5   -0.074853 -0.467822 -0.442993 -0.309292  0.211634    0.038882   \n",
       "CV_mean -0.030468 -0.173909 -0.145033 -0.063249  0.077037   -0.046262   \n",
       "\n",
       "         X1_dummy     X1_lr  X1_ridge  X1_lasso     X1_RF  X1_bagging  \n",
       "Fold1   -0.053387  0.116815  0.242507 -0.037257  0.216511    0.328354  \n",
       "Fold2   -0.036222 -0.023025  0.003988 -0.006095  0.144951    0.085585  \n",
       "Fold3   -0.079983 -0.602461 -0.639898 -0.422540  0.090730    0.068037  \n",
       "Fold4   -0.001910  0.145845  0.197001  0.026255  0.302721    0.343823  \n",
       "Fold5   -0.001615  0.162382  0.184354  0.000807  0.234771    0.184443  \n",
       "CV_mean -0.034623 -0.040089 -0.002409 -0.087766  0.197937    0.202048  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3','Fold4','Fold5','CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, everything does seem to improve when removing the outliers. Looks like the non-linear regression based models still faired best but the set from fold 4 performed well across all models. The outliers, however, are in the positive direction: higher recyclers. So if I do go with a model with the outliers removed, I still need to go back and see what is unique about those outliers; I shouldn't just throw them out and forget about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:Train Ratio\n",
    "\n",
    "I can kinda of informally see how the dataset does with a higher test ratio by changing the n_split during the cross validation. Above, I used the default of 5, however, this only leaves us with 54 test points. We may increase our odds of success by increasing this quantity so I'll change the n_split to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  2   6   7   8   9  10  11  12  14  15  16  18  19  20  21  24  27  28\n",
      "  29  31  32  35  36  37  38  40  41  43  44  46  47  48  49  50  51  54\n",
      "  58  59  60  61  63  64  66  67  68  70  73  74  75  76  81  83  85  86\n",
      "  89  90  91  92  95  97  98  99 101 102 104 105 106 107 108 112 115 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 130 131 132 133 134 135 136\n",
      " 137 138 140 141 142 143 144 145 147 150 152 153 154 155 156 159 160 161\n",
      " 162 164 166 167 168 169 170 171 173 174 175 176 179 181 183 184 188 190\n",
      " 191 194 195 196 199 200 201 203 205 206 207 210 211 213 214 216 217 220\n",
      " 223 224 225 226 228 229 231 234 235 236 237 238 239 242 243 245 246 247\n",
      " 248 249 250 251 252 253 254 255 257 258 259 261 262 264 266 267 269 270]\n",
      "TEST: [  0   1   3   4   5  13  17  22  23  25  26  30  33  34  39  42  45  52\n",
      "  53  55  56  57  62  65  69  71  72  77  78  79  80  82  84  87  88  93\n",
      "  94  96 100 103 109 110 111 113 114 116 129 139 146 148 149 151 157 158\n",
      " 163 165 172 177 178 180 182 185 186 187 189 192 193 197 198 202 204 208\n",
      " 209 212 215 218 219 221 222 227 230 232 233 240 241 244 256 260 263 265\n",
      " 268]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  13  15  16  17  18  19  20  21\n",
      "  22  23  25  26  28  30  31  33  34  36  37  38  39  42  45  46  47  48\n",
      "  51  52  53  54  55  56  57  59  61  62  63  64  65  66  69  71  72  73\n",
      "  75  77  78  79  80  81  82  84  85  86  87  88  91  93  94  95  96  98\n",
      " 100 102 103 105 107 108 109 110 111 112 113 114 115 116 118 120 122 123\n",
      " 125 126 129 133 134 135 136 137 138 139 143 146 147 148 149 151 152 155\n",
      " 156 157 158 160 163 165 166 167 170 172 173 174 177 178 180 182 183 185\n",
      " 186 187 188 189 191 192 193 194 196 197 198 199 200 202 203 204 208 209\n",
      " 210 212 215 216 217 218 219 220 221 222 223 224 227 229 230 232 233 235\n",
      " 237 238 240 241 242 243 244 248 249 251 256 257 259 260 263 265 267 268\n",
      " 270]\n",
      "TEST: [  8  10  12  14  24  27  29  32  35  40  41  43  44  49  50  58  60  67\n",
      "  68  70  74  76  83  89  90  92  97  99 101 104 106 117 119 121 124 127\n",
      " 128 130 131 132 140 141 142 144 145 150 153 154 159 161 162 164 168 169\n",
      " 171 175 176 179 181 184 190 195 201 205 206 207 211 213 214 225 226 228\n",
      " 231 234 236 239 245 246 247 250 252 253 254 255 258 261 262 264 266 269]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   3   4   5   8  10  12  13  14  17  22  23  24  25  26  27  29\n",
      "  30  32  33  34  35  39  40  41  42  43  44  45  49  50  52  53  55  56\n",
      "  57  58  60  62  65  67  68  69  70  71  72  74  76  77  78  79  80  82\n",
      "  83  84  87  88  89  90  92  93  94  96  97  99 100 101 103 104 106 109\n",
      " 110 111 113 114 116 117 119 121 124 127 128 129 130 131 132 139 140 141\n",
      " 142 144 145 146 148 149 150 151 153 154 157 158 159 161 162 163 164 165\n",
      " 168 169 171 172 175 176 177 178 179 180 181 182 184 185 186 187 189 190\n",
      " 192 193 195 197 198 201 202 204 205 206 207 208 209 211 212 213 214 215\n",
      " 218 219 221 222 225 226 227 228 230 231 232 233 234 236 239 240 241 244\n",
      " 245 246 247 250 252 253 254 255 256 258 260 261 262 263 264 265 266 268\n",
      " 269]\n",
      "TEST: [  2   6   7   9  11  15  16  18  19  20  21  28  31  36  37  38  46  47\n",
      "  48  51  54  59  61  63  64  66  73  75  81  85  86  91  95  98 102 105\n",
      " 107 108 112 115 118 120 122 123 125 126 133 134 135 136 137 138 143 147\n",
      " 152 155 156 160 166 167 170 173 174 183 188 191 194 196 199 200 203 210\n",
      " 216 217 220 223 224 229 235 237 238 242 243 248 249 251 257 259 267 270]\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "cv_kf = KFold(n_splits=3, shuffle=True, random_state=8)\n",
    "\n",
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X0):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01458113, -0.01553683, -0.09007735])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08721139,  0.15905641, -0.75862946])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01603247,  0.16700945, -0.74216146])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01745458,  0.00209897, -0.74093297])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11768537, 0.2370164 , 0.11437933])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04694505,  0.11108638,  0.03541457])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  2   6   7   8   9  10  11  12  14  15  16  18  19  20  21  24  27  28\n",
      "  29  31  32  35  36  37  38  40  41  43  44  46  47  48  49  50  51  52\n",
      "  53  54  58  59  60  61  63  64  66  67  68  70  71  73  74  75  76  81\n",
      "  83  85  86  89  90  91  93  95  97  98  99 101 102 104 105 106 107 108\n",
      " 112 114 115 118 119 120 122 123 124 125 126 127 129 130 133 134 135 136\n",
      " 137 138 140 142 143 144 147 148 150 152 154 155 156 158 159 160 162 163\n",
      " 165 166 167 168 170 173 174 177 178 179 180 181 182 183 184 185 188 190\n",
      " 191 192 194 195 196 199 200 202 203 205 208 209 211 213 215 216 217 219\n",
      " 220 221 223 225 227 228 229 230 231 232 233 234 235 236 237 240 241 243\n",
      " 244 245 249 250 251 252 254 255 257 258 260 262 263 264 265 266]\n",
      "TEST: [  0   1   3   4   5  13  17  22  23  25  26  30  33  34  39  42  45  55\n",
      "  56  57  62  65  69  72  77  78  79  80  82  84  87  88  92  94  96 100\n",
      " 103 109 110 111 113 116 117 121 128 131 132 139 141 145 146 149 151 153\n",
      " 157 161 164 169 171 172 175 176 186 187 189 193 197 198 201 204 206 207\n",
      " 210 212 214 218 222 224 226 238 239 242 246 247 248 253 256 259 261]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  13  14  15  16  17  18  19  20  21\n",
      "  22  23  25  26  28  30  31  33  34  36  37  38  39  42  45  46  47  48\n",
      "  51  53  54  55  56  57  59  61  62  63  64  65  66  69  71  72  73  77\n",
      "  78  79  80  81  82  84  85  86  87  88  91  92  93  94  95  96  98 100\n",
      " 102 103 105 107 108 109 110 111 112 113 115 116 117 118 120 121 122 123\n",
      " 125 126 128 131 132 133 134 135 136 137 138 139 141 143 145 146 149 151\n",
      " 152 153 154 155 157 160 161 164 166 167 169 170 171 172 173 175 176 181\n",
      " 183 184 186 187 188 189 191 192 193 194 196 197 198 199 200 201 204 206\n",
      " 207 210 212 214 215 218 220 222 224 226 227 228 229 232 233 235 238 239\n",
      " 240 242 243 244 245 246 247 248 249 251 253 254 256 259 261 263]\n",
      "TEST: [  8  10  11  12  24  27  29  32  35  40  41  43  44  49  50  52  58  60\n",
      "  67  68  70  74  75  76  83  89  90  97  99 101 104 106 114 119 124 127\n",
      " 129 130 140 142 144 147 148 150 156 158 159 162 163 165 168 174 177 178\n",
      " 179 180 182 185 190 195 202 203 205 208 209 211 213 216 217 219 221 223\n",
      " 225 230 231 234 236 237 241 250 252 255 257 258 260 262 264 265 266]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   3   4   5   8  10  11  12  13  17  22  23  24  25  26  27  29\n",
      "  30  32  33  34  35  39  40  41  42  43  44  45  49  50  52  55  56  57\n",
      "  58  60  62  65  67  68  69  70  72  74  75  76  77  78  79  80  82  83\n",
      "  84  87  88  89  90  92  94  96  97  99 100 101 103 104 106 109 110 111\n",
      " 113 114 116 117 119 121 124 127 128 129 130 131 132 139 140 141 142 144\n",
      " 145 146 147 148 149 150 151 153 156 157 158 159 161 162 163 164 165 168\n",
      " 169 171 172 174 175 176 177 178 179 180 182 185 186 187 189 190 193 195\n",
      " 197 198 201 202 203 204 205 206 207 208 209 210 211 212 213 214 216 217\n",
      " 218 219 221 222 223 224 225 226 230 231 234 236 237 238 239 241 242 246\n",
      " 247 248 250 252 253 255 256 257 258 259 260 261 262 264 265 266]\n",
      "TEST: [  2   6   7   9  14  15  16  18  19  20  21  28  31  36  37  38  46  47\n",
      "  48  51  53  54  59  61  63  64  66  71  73  81  85  86  91  93  95  98\n",
      " 102 105 107 108 112 115 118 120 122 123 125 126 133 134 135 136 137 138\n",
      " 143 152 154 155 160 166 167 170 173 181 183 184 188 191 192 194 196 199\n",
      " 200 215 220 227 228 229 232 233 235 240 243 244 245 249 251 254 263]\n"
     ]
    }
   ],
   "source": [
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X1):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08957878, -0.1209515 , -0.01201351])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01517724, -0.38834619,  0.10209835])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08972173, -0.38117819,  0.16464953])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06988468, -0.23457381,  0.00298756])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19785585, 0.00528953, 0.20736793])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16058833, -0.06794259,  0.13272154])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X1, y1, cv=cv_kf)\n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "      <th>X1_dummy</th>\n",
       "      <th>X1_lr</th>\n",
       "      <th>X1_ridge</th>\n",
       "      <th>X1_lasso</th>\n",
       "      <th>X1_RF</th>\n",
       "      <th>X1_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.014581</td>\n",
       "      <td>-0.087211</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>0.117685</td>\n",
       "      <td>-0.046945</td>\n",
       "      <td>-0.089579</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.089722</td>\n",
       "      <td>-0.069885</td>\n",
       "      <td>0.197856</td>\n",
       "      <td>0.160588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.015537</td>\n",
       "      <td>0.159056</td>\n",
       "      <td>0.167009</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.237016</td>\n",
       "      <td>0.111086</td>\n",
       "      <td>-0.120952</td>\n",
       "      <td>-0.388346</td>\n",
       "      <td>-0.381178</td>\n",
       "      <td>-0.234574</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>-0.067943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.090077</td>\n",
       "      <td>-0.758629</td>\n",
       "      <td>-0.742161</td>\n",
       "      <td>-0.740933</td>\n",
       "      <td>0.114379</td>\n",
       "      <td>0.035415</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>0.102098</td>\n",
       "      <td>0.164650</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.207368</td>\n",
       "      <td>0.132722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.040065</td>\n",
       "      <td>-0.228928</td>\n",
       "      <td>-0.197061</td>\n",
       "      <td>-0.240460</td>\n",
       "      <td>0.156360</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>-0.074181</td>\n",
       "      <td>-0.090357</td>\n",
       "      <td>-0.042269</td>\n",
       "      <td>-0.100490</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>0.075122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging  \\\n",
       "Fold1   -0.014581 -0.087211 -0.016032  0.017455  0.117685   -0.046945   \n",
       "Fold2   -0.015537  0.159056  0.167009  0.002099  0.237016    0.111086   \n",
       "Fold3   -0.090077 -0.758629 -0.742161 -0.740933  0.114379    0.035415   \n",
       "CV_mean -0.040065 -0.228928 -0.197061 -0.240460  0.156360    0.033185   \n",
       "\n",
       "         X1_dummy     X1_lr  X1_ridge  X1_lasso     X1_RF  X1_bagging  \n",
       "Fold1   -0.089579  0.015177  0.089722 -0.069885  0.197856    0.160588  \n",
       "Fold2   -0.120952 -0.388346 -0.381178 -0.234574  0.005290   -0.067943  \n",
       "Fold3   -0.012014  0.102098  0.164650  0.002988  0.207368    0.132722  \n",
       "CV_mean -0.074181 -0.090357 -0.042269 -0.100490  0.136838    0.075122  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3', 'CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the averages definitely seem better. It does mean I've only tested 3 configurations rather than 5 but RF consistently is positive and bagging does fairly well. It also seems like the difference between the data with the outliers and without the outliers has fewer differences in fit. It seems like increasing the test_split will be helpful.\n",
    "\n",
    "---\n",
    "\n",
    "I think moving forward, I'm going to do the normal train_test_split method, but with a test_split = 0.34 and I will only look at models based on decision trees and linear regression-based models are not working well with this data set. So the models I'll look at are: RandomForests, Bagging, and Gradient Boosting (adding this one in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = {}\n",
    "\n",
    "def cv_test(X, Y, testsize, model, name):\n",
    "    cv = cross_val_score(model, X, y) \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testsize ,random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "    fit_results[name] = (score, rmse)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = {}\n",
    "\n",
    "def fit_model(model, name):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "    fit_results[name] = (score, rmse)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = DummyRegressor()\n",
    "fit_model(model0, 'dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21859654846224486"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LinearRegression(n_jobs=-1)\n",
    "fit_model(model1, 'plain_linreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13740517005245223"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RandomForestRegressor(n_jobs=-1, random_state=123)\n",
    "fit_model(model2, 'RFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25126471106226456"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = HistGradientBoostingRegressor(max_iter=10_000, random_state=123)\n",
    "fit_model(model3, 'GradBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15359534479323111"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = BaggingRegressor(n_jobs=-1, n_estimators=100, random_state=123)\n",
    "fit_model(model4, 'bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25126471106226456"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = make_pipeline(StandardScaler(), HistGradientBoostingRegressor(max_iter=10_000, random_state=123))\n",
    "fit_model(model5, 'GB_w_scaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22099629888522287"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = make_pipeline(StandardScaler(),Ridge())\n",
    "fit_model(model6, 'plain_ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.005464464679645564"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = make_pipeline(StandardScaler(),Lasso())\n",
    "fit_model(model7, 'lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
