{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file\n",
    "df_for_regression = pd.read_csv('data/data_for_regression.csv', index_col='Municipality Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, BaggingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach:\n",
    "\n",
    "NEW ANALYTICS: \n",
    "* score of the TRAIN and test set\n",
    "* plot all the residuals between y_test and y_preds, not just looking at the averages in MAE and RMSE\n",
    "* Test all models with cv\n",
    "\n",
    "NEW MODELS:\n",
    "* Repeat ever model with outliers removed\n",
    "* Try a large test split\n",
    "* Emphasis on all models with bootstraping \n",
    "* Jeff kept suggest gradboost even though that one sucked\n",
    "* NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "\n",
    "X0 = df_for_regression.drop(columns=['%recycle/hh'])\n",
    "y0 = df_for_regression['%recycle/hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data w/o outliers\n",
    "df_for_regression1 = df_for_regression[df_for_regression['%recycle/hh'] < 0.5]\n",
    "X1 = df_for_regression1.drop(columns=['%recycle/hh'])\n",
    "y1 = df_for_regression1['%recycle/hh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First** just going to look at fast models, (no grad boost) and just the raw data. I found [this nifty way of seeing the test train splits in the KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  0   1   2   5   6   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  21  24  27  28  29  31  32  33  35  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  54  55  57  58  59  60  61  63  64  65  66\n",
      "  67  68  69  70  72  73  74  75  76  81  83  84  85  86  88  89  90  91\n",
      "  92  95  96  97  98  99 101 102 104 105 106 107 108 109 112 115 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n",
      " 137 138 140 141 142 143 144 145 146 147 149 150 151 152 153 154 155 156\n",
      " 157 159 160 161 162 164 166 167 168 169 170 171 172 173 174 175 176 179\n",
      " 181 183 184 186 188 189 190 191 194 195 196 197 199 200 201 202 203 205\n",
      " 206 207 208 210 211 213 214 215 216 217 218 220 223 224 225 226 227 228\n",
      " 229 231 234 235 236 237 238 239 240 241 242 243 245 246 247 248 249 250\n",
      " 251 252 253 254 255 257 258 259 261 262 263 264 265 266 267 268 269 270]\n",
      "TEST: [  3   4  13  22  23  25  26  30  34  52  53  56  62  71  77  78  79  80\n",
      "  82  87  93  94 100 103 110 111 113 114 116 139 148 158 163 165 177 178\n",
      " 180 182 185 187 192 193 198 204 209 212 219 221 222 230 232 233 244 256\n",
      " 260]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  2   3   4   6   7   8   9  10  11  13  14  15  16  18  19  20  21  22\n",
      "  23  24  25  26  28  29  30  31  32  34  35  36  37  38  40  41  43  44\n",
      "  46  47  48  49  51  52  53  54  56  58  59  60  61  62  63  64  66  67\n",
      "  68  70  71  73  74  75  77  78  79  80  81  82  83  85  86  87  89  91\n",
      "  93  94  95  97  98  99 100 101 102 103 104 105 106 107 108 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 130 131\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 147 148 150 152 154\n",
      " 155 156 158 159 160 161 162 163 164 165 166 167 169 170 171 173 174 175\n",
      " 177 178 179 180 181 182 183 184 185 187 188 190 191 192 193 194 195 196\n",
      " 198 199 200 203 204 205 207 209 210 211 212 213 214 216 217 219 220 221\n",
      " 222 223 224 229 230 231 232 233 235 237 238 239 242 243 244 245 246 247\n",
      " 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 264 266 267\n",
      " 270]\n",
      "TEST: [  0   1   5  12  17  27  33  39  42  45  50  55  57  65  69  72  76  84\n",
      "  88  90  92  96 109 129 132 146 149 151 153 157 168 172 176 186 189 197\n",
      " 201 202 206 208 215 218 225 226 227 228 234 236 240 241 263 265 268 269]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  12  13  15  16  17  18  19  20\n",
      "  21  22  23  25  26  27  28  30  31  33  34  36  37  38  39  42  43  45\n",
      "  46  47  48  50  51  52  53  54  55  56  57  58  59  61  62  63  64  65\n",
      "  66  69  71  72  73  74  75  76  77  78  79  80  81  82  84  85  86  87\n",
      "  88  90  91  92  93  94  95  96  98  99 100 102 103 104 105 107 108 109\n",
      " 110 111 112 113 114 115 116 118 119 120 122 123 124 125 126 129 132 133\n",
      " 134 135 136 137 138 139 142 143 144 146 147 148 149 151 152 153 155 156\n",
      " 157 158 160 161 163 165 166 167 168 170 172 173 174 176 177 178 180 182\n",
      " 183 184 185 186 187 188 189 191 192 193 194 196 197 198 199 200 201 202\n",
      " 203 204 206 207 208 209 210 212 213 215 216 217 218 219 220 221 222 223\n",
      " 224 225 226 227 228 229 230 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 248 249 250 251 253 254 256 257 259 260 261 263 265 267 268 269\n",
      " 270]\n",
      "TEST: [  8  10  14  24  29  32  35  40  41  44  49  60  67  68  70  83  89  97\n",
      " 101 106 117 121 127 128 130 131 140 141 145 150 154 159 162 164 169 171\n",
      " 175 179 181 190 195 205 211 214 231 245 246 247 252 255 258 262 264 266]\n",
      "CV_KF set:  3\n",
      "TRAIN: [  0   1   2   3   4   5   8   9  10  12  13  14  15  17  18  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  39  40  41\n",
      "  42  44  45  47  48  49  50  51  52  53  55  56  57  60  61  62  63  64\n",
      "  65  67  68  69  70  71  72  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  96  97 100 101 102 103 106 107 108 109\n",
      " 110 111 113 114 115 116 117 120 121 123 125 127 128 129 130 131 132 133\n",
      " 135 136 138 139 140 141 143 145 146 148 149 150 151 153 154 155 157 158\n",
      " 159 162 163 164 165 166 168 169 170 171 172 173 175 176 177 178 179 180\n",
      " 181 182 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200\n",
      " 201 202 204 205 206 208 209 211 212 214 215 217 218 219 220 221 222 223\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 240 241 242 244\n",
      " 245 246 247 248 249 251 252 255 256 258 259 260 262 263 264 265 266 268\n",
      " 269]\n",
      "TEST: [  6   7  11  16  19  38  43  46  54  58  59  66  73  74  75  95  98  99\n",
      " 104 105 112 118 119 122 124 126 134 137 142 144 147 152 156 160 161 167\n",
      " 174 183 184 203 207 210 213 216 224 239 243 250 253 254 257 261 267 270]\n",
      "CV_KF set:  4\n",
      "TRAIN: [  0   1   3   4   5   6   7   8  10  11  12  13  14  16  17  19  22  23\n",
      "  24  25  26  27  29  30  32  33  34  35  38  39  40  41  42  43  44  45\n",
      "  46  49  50  52  53  54  55  56  57  58  59  60  62  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  82  83  84  87  88  89  90\n",
      "  92  93  94  95  96  97  98  99 100 101 103 104 105 106 109 110 111 112\n",
      " 113 114 116 117 118 119 121 122 124 126 127 128 129 130 131 132 134 137\n",
      " 139 140 141 142 144 145 146 147 148 149 150 151 152 153 154 156 157 158\n",
      " 159 160 161 162 163 164 165 167 168 169 171 172 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 189 190 192 193 195 197 198 201 202 203\n",
      " 204 205 206 207 208 209 210 211 212 213 214 215 216 218 219 221 222 224\n",
      " 225 226 227 228 230 231 232 233 234 236 239 240 241 243 244 245 246 247\n",
      " 250 252 253 254 255 256 257 258 260 261 262 263 264 265 266 267 268 269\n",
      " 270]\n",
      "TEST: [  2   9  15  18  20  21  28  31  36  37  47  48  51  61  63  64  81  85\n",
      "  86  91 102 107 108 115 120 123 125 133 135 136 138 143 155 166 170 173\n",
      " 188 191 194 196 199 200 217 220 223 229 235 237 238 242 248 249 251 259]\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "cv_kf = KFold(n_splits=5, shuffle=True, random_state=8)\n",
    "\n",
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X0):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00262471, -0.01296429, -0.03149499, -0.03040279, -0.074853  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08579309, -0.42197651,  0.12508735, -0.01904092, -0.46782195])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02700948, -0.38914783,  0.13313634,  0.00084912, -0.44299328])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02981099,  0.02036987, -0.01632682, -0.04080895, -0.30929207])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03086535,  0.19833803,  0.11729076, -0.17294445,  0.21163409])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0169631 , -0.08887127,  0.04728323, -0.211642  ,  0.03888159])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.085793</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>0.029811</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>-0.016963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.012964</td>\n",
       "      <td>-0.421977</td>\n",
       "      <td>-0.389148</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>-0.088871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.031495</td>\n",
       "      <td>0.125087</td>\n",
       "      <td>0.133136</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.047283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold4</th>\n",
       "      <td>-0.030403</td>\n",
       "      <td>-0.019041</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>-0.040809</td>\n",
       "      <td>-0.172944</td>\n",
       "      <td>-0.211642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold5</th>\n",
       "      <td>-0.074853</td>\n",
       "      <td>-0.467822</td>\n",
       "      <td>-0.442993</td>\n",
       "      <td>-0.309292</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.038882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.030468</td>\n",
       "      <td>-0.173909</td>\n",
       "      <td>-0.145033</td>\n",
       "      <td>-0.063249</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>-0.046262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging\n",
       "Fold1   -0.002625 -0.085793 -0.027009  0.029811  0.030865   -0.016963\n",
       "Fold2   -0.012964 -0.421977 -0.389148  0.020370  0.198338   -0.088871\n",
       "Fold3   -0.031495  0.125087  0.133136 -0.016327  0.117291    0.047283\n",
       "Fold4   -0.030403 -0.019041  0.000849 -0.040809 -0.172944   -0.211642\n",
       "Fold5   -0.074853 -0.467822 -0.442993 -0.309292  0.211634    0.038882\n",
       "CV_mean -0.030468 -0.173909 -0.145033 -0.063249  0.077037   -0.046262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3','Fold4','Fold5','CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, looks like Random Forest did best. However, if I used the train test split in fold 3, I could potentially get away with using linear regressions. **Next**, let's look at the same models but on the data with no outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  0   1   2   5   6   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  21  24  27  28  29  31  32  33  35  36  37  38  39  40  41  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  57  58  59  60  61  63  64  65  66\n",
      "  67  68  70  71  72  73  74  75  76  79  81  83  85  86  88  89  90  91\n",
      "  93  95  97  98  99 100 101 102 104 105 106 107 108 112 113 114 115 118\n",
      " 119 120 121 122 123 124 125 126 127 129 130 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 146 147 148 150 151 152 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 170 171 173 174 177 178 179 180 181 182\n",
      " 183 184 185 188 190 191 192 193 194 195 196 199 200 201 202 203 204 205\n",
      " 206 208 209 211 212 213 214 215 216 217 219 220 221 222 223 224 225 226\n",
      " 227 228 229 230 231 232 233 234 235 236 237 240 241 242 243 244 245 248\n",
      " 249 250 251 252 254 255 256 257 258 260 262 263 264 265 266]\n",
      "TEST: [  3   4  13  22  23  25  26  30  34  42  55  56  62  69  77  78  80  82\n",
      "  84  87  92  94  96 103 109 110 111 116 117 128 131 132 145 149 153 169\n",
      " 172 175 176 186 187 189 197 198 207 210 218 238 239 246 247 253 259 261]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  2   3   4   6   7   8   9  10  11  13  14  15  16  18  19  20  21  22\n",
      "  23  24  25  26  28  29  30  31  32  34  35  36  37  38  40  41  42  43\n",
      "  44  46  47  48  49  50  51  52  53  54  55  56  58  59  60  61  62  63\n",
      "  64  66  67  68  69  70  71  73  74  75  77  78  80  81  82  83  84  85\n",
      "  86  87  91  92  93  94  95  96  97  98  99 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 115 116 117 118 119 120 122 123 124 125 126 127 128\n",
      " 130 131 132 133 134 135 136 137 138 142 143 144 145 147 148 149 150 152\n",
      " 153 154 155 156 160 162 163 165 166 167 168 169 170 172 173 174 175 176\n",
      " 179 180 181 183 184 185 186 187 188 189 190 191 192 194 196 197 198 199\n",
      " 200 202 203 205 207 208 210 211 215 216 217 218 219 220 221 223 227 228\n",
      " 229 230 231 232 233 234 235 236 237 238 239 240 241 243 244 245 246 247\n",
      " 249 250 251 252 253 254 255 257 258 259 260 261 262 263 266]\n",
      "TEST: [  0   1   5  12  17  27  33  39  45  57  65  72  76  79  88  89  90 100\n",
      " 113 114 121 129 139 140 141 146 151 157 158 159 161 164 171 177 178 182\n",
      " 193 195 201 204 206 209 212 213 214 222 224 225 226 242 248 256 264 265]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  30  31  33  34  36  37  38  39  42  43\n",
      "  45  46  47  48  51  53  54  55  56  57  58  59  61  62  63  64  65  66\n",
      "  69  71  72  73  75  76  77  78  79  80  81  82  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  98 100 102 103 104 105 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 128 129 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 145 146 147 149 151 152\n",
      " 153 154 155 156 157 158 159 160 161 164 166 167 169 170 171 172 173 174\n",
      " 175 176 177 178 181 182 183 184 185 186 187 188 189 191 192 193 194 195\n",
      " 196 197 198 199 200 201 202 204 206 207 209 210 212 213 214 215 218 220\n",
      " 222 224 225 226 227 228 229 232 233 235 237 238 239 240 241 242 243 244\n",
      " 245 246 247 248 249 251 253 254 256 257 259 261 263 264 265 266]\n",
      "TEST: [  8  10  24  29  32  35  40  41  44  49  50  52  60  67  68  70  74  83\n",
      "  97  99 101 106 127 130 144 148 150 162 163 165 168 179 180 190 203 205\n",
      " 208 211 216 217 219 221 223 230 231 234 236 250 252 255 258 260 262]\n",
      "CV_KF set:  3\n",
      "TRAIN: [  0   1   2   3   4   5   8   9  10  12  13  14  15  17  18  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  39  40  41  42\n",
      "  44  45  47  48  49  50  51  52  53  55  56  57  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  74  76  77  78  79  80  81  82  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  96  97  99 100 101 102 103 105\n",
      " 106 107 108 109 110 111 113 114 115 116 117 121 125 127 128 129 130 131\n",
      " 132 133 135 136 138 139 140 141 143 144 145 146 148 149 150 151 153 154\n",
      " 155 157 158 159 161 162 163 164 165 166 168 169 170 171 172 173 175 176\n",
      " 177 178 179 180 181 182 184 186 187 189 190 191 193 195 196 197 198 199\n",
      " 200 201 203 204 205 206 207 208 209 210 211 212 213 214 216 217 218 219\n",
      " 220 221 222 223 224 225 226 227 229 230 231 233 234 236 238 239 242 246\n",
      " 247 248 250 251 252 253 254 255 256 258 259 260 261 262 264 265]\n",
      "TEST: [  6   7  11  16  19  37  38  43  46  54  58  73  75  95  98 104 112 118\n",
      " 119 120 122 123 124 126 134 137 142 147 152 156 160 167 174 183 185 188\n",
      " 192 194 202 215 228 232 235 237 240 241 243 244 245 249 257 263 266]\n",
      "CV_KF set:  4\n",
      "TRAIN: [  0   1   3   4   5   6   7   8  10  11  12  13  16  17  19  22  23  24\n",
      "  25  26  27  29  30  32  33  34  35  37  38  39  40  41  42  43  44  45\n",
      "  46  49  50  52  54  55  56  57  58  60  62  65  67  68  69  70  72  73\n",
      "  74  75  76  77  78  79  80  82  83  84  87  88  89  90  92  94  95  96\n",
      "  97  98  99 100 101 103 104 106 109 110 111 112 113 114 116 117 118 119\n",
      " 120 121 122 123 124 126 127 128 129 130 131 132 134 137 139 140 141 142\n",
      " 144 145 146 147 148 149 150 151 152 153 156 157 158 159 160 161 162 163\n",
      " 164 165 167 168 169 171 172 174 175 176 177 178 179 180 182 183 185 186\n",
      " 187 188 189 190 192 193 194 195 197 198 201 202 203 204 205 206 207 208\n",
      " 209 210 211 212 213 214 215 216 217 218 219 221 222 223 224 225 226 228\n",
      " 230 231 232 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248\n",
      " 249 250 252 253 255 256 257 258 259 260 261 262 263 264 265 266]\n",
      "TEST: [  2   9  14  15  18  20  21  28  31  36  47  48  51  53  59  61  63  64\n",
      "  66  71  81  85  86  91  93 102 105 107 108 115 125 133 135 136 138 143\n",
      " 154 155 166 170 173 181 184 191 196 199 200 220 227 229 233 251 254]\n"
     ]
    }
   ],
   "source": [
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X1):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05338701, -0.03622173, -0.07998282, -0.00190992, -0.00161515])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11681536, -0.02302504, -0.60246096,  0.14584508,  0.16238194])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2425074 ,  0.00398809, -0.63989767,  0.19700119,  0.18435423])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03725743, -0.00609516, -0.42253981,  0.02625488,  0.00080746])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2165107 , 0.14495103, 0.09073038, 0.30272136, 0.23477095])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32835449, 0.08558503, 0.06803691, 0.34382283, 0.18444288])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X1, y1, cv=cv_kf)\n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "      <th>X1_dummy</th>\n",
       "      <th>X1_lr</th>\n",
       "      <th>X1_ridge</th>\n",
       "      <th>X1_lasso</th>\n",
       "      <th>X1_RF</th>\n",
       "      <th>X1_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.085793</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>0.029811</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>-0.016963</td>\n",
       "      <td>-0.053387</td>\n",
       "      <td>0.116815</td>\n",
       "      <td>0.242507</td>\n",
       "      <td>-0.037257</td>\n",
       "      <td>0.216511</td>\n",
       "      <td>0.328354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.012964</td>\n",
       "      <td>-0.421977</td>\n",
       "      <td>-0.389148</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>-0.088871</td>\n",
       "      <td>-0.036222</td>\n",
       "      <td>-0.023025</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>0.144951</td>\n",
       "      <td>0.085585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.031495</td>\n",
       "      <td>0.125087</td>\n",
       "      <td>0.133136</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.047283</td>\n",
       "      <td>-0.079983</td>\n",
       "      <td>-0.602461</td>\n",
       "      <td>-0.639898</td>\n",
       "      <td>-0.422540</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold4</th>\n",
       "      <td>-0.030403</td>\n",
       "      <td>-0.019041</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>-0.040809</td>\n",
       "      <td>-0.172944</td>\n",
       "      <td>-0.211642</td>\n",
       "      <td>-0.001910</td>\n",
       "      <td>0.145845</td>\n",
       "      <td>0.197001</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.302721</td>\n",
       "      <td>0.343823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold5</th>\n",
       "      <td>-0.074853</td>\n",
       "      <td>-0.467822</td>\n",
       "      <td>-0.442993</td>\n",
       "      <td>-0.309292</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>-0.001615</td>\n",
       "      <td>0.162382</td>\n",
       "      <td>0.184354</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.234771</td>\n",
       "      <td>0.184443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.030468</td>\n",
       "      <td>-0.173909</td>\n",
       "      <td>-0.145033</td>\n",
       "      <td>-0.063249</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>-0.046262</td>\n",
       "      <td>-0.034623</td>\n",
       "      <td>-0.040089</td>\n",
       "      <td>-0.002409</td>\n",
       "      <td>-0.087766</td>\n",
       "      <td>0.197937</td>\n",
       "      <td>0.202048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging  \\\n",
       "Fold1   -0.002625 -0.085793 -0.027009  0.029811  0.030865   -0.016963   \n",
       "Fold2   -0.012964 -0.421977 -0.389148  0.020370  0.198338   -0.088871   \n",
       "Fold3   -0.031495  0.125087  0.133136 -0.016327  0.117291    0.047283   \n",
       "Fold4   -0.030403 -0.019041  0.000849 -0.040809 -0.172944   -0.211642   \n",
       "Fold5   -0.074853 -0.467822 -0.442993 -0.309292  0.211634    0.038882   \n",
       "CV_mean -0.030468 -0.173909 -0.145033 -0.063249  0.077037   -0.046262   \n",
       "\n",
       "         X1_dummy     X1_lr  X1_ridge  X1_lasso     X1_RF  X1_bagging  \n",
       "Fold1   -0.053387  0.116815  0.242507 -0.037257  0.216511    0.328354  \n",
       "Fold2   -0.036222 -0.023025  0.003988 -0.006095  0.144951    0.085585  \n",
       "Fold3   -0.079983 -0.602461 -0.639898 -0.422540  0.090730    0.068037  \n",
       "Fold4   -0.001910  0.145845  0.197001  0.026255  0.302721    0.343823  \n",
       "Fold5   -0.001615  0.162382  0.184354  0.000807  0.234771    0.184443  \n",
       "CV_mean -0.034623 -0.040089 -0.002409 -0.087766  0.197937    0.202048  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3','Fold4','Fold5','CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, everything does seem to improve when removing the outliers. Looks like the non-linear regression based models still faired best but the set from fold 4 performed well across all models. The outliers, however, are in the positive direction: higher recyclers. So if I do go with a model with the outliers removed, I still need to go back and see what is unique about those outliers; I shouldn't just throw them out and forget about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:Train Ratio\n",
    "\n",
    "I can kinda of informally see how the dataset does with a higher test ratio by changing the n_split during the cross validation. Above, I used the default of 5, however, this only leaves us with 54 test points. We may increase our odds of success by increasing this quantity so I'll change the n_split to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  2   6   7   8   9  10  11  12  14  15  16  18  19  20  21  24  27  28\n",
      "  29  31  32  35  36  37  38  40  41  43  44  46  47  48  49  50  51  54\n",
      "  58  59  60  61  63  64  66  67  68  70  73  74  75  76  81  83  85  86\n",
      "  89  90  91  92  95  97  98  99 101 102 104 105 106 107 108 112 115 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 130 131 132 133 134 135 136\n",
      " 137 138 140 141 142 143 144 145 147 150 152 153 154 155 156 159 160 161\n",
      " 162 164 166 167 168 169 170 171 173 174 175 176 179 181 183 184 188 190\n",
      " 191 194 195 196 199 200 201 203 205 206 207 210 211 213 214 216 217 220\n",
      " 223 224 225 226 228 229 231 234 235 236 237 238 239 242 243 245 246 247\n",
      " 248 249 250 251 252 253 254 255 257 258 259 261 262 264 266 267 269 270]\n",
      "TEST: [  0   1   3   4   5  13  17  22  23  25  26  30  33  34  39  42  45  52\n",
      "  53  55  56  57  62  65  69  71  72  77  78  79  80  82  84  87  88  93\n",
      "  94  96 100 103 109 110 111 113 114 116 129 139 146 148 149 151 157 158\n",
      " 163 165 172 177 178 180 182 185 186 187 189 192 193 197 198 202 204 208\n",
      " 209 212 215 218 219 221 222 227 230 232 233 240 241 244 256 260 263 265\n",
      " 268]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  13  15  16  17  18  19  20  21\n",
      "  22  23  25  26  28  30  31  33  34  36  37  38  39  42  45  46  47  48\n",
      "  51  52  53  54  55  56  57  59  61  62  63  64  65  66  69  71  72  73\n",
      "  75  77  78  79  80  81  82  84  85  86  87  88  91  93  94  95  96  98\n",
      " 100 102 103 105 107 108 109 110 111 112 113 114 115 116 118 120 122 123\n",
      " 125 126 129 133 134 135 136 137 138 139 143 146 147 148 149 151 152 155\n",
      " 156 157 158 160 163 165 166 167 170 172 173 174 177 178 180 182 183 185\n",
      " 186 187 188 189 191 192 193 194 196 197 198 199 200 202 203 204 208 209\n",
      " 210 212 215 216 217 218 219 220 221 222 223 224 227 229 230 232 233 235\n",
      " 237 238 240 241 242 243 244 248 249 251 256 257 259 260 263 265 267 268\n",
      " 270]\n",
      "TEST: [  8  10  12  14  24  27  29  32  35  40  41  43  44  49  50  58  60  67\n",
      "  68  70  74  76  83  89  90  92  97  99 101 104 106 117 119 121 124 127\n",
      " 128 130 131 132 140 141 142 144 145 150 153 154 159 161 162 164 168 169\n",
      " 171 175 176 179 181 184 190 195 201 205 206 207 211 213 214 225 226 228\n",
      " 231 234 236 239 245 246 247 250 252 253 254 255 258 261 262 264 266 269]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   3   4   5   8  10  12  13  14  17  22  23  24  25  26  27  29\n",
      "  30  32  33  34  35  39  40  41  42  43  44  45  49  50  52  53  55  56\n",
      "  57  58  60  62  65  67  68  69  70  71  72  74  76  77  78  79  80  82\n",
      "  83  84  87  88  89  90  92  93  94  96  97  99 100 101 103 104 106 109\n",
      " 110 111 113 114 116 117 119 121 124 127 128 129 130 131 132 139 140 141\n",
      " 142 144 145 146 148 149 150 151 153 154 157 158 159 161 162 163 164 165\n",
      " 168 169 171 172 175 176 177 178 179 180 181 182 184 185 186 187 189 190\n",
      " 192 193 195 197 198 201 202 204 205 206 207 208 209 211 212 213 214 215\n",
      " 218 219 221 222 225 226 227 228 230 231 232 233 234 236 239 240 241 244\n",
      " 245 246 247 250 252 253 254 255 256 258 260 261 262 263 264 265 266 268\n",
      " 269]\n",
      "TEST: [  2   6   7   9  11  15  16  18  19  20  21  28  31  36  37  38  46  47\n",
      "  48  51  54  59  61  63  64  66  73  75  81  85  86  91  95  98 102 105\n",
      " 107 108 112 115 118 120 122 123 125 126 133 134 135 136 137 138 143 147\n",
      " 152 155 156 160 166 167 170 173 174 183 188 191 194 196 199 200 203 210\n",
      " 216 217 220 223 224 229 235 237 238 242 243 248 249 251 257 259 267 270]\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "cv_kf = KFold(n_splits=3, shuffle=True, random_state=8)\n",
    "\n",
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X0):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01458113, -0.01553683, -0.09007735])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08721139,  0.15905641, -0.75862946])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01603247,  0.16700945, -0.74216146])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01745458,  0.00209897, -0.74093297])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11768537, 0.2370164 , 0.11437933])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04694505,  0.11108638,  0.03541457])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  2   6   7   8   9  10  11  12  14  15  16  18  19  20  21  24  27  28\n",
      "  29  31  32  35  36  37  38  40  41  43  44  46  47  48  49  50  51  52\n",
      "  53  54  58  59  60  61  63  64  66  67  68  70  71  73  74  75  76  81\n",
      "  83  85  86  89  90  91  93  95  97  98  99 101 102 104 105 106 107 108\n",
      " 112 114 115 118 119 120 122 123 124 125 126 127 129 130 133 134 135 136\n",
      " 137 138 140 142 143 144 147 148 150 152 154 155 156 158 159 160 162 163\n",
      " 165 166 167 168 170 173 174 177 178 179 180 181 182 183 184 185 188 190\n",
      " 191 192 194 195 196 199 200 202 203 205 208 209 211 213 215 216 217 219\n",
      " 220 221 223 225 227 228 229 230 231 232 233 234 235 236 237 240 241 243\n",
      " 244 245 249 250 251 252 254 255 257 258 260 262 263 264 265 266]\n",
      "TEST: [  0   1   3   4   5  13  17  22  23  25  26  30  33  34  39  42  45  55\n",
      "  56  57  62  65  69  72  77  78  79  80  82  84  87  88  92  94  96 100\n",
      " 103 109 110 111 113 116 117 121 128 131 132 139 141 145 146 149 151 153\n",
      " 157 161 164 169 171 172 175 176 186 187 189 193 197 198 201 204 206 207\n",
      " 210 212 214 218 222 224 226 238 239 242 246 247 248 253 256 259 261]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  13  14  15  16  17  18  19  20  21\n",
      "  22  23  25  26  28  30  31  33  34  36  37  38  39  42  45  46  47  48\n",
      "  51  53  54  55  56  57  59  61  62  63  64  65  66  69  71  72  73  77\n",
      "  78  79  80  81  82  84  85  86  87  88  91  92  93  94  95  96  98 100\n",
      " 102 103 105 107 108 109 110 111 112 113 115 116 117 118 120 121 122 123\n",
      " 125 126 128 131 132 133 134 135 136 137 138 139 141 143 145 146 149 151\n",
      " 152 153 154 155 157 160 161 164 166 167 169 170 171 172 173 175 176 181\n",
      " 183 184 186 187 188 189 191 192 193 194 196 197 198 199 200 201 204 206\n",
      " 207 210 212 214 215 218 220 222 224 226 227 228 229 232 233 235 238 239\n",
      " 240 242 243 244 245 246 247 248 249 251 253 254 256 259 261 263]\n",
      "TEST: [  8  10  11  12  24  27  29  32  35  40  41  43  44  49  50  52  58  60\n",
      "  67  68  70  74  75  76  83  89  90  97  99 101 104 106 114 119 124 127\n",
      " 129 130 140 142 144 147 148 150 156 158 159 162 163 165 168 174 177 178\n",
      " 179 180 182 185 190 195 202 203 205 208 209 211 213 216 217 219 221 223\n",
      " 225 230 231 234 236 237 241 250 252 255 257 258 260 262 264 265 266]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   3   4   5   8  10  11  12  13  17  22  23  24  25  26  27  29\n",
      "  30  32  33  34  35  39  40  41  42  43  44  45  49  50  52  55  56  57\n",
      "  58  60  62  65  67  68  69  70  72  74  75  76  77  78  79  80  82  83\n",
      "  84  87  88  89  90  92  94  96  97  99 100 101 103 104 106 109 110 111\n",
      " 113 114 116 117 119 121 124 127 128 129 130 131 132 139 140 141 142 144\n",
      " 145 146 147 148 149 150 151 153 156 157 158 159 161 162 163 164 165 168\n",
      " 169 171 172 174 175 176 177 178 179 180 182 185 186 187 189 190 193 195\n",
      " 197 198 201 202 203 204 205 206 207 208 209 210 211 212 213 214 216 217\n",
      " 218 219 221 222 223 224 225 226 230 231 234 236 237 238 239 241 242 246\n",
      " 247 248 250 252 253 255 256 257 258 259 260 261 262 264 265 266]\n",
      "TEST: [  2   6   7   9  14  15  16  18  19  20  21  28  31  36  37  38  46  47\n",
      "  48  51  53  54  59  61  63  64  66  71  73  81  85  86  91  93  95  98\n",
      " 102 105 107 108 112 115 118 120 122 123 125 126 133 134 135 136 137 138\n",
      " 143 152 154 155 160 166 167 170 173 181 183 184 188 191 192 194 196 199\n",
      " 200 215 220 227 228 229 232 233 235 240 243 244 245 249 251 254 263]\n"
     ]
    }
   ],
   "source": [
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X1):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08957878, -0.1209515 , -0.01201351])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01517724, -0.38834619,  0.10209835])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08972173, -0.38117819,  0.16464953])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06988468, -0.23457381,  0.00298756])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19785585, 0.00528953, 0.20736793])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16058833, -0.06794259,  0.13272154])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X1, y1, cv=cv_kf)\n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "      <th>X1_dummy</th>\n",
       "      <th>X1_lr</th>\n",
       "      <th>X1_ridge</th>\n",
       "      <th>X1_lasso</th>\n",
       "      <th>X1_RF</th>\n",
       "      <th>X1_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.014581</td>\n",
       "      <td>-0.087211</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>0.117685</td>\n",
       "      <td>-0.046945</td>\n",
       "      <td>-0.089579</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.089722</td>\n",
       "      <td>-0.069885</td>\n",
       "      <td>0.197856</td>\n",
       "      <td>0.160588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.015537</td>\n",
       "      <td>0.159056</td>\n",
       "      <td>0.167009</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.237016</td>\n",
       "      <td>0.111086</td>\n",
       "      <td>-0.120952</td>\n",
       "      <td>-0.388346</td>\n",
       "      <td>-0.381178</td>\n",
       "      <td>-0.234574</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>-0.067943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.090077</td>\n",
       "      <td>-0.758629</td>\n",
       "      <td>-0.742161</td>\n",
       "      <td>-0.740933</td>\n",
       "      <td>0.114379</td>\n",
       "      <td>0.035415</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>0.102098</td>\n",
       "      <td>0.164650</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.207368</td>\n",
       "      <td>0.132722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.040065</td>\n",
       "      <td>-0.228928</td>\n",
       "      <td>-0.197061</td>\n",
       "      <td>-0.240460</td>\n",
       "      <td>0.156360</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>-0.074181</td>\n",
       "      <td>-0.090357</td>\n",
       "      <td>-0.042269</td>\n",
       "      <td>-0.100490</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>0.075122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging  \\\n",
       "Fold1   -0.014581 -0.087211 -0.016032  0.017455  0.117685   -0.046945   \n",
       "Fold2   -0.015537  0.159056  0.167009  0.002099  0.237016    0.111086   \n",
       "Fold3   -0.090077 -0.758629 -0.742161 -0.740933  0.114379    0.035415   \n",
       "CV_mean -0.040065 -0.228928 -0.197061 -0.240460  0.156360    0.033185   \n",
       "\n",
       "         X1_dummy     X1_lr  X1_ridge  X1_lasso     X1_RF  X1_bagging  \n",
       "Fold1   -0.089579  0.015177  0.089722 -0.069885  0.197856    0.160588  \n",
       "Fold2   -0.120952 -0.388346 -0.381178 -0.234574  0.005290   -0.067943  \n",
       "Fold3   -0.012014  0.102098  0.164650  0.002988  0.207368    0.132722  \n",
       "CV_mean -0.074181 -0.090357 -0.042269 -0.100490  0.136838    0.075122  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3', 'CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the averages definitely seem better. It does mean I've only tested 3 configurations rather than 5 but RF consistently is positive and bagging does fairly well. It also seems like the difference between the data with the outliers and without the outliers has fewer differences in fit. It seems like increasing the test_split will be helpful.\n",
    "\n",
    "---\n",
    "\n",
    "### Take Aways\n",
    "\n",
    "There probably is no linear relationship between my dependent variable and the rest of the dataset; this means that tree-based regressors will fair much better *consistently*. This intuitively makes sense to me because I have so many binary features that this inheriently lends itself better to decision trees, not so much for linear regression. This also gives me more hope that a neural network may fair well (more on that later).\n",
    "\n",
    "I think moving forward, I'm going to do the normal train_test_split method, including the outliers for now, but with a test_split = 0.34 and I will only look at models based on decision trees. I am especially interested in models that support bootstrapping since my dataset isn't huge. So the models I'll look at are: RandomForests (bootstrapping), Bagging (bootstrapping), and Gradient Boosting (adding this one in). [Source to look at other tree-based ensembles](https://scikit-learn.org/stable/modules/classes.html?highlight=ensemble#module-sklearn.ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with outliers\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X0, y0, test_size= 0.33, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = {}\n",
    "\n",
    "def fit_model(model, name):\n",
    "    model.fit(X_train, y_train)\n",
    "    score_train = model.score(X_train, y_train)\n",
    "    score_test = model.score(X_test, y_test)\n",
    "    rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "    mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "    fit_results[name] = (score_train, score_test, rmse, mae)\n",
    "    return score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAV/0lEQVR4nO3dfYxU133G8e+zLyRAYoHttY0XKMRBtnACxJ6YvFRxqOvERKrXbuwWRFwrRcJuSqpUSmRaRQjLTRvFjtKo8os2hMhSU7uxgx3axiGRWylSKZTFdmxjGxvjFxYIXlPwKw4s/PrH3IXLMLtzd9idAc7zkUY799xz7/zOmTv7zNyZnVVEYGZm6WlpdgFmZtYcDgAzs0Q5AMzMEuUAMDNLlAPAzCxRbc0uYDjOPvvsmDZtWrPLMDM7pWzatOn1iOiobD+lAmDatGn09PQ0uwwzs1OKpFeqtfsUkJlZohwAZmaJcgCYmSXKAWBmligHgJlZogoFgKSrJG2RtFXSsirrF0l6MruskzQ7t+6vJW2W9LSk+yS9P2s/U9KvJL2Q/Zw4csMyM7NaagaApFbgTmA+MBNYKGlmRbeXgMsjYhZwG9CdbdsJ/BVQioiPAK3AgmybZcCjETEDeDRbNjOzBinyCuAyYGtEbIuIA8D9QFe+Q0Ssi4i92eJ6YHJudRswVlIbMA7YmbV3Afdm1+8FrqlvCGZmVo8iAdAJbM8t92Ztg1kMPAIQETuAO4BXgV3AGxHxy6zfuRGxK+u3Czin2s4kLZHUI6mnr6+vQLlmZlZEkQBQlbaq/0VG0jzKAXBLtjyR8jP96cD5wHhJXxpOgRHRHRGliCh1dBz3l8xmZlanIgHQC0zJLU/m6GmcIyTNAlYCXRGxJ2v+Q+CliOiLiIPAauBT2brdkiZl204CXqtvCGZmVo8iAbARmCFpuqQxlN/EXZPvIGkq5V/uN0TE87lVrwKfkDROkoArgGezdWuAG7PrNwI/q38YZmY2XDW/DC4i+iUtBdZS/hTPqojYLOnmbP09wHLgLOCu8u95+rPTNhskPQg8BvQDj5N9Qgj4NvATSYspB8X1Izs0MzMbik6lfwpfKpXC3wZqZjY8kjZFRKmy3X8JbGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJapQAEi6StIWSVslLauyfpGkJ7PLOkmzs/YLJT2Ru7wp6WvZuhWSduTWfWFkh2ZmZkNpq9VBUitwJ3Al0AtslLQmIp7JdXsJuDwi9kqaD3QDcyNiCzAnt58dwEO57b4XEXeMzFDMzGw4irwCuAzYGhHbIuIAcD/Qle8QEesiYm+2uB6YXGU/VwAvRsQrJ1KwmZmNjCIB0Alszy33Zm2DWQw8UqV9AXBfRdvS7LTRKkkTq+1M0hJJPZJ6+vr6CpRrZmZFFAkAVWmLqh2leZQD4JaK9jHA1cADuea7gQsonyLaBXy32j4jojsiShFR6ujoKFCumZkVUSQAeoEpueXJwM7KTpJmASuBrojYU7F6PvBYROweaIiI3RFxKCIOAz+gfKrJzMwapEgAbARmSJqePZNfAKzJd5A0FVgN3BARz1fZx0IqTv9ImpRbvBZ4ejiFm5nZian5KaCI6Je0FFgLtAKrImKzpJuz9fcAy4GzgLskAfRHRAlA0jjKnyC6qWLX35E0h/LppJerrDczs1GkiKqn809KpVIpenp6ml2GmdkpRdKmgSflef5LYDOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFGFAkDSVZK2SNoqaVmV9YskPZld1kmanbVfKOmJ3OVNSV/L1p0p6VeSXsh+ThzZoZmZ2VBqBoCkVuBOYD4wE1goaWZFt5eAyyNiFnAb0A0QEVsiYk5EzAEuBd4FHsq2WQY8GhEzgEezZTMza5AirwAuA7ZGxLaIOADcD3TlO0TEuojYmy2uByZX2c8VwIsR8Uq23AXcm12/F7hmuMWbmVn9igRAJ7A9t9ybtQ1mMfBIlfYFwH255XMjYhdA9vOcajuTtERSj6Sevr6+AuWamVkRRQJAVdqiakdpHuUAuKWifQxwNfDAcAuMiO6IKEVEqaOjY7ibm5nZIIoEQC8wJbc8GdhZ2UnSLGAl0BUReypWzwcei4jdubbdkiZl204CXhtO4WZmdmKKBMBGYIak6dkz+QXAmnwHSVOB1cANEfF8lX0s5NjTP2T7uDG7fiPws+EUbmZmJ6atVoeI6Je0FFgLtAKrImKzpJuz9fcAy4GzgLskAfRHRAlA0jjgSuCmil1/G/iJpMXAq8D1IzMkMzMrQhFVT+eflEqlUvT09DS7DDOzU4qkTQNPyvP8l8BmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiav5HsFPdw4/v4Pa1W9i5bz/nTxjLNz5/Idd8rLOpt/3w4zu49d82s/fdgwBMGNvOiqsvPqG66hlnkW2q9QG4fe0WduzbT4vgcMX/FJIgAjonjGXeRR3813N97Ni3n1aJQxFHfnbm9ve3q5/k3YOHj+xj/JhWvnXtR3mg51X++8X/O2b/nRVzuWLNZvbtP3hMnzGt4k8+PoWfbuplf26/A9pb4FCUaxfQ2iL6KwdS4dMXnMn0jg/w4/Wvku8pwaK5U/m7az56TP9vPvwU923YzqFB/ulSi+CCjvG82PfOcXM44H1tLYxtbz1ufANjPHg4iGwM48a08u6BQ0wY104EvLH/YKFjYeA+zt9HlXM81PrKfeXvj3HtLUjinQOHgPKxfvH5H2T9tr1HjoWFc6ccN3fV6hvsOG3mY3w0DWfe63Va/0ewhx/fwd+sfor9Bw8daRvb3so//PFHR/0AGey2v3hpJ/+6cTsHDx077+0t4vbrZ9dVVz3jLLJNtT7tLQJxXP31am9VXfs6Mpf/u52DNX5xN8qXPnE0BL758FP88/pXm1xR2VDHQrX7OL/dFy/t5Kebdgy6vvJ4+cYDv6nr/sjPXa368rfbzMf4aKp1vwx3fEn+R7Db1245bgL3HzzE7Wu3NO2279tw/C9/gIOHo+666hlnkW2q9Tl4OEbslz/UHyRH5vIk+eUPcN+G7VWvN9tQx0K1+zi/3X0btg+5vvJ4qff+GGy+ah2nzXyMj6Za98tIje+0DoCd+/YPq70Rtz3Y6YChtqn3tobaX5FtGjFPJ2KouWyGfD0nW231PhZqjWOkjpfBbqdW3c18jI+mWvWP1PhO6wA4f8LYYbU34rZbpWFvU+9tDbW/Its0Yp5OxFBz2Qz5ek622up9LNQax0gdL4PdTq26m/kYH0216h+p8Z3WAfCNz1/I2PbWY9rGtrceeeOxGbe9cO4U2luPP9jbW1R3XfWMs8g21fq0t6hq/fWqd19H5rLl5PlFu3DulKrXm22oY6HafZzfbuHcKUOurzxe6r0/BpuvWsdpMx/jo6nW/TJS42tdsWLFiOyoEbq7u1csWbKkcP+LJp3B5IljeWrHG7z9Xj+dE8ay/I9mNuTNocFu+yvzPszUM8ex4aU9vJd9OmXC2Hb+/gTetKpnnEW2qdZnxdUX87mZ5/HUjjd4671+WgSVL94Hnsx1ThhL15zz2fP2Ad56r59WiYAjPwf2d9VHzuPXz792zPnj8WNauf262bz13gG27z325W7lXK7ftof3+o/9pM+YVrFw7lRe2P1W1U/3tGdPfYLyJ2jaWjToJ3EGfPqCM7n8wg6e6n3juPFWvon5Bxedy+tv/47NO948bn4GtAg+fM549r17cNA+72tr4YPvaztufANjHGgV5TnrPxRMHNfO+9ta+V3/4ZrHQv4+zt9H+Tkean3l8VJ5f4xrb2FMW8uR93omjG3n0t+bwM597x05FhYN8gZwZX3VjtNmPsZHU637Zbjju/XWW3etWLGiu7L9tP4UkJmZJfopIDMzG5wDwMwsUQ4AM7NEOQDMzBJVKAAkXSVpi6StkpZVWb9I0pPZZZ2k2bl1EyQ9KOk5Sc9K+mTWvkLSDklPZJcvjNywzMyslppfBiepFbgTuBLoBTZKWhMRz+S6vQRcHhF7Jc0HuoG52brvA7+IiOskjQHG5bb7XkTcMRIDMTOz4SnyCuAyYGtEbIuIA8D9QFe+Q0Ssi4i92eJ6YDKApDOAzwA/zPodiIh9I1W8mZnVr0gAdAL5b2rqzdoGsxh4JLv+IaAP+JGkxyWtlDQ+13dpdtpolaSJ1XYmaYmkHkk9fX19Bco1M7MiigRAtb/trvrXY5LmUQ6AW7KmNuAS4O6I+BjwDjDwHsLdwAXAHGAX8N1q+4yI7ogoRUSpo6OjQLlmZlZEkQDoBfJf1DEZ2FnZSdIsYCXQFRF7ctv2RsSGbPlByoFAROyOiEMRcRj4AeVTTWZm1iBFAmAjMEPS9OxN3AXAmnwHSVOB1cANEfH8QHtE/BbYLmngm4uuAJ7JtpmU28W1wNN1j8LMzIat5qeAIqJf0lJgLdAKrIqIzZJuztbfAywHzgLuUvmbwPpz3zvxVeDHWXhsA76ctX9H0hzKp5NeBm4asVGZmVlN/jI4M7PTnL8MzszMjuEAMDNLlAPAzCxRDgAzs0Q5AMzMEuUAMDNLlAPAzCxRDgAzs0Q5AMzMEuUAMDNLlAPAzCxRDgAzs0Q5AMzMEuUAMDNLlAPAzCxRDgAzs0Q5AMzMEuUAMDNLlAPAzCxRDgAzs0Q5AMzMEuUAMDNLlAPAzCxRDgAzs0Q5AMzMEuUAMDNLlAPAzCxRDgAzs0QVCgBJV0naImmrpGVV1i+S9GR2WSdpdm7dBEkPSnpO0rOSPpm1nynpV5JeyH5OHLlhmZlZLTUDQFIrcCcwH5gJLJQ0s6LbS8DlETELuA3ozq37PvCLiLgImA08m7UvAx6NiBnAo9mymZk1SJFXAJcBWyNiW0QcAO4HuvIdImJdROzNFtcDkwEknQF8Bvhh1u9AROzL+nUB92bX7wWuOZGBmJnZ8BQJgE5ge265N2sbzGLgkez6h4A+4EeSHpe0UtL4bN25EbELIPt5TrWdSVoiqUdST19fX4FyzcysiCIBoCptUbWjNI9yANySNbUBlwB3R8THgHcY5qmeiOiOiFJElDo6OoazqZmZDaFIAPQCU3LLk4GdlZ0kzQJWAl0RsSe3bW9EbMiWH6QcCAC7JU3Ktp0EvDb88s3MrF5FAmAjMEPSdEljgAXAmnwHSVOB1cANEfH8QHtE/BbYLunCrOkK4Jns+hrgxuz6jcDP6h6FmZkNW1utDhHRL2kpsBZoBVZFxGZJN2fr7wGWA2cBd0kC6I+IUraLrwI/zsJjG/DlrP3bwE8kLQZeBa4fuWGZmVktiqh6Ov+kVCqVoqenp9llmJmdUiRtyj0pP8J/CWxmligHgJlZohwAZmaJcgCYmSXKAWBmligHgJlZohwAZmaJcgCYmSXKAWBmligHgJlZohwAZmaJcgCYmSXKAWBmligHgJlZohwAZmaJcgCYmSXKAWBmligHgJlZohwAZmaJcgCYmSXKAWBmligHgJlZohwAZmaJcgCYmSXKAWBmligHgJlZohwAZmaJcgCYmSWqUABIukrSFklbJS2rsn6RpCezyzpJs3PrXpb0lKQnJPXk2ldI2pG1PyHpCyMzJDMzK6KtVgdJrcCdwJVAL7BR0pqIeCbX7SXg8ojYK2k+0A3Mza2fFxGvV9n99yLijvrLNzOzehV5BXAZsDUitkXEAeB+oCvfISLWRcTebHE9MHlkyzQzs5FWJAA6ge255d6sbTCLgUdyywH8UtImSUsq+i7NThutkjSxUMVmZjYiigSAqrRF1Y7SPMoBcEuu+dMRcQkwH/hLSZ/J2u8GLgDmALuA7w6yzyWSeiT19PX1FSjXzMyKKBIAvcCU3PJkYGdlJ0mzgJVAV0TsGWiPiJ3Zz9eAhyifUiIidkfEoYg4DPxgoL1SRHRHRCkiSh0dHcVGZWZmNRUJgI3ADEnTJY0BFgBr8h0kTQVWAzdExPO59vGSPjhwHfgc8HS2PCm3i2sH2s3MrDFqfgooIvolLQXWAq3AqojYLOnmbP09wHLgLOAuSQD9EVECzgUeytragH+JiF9ku/6OpDmUTye9DNw0kgMzM7OhKaLq6fyTUqlUip6entodzczsCEmbsiflx/BfApuZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJcoBYGaWKAeAmVmiHABmZolyAJiZJeqU+o9gkvqAV5pdxzCcDbze7CJOEp6LozwXR3kujhrNufi9iOiobDylAuBUI6mn2r9hS5Hn4ijPxVGei6OaMRc+BWRmligHgJlZohwAo6u72QWcRDwXR3kujvJcHNXwufB7AGZmifIrADOzRDkAzMwS5QA4QZKukrRF0lZJy6qsv0jS/0j6naSvN6PGRikwF4skPZld1kma3Yw6G6HAXHRl8/CEpB5Jv9+MOhul1nzk+n1c0iFJ1zWyvkYqcGx8VtIb2bHxhKTlo1ZMRPhS5wVoBV4EPgSMAX4DzKzocw7wceBbwNebXXOT5+JTwMTs+nxgQ7PrbuJcfICj78HNAp5rdt3NnI9cv/8Efg5c1+y6m3hsfBb490bU41cAJ+YyYGtEbIuIA8D9QFe+Q0S8FhEbgYPNKLCBiszFuojYmy2uByY3uMZGKTIXb0f2aAfGA6fzpzFqzkfmq8BPgdcaWVyDFZ2LhnAAnJhOYHtuuTdrS9Fw52Ix8MioVtQ8heZC0rWSngP+A/jzBtXWDDXnQ1IncC1wTwPraoaij5NPSvqNpEckXTxaxTgAToyqtJ3Oz+SGUnguJM2jHAC3jGpFzVNoLiLioYi4CLgGuG3Uq2qeIvPxj8AtEXGoAfU0U5G5eIzyd/fMBv4JeHi0inEAnJheYEpueTKws0m1NFuhuZA0C1gJdEXEngbV1mjDOi4i4tfABZLOHu3CmqTIfJSA+yW9DFwH3CXpmsaU11A15yIi3oyIt7PrPwfaR+vYcACcmI3ADEnTJY0BFgBrmlxTs9ScC0lTgdXADRHxfBNqbJQic/FhScquX0L5DcHTNRBrzkdETI+IaRExDXgQ+EpEjNoz3yYqcmyclzs2LqP8e3pUjo220dhpKiKiX9JSYC3ld/dXRcRmSTdn6++RdB7QA5wBHJb0Ncrv+r/ZtMJHQZG5AJYDZ1F+dgfQH6fhN0EWnIsvAn8m6SCwH/jT3JvCp5WC85GEgnNxHfAXkvopHxsLRuvY8FdBmJklyqeAzMwS5QAwM0uUA8DMLFEOADOzRDkAzMwS5QAwM0uUA8DMLFH/DzFrMSwqN8i4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model0 = DummyRegressor()\n",
    "fit_model(model0, 'dummy')\n",
    "plt.scatter(y_test, model0.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = RandomForestRegressor(n_jobs=-1, random_state=8)\n",
    "fit_model(model1, 'RFR')\n",
    "plt.scatter(y_test, model1.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = BaggingRegressor(n_jobs=-1, random_state=8)\n",
    "fit_model(model2, 'bagging')\n",
    "plt.scatter(y_test, model2.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = HistGradientBoostingRegressor(max_iter=10_000, random_state=8)\n",
    "fit_model(model3, 'GradBoost')\n",
    "plt.scatter(y_test, model3.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost\n",
       "score_train  0.000000  0.880999  0.809259   0.998480\n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776\n",
       "rmse         0.080172  0.076054  0.080895   0.093898\n",
       "mae          0.060118  0.058374  0.062488   0.068800"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like in each model we have a very decent train fit but the test fit is horrible, especially with GradBoost (which is the only model that doesn't have bootstrapping... not sure if that's why or not). What confuses me is that the residuals scatter plots make it seem like Boosting is the cleanest fit... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "[Hyperparameters](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor) of interest:\n",
    "\n",
    "* **n_estimators**-- how many trees in forest. Seems simple enough to test a few.\n",
    "* **max_samples** -- By default, it's all of the X's in the training set. However, I'm curious to see how decreasing this quantity may impact the residuals of y_preds vs y_test.\n",
    "* **criterion** {“mse”, “mae”}, default=”mse” -- according to the docs, \"The function to measure the quality of a split. Supported criteria are “mse” for the mean squared error, which is equal to variance reduction as feature selection criterion, and “mae” for the mean absolute error.\" I think this may be suggesting that if I have issues with model-variance (overfitting), I may want to change the criterion to MAE.\n",
    "* **max_features** -- this could be an interesting pseudo RFE\n",
    "* **min_impurity_decrease** -- this may be better than looking at max leave nodes if I care more about how much the model is improve, rather than complexity (which may be driving up model complexity). Otherwise, I may want to look at **max_depth**\n",
    "* **ccp_alpha** -- This parameter is used to effectively prune out any highly complex models. I don't really know how to use this but I may study this more if model-variance still seems to be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "    'n_estimators': [10,100,1000],\n",
    "    'max_samples': [None, 0.66, 0.33],\n",
    "    'min_impurity_decrease': [0.0, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle = True, random_state= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1a = RandomForestRegressor(criterion='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcvUlEQVR4nO3df6zd9X3f8ecrF1szpIkzcFVxbdduwkCkmJjcQlqjEmgjYGlnByJBRqi2gCwy0SVZy3CmiWxiEZ4ytY0qmGW57J+h0SoQyxtmXlWnihYKsh0bUuOAXGjCvWaKw3BTmBV8nff+OOea4+vvued77vn++Hy/5/WQLN3zPd/vOZ/v9x6/7+e8P+/P56uIwMzM2us9dTfAzMzK5UBvZtZyDvRmZi3nQG9m1nIO9GZmLXde3Q3IctFFF8WaNWvqboaZWWMcOHDgxxGxIuu5JAP9mjVr2L9/f93NMDNrDEk/6PecUzdmZi3nQG9m1nIO9GZmLedAb2bWcg70ZmYtl2TVjZkNtvPgDF/b8xLHTpzk4uXLuO/GS9m0frLuZlmCHOjNGmjnwRm+/OT3OHnqNAAzJ07y5Se/B+Bgb+fIlbqRdJOklyQdlbQl4/mNkl6QdEjSfknXdrevkvQtSUckHZb0haJPwGwcfW3PS2eC/JyTp07ztT0v1dQiS9nAHr2kCeBh4BPANLBP0q6IeLFnt78AdkVESFoH/BlwGTAL/F5EfFfSzwEHJP35vGOtQZwuSMOxEyeH2l4FfzbSlSd1czVwNCJeAZD0OLAROBOsI+Ktnv0vAKK7/XXg9e7Pfy/pCDDZe6w1h9MFg1UV7C5evoyZjKB+8fJlhb9XHv5spC1P6mYSeK3n8XR321kkfUrS94GngM9lPL8GWA88l/UmkjZ30z77jx8/nqNZVjWnCxY2F+xmTpwkeDfY7Tw4U/h73XfjpSxbMnHWtmVLJrjvxksLf688/NlIW55Ar4xt59x/MCK+GRGXAZuAB896Aem9wBPAFyPiJ1lvEhHbI2IqIqZWrMhcl8dqlmK6ICVVBrtN6yd56JYrmFy+DAGTy5fx0C1X1NZ79mcjbXlSN9PAqp7HK4Fj/XaOiG9L+qCkiyLix5KW0Anyj0XEk6M11+qUWrogNVUHu03rJ5NJi/izkbY8Pfp9wCWS1kpaCtwO7OrdQdKHJKn781XAUuCN7rY/AY5ExB8U23SrWmrpgtT0C2opBbudB2fYsHUva7c8xYatewtLK/mzkbaBgT4iZoF7gT3AEeDPIuKwpHsk3dPd7VbgryUdolOhc1tEBLABuBO4oVt6eUjSPy7lTKx0qaULUpN6sCtzDMGfjbSpE4/TMjU1FV6P3qpQdJVMyiWGG7buzUyvTC5fxne23FBDi6xIkg5ExFTWc54Za2OrjJLAlPLm83nAdHx5UTMbW+NWEtiEMQQrhwO9ja1x6+GmPoZg5XGgt7E1bj1cD5iOL+fora+UBxZHtfPgDG//dPac7W3t4c7/Xf7hbR9pze/SBnOgt0xtXrtk/rnN+cD5S/jKb3+48ec3X5t/l21RdqfKqRvL1OaByqxzAzh/6XmtDHxt/l22QRVrJLlHb5naPFCZ59zalLZq8++yDRb6Q1zUZ849esvU5oHKQedW5SqUVWjz77INqvhD7EBvmdpcijfo3NqW6mjz77INqvhD7NSNZZr7ytjG5QEGnVtVqY6qrkcZv0srzn03XnpOcUDRf4i91o1VIqvSZdmSiSTruKtYE6ZJ18PKV8Qffa91Y7WrYsCpKFk9LIC3fzrLzoMzhbS3SdfDylf2GkkO9FaJVCs/FupJ/fv/fpg3/9+pM/ueOHlqUfXnWe+R6vWwdvJgrFUixcqPhaprNq2f5Pyl5/aDhh2U7fce71+2JHP/90iNre6xdDnQWyVSrPwYVF1TRK+733ucOv2zzJsxn45odCmnpcmB3iqR4oJagwJ5Ed9C+r3H2++cpl8ZRJNLOS1NztFbZVK7KcegG1oXUfbW7z0Gca7eiuQevY2tQemkIr6FZL1HHlWPXZR103BLg3v0NrbyTCQa9VtI1nu8/dNZTpw81feYqscuvLpl+3nClFnFsiZLCQg63xqqnrVaxASxVGY9jzNPmDJLyELfJOYC5pf+9FBlAXPU6iJ/I0ifA72NjZR6nVkpoboC5qBB6UE8yzd9uQZjJd0k6SVJRyVtyXh+o6QXJB2StF/StXmPNatCE5YermvVzFHnOHiWb/oGBnpJE8DDwM3A5cBnJF0+b7e/AK6MiI8AnwN2DHGsWemasPRwXQFz1OqiFGc929nypG6uBo5GxCsAkh4HNgIvzu0QEW/17H8BnJkLMvBYsyo0odc5agplFKNUF1WxzK6NJk+gnwRe63k8DVwzfydJnwIeAn4e+OQwx3aP3wxsBli9enWOZpnlV2cQzZI1XtDUgFnUevcpjaG0TZ5An7Ukxzk1mRHxTeCbkn4deBD4zbzHdo/fDmyHTnlljnZZQcbhP1hKQbTfoOtDt1zBQ7dc0cjfxajzDVy5U648gX4aWNXzeCVwrN/OEfFtSR+UdNGwx1r1xuU/WEp3WVpovOA7W25o1XXPy5U75coT6PcBl0haC8wAtwP/tHcHSR8C/iYiQtJVwFLgDeDEoGOtXm3+D5b1TaWoO0SNYtjxghS/cRXdpiaMoTTZwEAfEbOS7gX2ABPAoxFxWNI93ee3AbcCvyPpFHASuC06U24zjy3pXGwR2vofLOVvKsOMF6R4HmW0KbUxlLbJVUcfEbsj4h9FxAcj4qvdbdu6QZ6I+I8R8eGI+EhE/GpE/O+FjrV0tLU0LuVyymHq1lM8jzLalOL9CtrEq1eOubb+B0v5m8owdespnkcZbUrxfgVt4iUQxlxKg5RFSj0VkLdKJcXzyNumYfP4qd2voE0c6K2V/8FSKqecs5gBzBTPI0+bUhxbGGcO9NYIi+kdQjrfVBYb+FI7j7xtanM1VxN5PXrLpahyusW8Ttb67cuWTDQqh1vEmu9NsnbLU5kzIwW8uvWTGc/YqBZaj96DsTZQUSs/LvZ1Uqw8GVaKg6plams1V1M50NtARQXaxb5OG4LkuAW+tlZzNZUDvQ1UVKBd7Ou0IUiOW+BzuWRaPBhrAxVV4rfY1ymr8qSqpQXm3ufkqdNMSJyOqOXesFVrYzVXU7lHbwMV1Rtd7OuU0Tus6o5Tve8DcDrizDk7CFpV3KO3gYoq8RvldYruHVZV/ucyQ0uBA73lUlSgTeXrfFUDvG0YSE5Fiqt4NoVTNzaWqhrgbcNAcgqacHP3lDnQ21iqqgpm3KptytKGuRR1curGxlJVSwukuIRBEzkFNhoHehtbVY0XpDIu0WQpruLZJE7dmFnynAIbjXv0ZpY8p8BG40BvZo3gFNjiOXVjZtZyDvRmZi3nQG9m1nK5Ar2kmyS9JOmopC0Zz98h6YXuv2ckXdnz3JckHZb015L+m6R/UOQJmJnZwgYGekkTwMPAzcDlwGckXT5vt1eB6yJiHfAgsL177CTwL4GpiPhlYAK4vbjmm5nZIHl69FcDRyPilYh4B3gc2Ni7Q0Q8ExFvdh8+C6zsefo8YJmk84DzgWOjN9vMzPLKE+gngdd6Hk93t/VzF/A0QETMAP8J+CHwOvB3EfG/FtdUMzNbjDyBXhnbsm7wjqTr6QT6+7uPP0Cn978WuBi4QNJn+xy7WdJ+SfuPHz+ep+1mZpZDnkA/DazqebySjPSLpHXADmBjRLzR3fybwKsRcTwiTgFPAr+W9SYRsT0ipiJiasWKFcOcg5klaOfBGTZs3cvaLU+xYeteLylcozyBfh9wiaS1kpbSGUzd1buDpNV0gvidEfFyz1M/BD4m6XxJAn4DOFJM080sVV4/Pi0Dl0CIiFlJ9wJ76FTNPBoRhyXd031+G/AAcCHwSCeeM9vtnT8n6RvAd4FZ4CDdihyzNvHdj87mWyimJddaNxGxG9g9b9u2np/vBu7uc+xXgK+M0EazpM31XucC21zvFRjboOb149PimbFmIyrz7kdNzXP7FoppcaA3G1FZvdcm57m9fnxaHOht7I3aay6r99rk+6RuWj/JQ7dcweTyZQiYXL6Mh265YmxTWXXzevQ21orIr99346VnvQYU03ttep7b68enwz16G2tF9JrL6r06z21FcY/exlpRveYyeq9lfVOw8eMevY21lHvNznNbUdyjt7GWeq/ZeW4rggO9jbW5IOpZrdZmDvQ29txrtrZzjt7MrOUc6M3MWs6B3sys5ZyjN7OheVnmZnGgN7OheFnm5nHqxsyG0uTF1saVe/RmNpSmL7aWmirSYO7Rm9lQUl42ommquueAA72ZDcU3FSlOVWkwp27MKtCmKhUvG1GcqtJgDvRmJWtjlYqXjSjGxcuXMZMR1ItOgzl1Y1YyV6lYP1WlwdyjNyuZq1Ssn6rSYLkCvaSbgK8DE8COiNg67/k7gPu7D98CPh8Rz3efWw7sAH4ZCOBzEfFXxTTfLH1VfT23ZqoiDTYwdSNpAngYuBm4HPiMpMvn7fYqcF1ErAMeBLb3PPd14H9GxGXAlcCRIhpu1hSuUrG65enRXw0cjYhXACQ9DmwEXpzbISKe6dn/WWBld9/3Ab8O/LPufu8A7xTRcLOmcJWK1S1PoJ8EXut5PA1cs8D+dwFPd3/+JeA48F8kXQkcAL4QEW/PP0jSZmAzwOrVq3M0y6w5XKVidcpTdaOMbZG5o3Q9nUA/l68/D7gK+M8RsR54G9iSdWxEbI+IqYiYWrFiRY5mWdPsPDjDhq17WbvlKTZs3Vv47D8zy5Yn0E8Dq3oerwSOzd9J0jo6g64bI+KNnmOnI+K57uNv0An8NmaqmuptZufKE+j3AZdIWitpKXA7sKt3B0mrgSeBOyPi5bntEfF/gNckzY06/QY9uX0bH64lN6vPwBx9RMxKuhfYQ6e88tGIOCzpnu7z24AHgAuBRyQBzEbEVPclfhd4rPtH4hXgnxd/GpY615Kb1SdXHX1E7AZ2z9u2refnu4G7+xx7CJjKes7Gh2vJzerjJRCsEmXXknug16w/L4FglSizlryNi4aZFcmBvmRtWp52VGXVki800Duu19qslwN9idzTrIYHes0W5hx9iVxSWA3f2s5sYQ70JUqlp9n2gUovGma2MKduSpRCSeE4pI+8aJjZwhzoS3TfjZeeFWSh+p7muAxUetEws/4c6EuUQk8zlfRRHmVUKA16TVdF2ThwoC9Z3T3NFNJHeZSRYhr0muOQ1jIDD8a2XlMGKv/drsOFVygNqnpyVZSNC/foWy6F9NEgOw/OcOLkqcznRkkxDUpbNSmtZTYKB/oxUHf6aJCFetCjpJgGpa2aktYyG5VTN1a7hXrQvSmmYecDDEpbNSWtZTYqB3qrXb8e9AfOX3Lmm0jWHaq+9KeH+Lc7v9f3dTetn+ShW65gcvkyBEwuX8atH53ka3teYu2Wp/janpe4avX7mejcQ4EJiVs/mva3H7PFcOrGatdvvsFXfvvDZx5nDZwG8NizP2TqF/9h3+Dcm7bKqrLpTd2cjuCJAzMLvl5eLtu0lLhHb7XbtH6SWz86uWDPul96J1g4x98r64/FfEVU3fj+uJYaB3qr3c6DMzxxYIbTEcC7PevewLjQAGneKpmi9+vHZZuWGgd6q12ewHjfjZeiPsfnrZIper9+yirbbPvidFYeB3qrXZ7AuGn9JHd8bPU5wX6YKpmsKpv5iqi6KWPZZKeDbBQO9Fa7vIHxP2y6gj+87SNnVdE8dMsVuQc5s6pwPvux1Yt+vX7KKNt0OshG4aobW5Qiq0qGWeVz1MlfVUweK2M2smfx2igc6G1oRS8G1oRlGoZV9B8Uz+K1UeQK9JJuAr4OTAA7ImLrvOfvAO7vPnwL+HxEPN/z/ASwH5iJiN8qouFWnzyLhQ0bsFNfpqFuKdzbwJprYKDvBumHgU8A08A+Sbsi4sWe3V4FrouINyXdDGwHrul5/gvAEeB9hbXcatMvXTDXsx+3ZX+rmBzVxm89Vp08PfqrgaMR8QqApMeBjcCZQB8Rz/Ts/yywcu6BpJXAJ4GvAv+qgDZbzfqlEYCxuJtVryrXtPe3HlusPFU3k8BrPY+nu9v6uQt4uufxHwH/GvjZQm8iabOk/ZL2Hz9+PEezrC55yhR7NXHAMG/NuqthrAny9Oiz5qlE5o7S9XQC/bXdx78F/CgiDkj6+EJvEhHb6aR8mJqaynx9S0NvGqFfz75XVQOGRaVQhumluxrGmiBPj34aWNXzeCVwbP5OktYBO4CNEfFGd/MG4J9I+lvgceAGSf91pBZbEjatn+Q7W27oO1t1TlUDhkVOKBqml17G5CizouUJ9PuASyStlbQUuB3Y1buDpNXAk8CdEfHy3PaI+HJErIyINd3j9kbEZwtrvdVuoYBW1ASkPIpMoQzTS/ea9tYEA1M3ETEr6V5gD53yykcj4rCke7rPbwMeAC4EHlFnBcLZiJgqr9mWin5lf1UF+DlFplCGqVl3NYw1Qa46+ojYDeyet21bz893A3cPeI2/BP5y6BZa0lIJdEVOKMr64yXg+stWZO7vahhLnWfG2shSCHRFTijatH6S/T/4vzz27A/PVB0EFHZTErOqOdBbo/SrrCn6m8W3vn/8nNKyts8JsPZyoLfGGFT2WOQ3C5dNWpt4mWKr3GJvoFHl5CSXTVqbONBbpUapd6+yl11H2aTvIGVlcaC3So3SK6+yl511k5IyS0Z9BykrU2ty9FWsIGijG6VXXvVSvVVWEy30B9CfYxtVKwJ9lSsI2mhGqXdPpWa/DB78tTK1ItC7N9Qco/bKU6jZL4PvIGVlakWgd2+oOcrqlTc9dZfSHaSafi3tXK0I9O4NNUvRvfI2pO5SSUu14VrauVoR6FPqDVlHlb3CtqTuUkhLteVa2tlaEehT6Q1ZR9W9QqfuiuNr2U6tCPSQRm/IOsruFc7/tvD+ZUs4cfLUOfs1NXVXZ47cadB28oQpK1yZvcKsiUVvvzPLkvecfa+rhZYVLlLRs1nrnjjlG6m0kwO9Fa7MGaxZ3xZOnQ6Wnvees25rOLescJkBsoygXPfNxqueEWzVaE3qxtJR5uB4v28Fb79z+pxtZQ8ilpGiSiFH7jRo+zjQN0wTapzLHBzvl0PuZ5h9h1VGUHaO3MrgQN8gTapxLqtXmPVtYcmEOHV6/m1COkTnupXRljKCskuFrQzO0TdI3fnbFGTlkC9Y2r+/ElDa9Slj4NI5ciuDe/QNkkL+NgXzvy2s3fLUgvuXdX0WSlGNkmJzjtyK5kDfIM7fZhuUty/z+mQF5Sal2Gw85ErdSLpJ0kuSjkrakvH8HZJe6P57RtKV3e2rJH1L0hFJhyV9oegTGCeucc6WdV3m1HF9nGKz1Azs0UuaAB4GPgFMA/sk7YqIF3t2exW4LiLelHQzsB24BpgFfi8ivivp54ADkv583rGWk5d6yNZ7XWZOnGRC4nQEkzVdH6fYLDV5UjdXA0cj4hUASY8DG4EzwToinunZ/1lgZXf768Dr3Z//XtIRYLL3WBuO87fZUrouTrFZavKkbiaB13oeT3e39XMX8PT8jZLWAOuB5/I3z6x5nGKz1OTp0StjW2bRsqTr6QT6a+dtfy/wBPDFiPhJn2M3A5sBVq9enaNZZmlyis1SkyfQTwOreh6vBI7N30nSOmAHcHNEvNGzfQmdIP9YRDzZ700iYjud3D5TU1PZs1/MGiKlVJJZntTNPuASSWslLQVuB3b17iBpNfAkcGdEvNyzXcCfAEci4g+Ka7aZmeU1sEcfEbOS7gX2ABPAoxFxWNI93ee3AQ8AFwKPdGI7sxExBWwA7gS+J+lQ9yX/TUTsLv5UzMwsiyLSy5JMTU3F/v37626GmVljSDrQ7WCfwzNjbUFNWC3TzBbmQG99eSq/WTt49Urry1P5zdrBgd768lR+s3Zw6sb6Smkqv8cKzBbPPXrrK5Wp/GXchNtsnDjQW1+p3O3IYwVmo3HqxhaUwlR+jxWYjcaBvgDjkD+u8xxTGiswayKnbkY0Dvnjus8xlbECs6ZyoB/ROOSP6z7HVMYKzJrKqZsRjUP+OIVzTGGswKyp3KMfUb88cZvyx+NwjmZt5kA/onHIH4/DOZq1mVM3IxqH28aNwzmatZnXozczawGvR2/WNQ5zHszmc6C3seH19W1cOdDb2FhoPkBvoHev39rGgd7GRp75AO71Wxu5vLIkOw/OsGHrXtZueYoNW/e2akmEpsozH6DuWcBmZXCgL0Hda8NYtjzzAVKYBWxWNAf6ErhXmKY8a+Z4FrC1Ua4cvaSbgK8DE8COiNg67/k7gPu7D98CPh8Rz+c5to3cK6zOsAOng9bMue/GS8/K0YNnAVvzDQz0kiaAh4FPANPAPkm7IuLFnt1eBa6LiDcl3QxsB67JeWzreP304Sy2yqWMgVPPArY2ytOjvxo4GhGvAEh6HNgInAnWEfFMz/7PAivzHttG7hXmN0qwzlsuOSyvlGltkydHPwm81vN4urutn7uAp4c9VtJmSfsl7T9+/HiOZqXL66fnN8p4hlNkZvnk6dErY1vmAjmSrqcT6K8d9tiI2E4n5cPU1FR6C/AMyb3CfEYJ1k6RmeWTp0c/DazqebwSODZ/J0nrgB3Axoh4Y5hjbXyNUuXi5ZPN8skT6PcBl0haK2kpcDuwq3cHSauBJ4E7I+LlYY618TZKsG5risyT7axoA1M3ETEr6V5gD50SyUcj4rCke7rPbwMeAC4EHpEEMBsRU/2OLelcrIFGrXJpW4rMSzBYGbwevVlCNmzdmznuMLl8Gd/ZckMNLbKmWGg9es+MNUuIK4msDA70ZgnxEgxWBgd6s4S4ksjK4PXozRLiJRisDA70ZolpWyWR1c+pGzOzlnOgNzNrOQd6M7OWc6A3M2s5B3ozs5ZLcgkESceBH9TdjpwuAn5cdyMS4WvxLl+Ls/l6vKusa/GLEbEi64kkA32TSNrfb32JceNr8S5fi7P5eryrjmvh1I2ZWcs50JuZtZwD/ei2192AhPhavMvX4my+Hu+q/Fo4R29m1nLu0ZuZtZwDvZlZyznQ5yTpJkkvSToqaUvG85dJ+itJP5X0+3W0sSo5rsUdkl7o/ntG0pV1tLMKOa7Fxu51OCRpv6Rr62hnFQZdi579fkXSaUmfrrJ9Vcrxufi4pL/rfi4OSXqg1AZFhP8N+EfnxuZ/A/wSsBR4Hrh83j4/D/wK8FXg9+tuc83X4teAD3R/vhl4ru5213gt3su7Y2HrgO/X3e66rkXPfnuB3cCn6253jZ+LjwP/o6o2uUefz9XA0Yh4JSLeAR4HNvbuEBE/ioh9wKk6GlihPNfimYh4s/vwWWBlxW2sSp5r8VZ0/2cDFwBtrX4YeC26fhd4AvhRlY2rWN5rURkH+nwmgdd6Hk93t42jYa/FXcDTpbaoPrmuhaRPSfo+8BTwuYraVrWB10LSJPApYFuF7apD3v8jvyrpeUlPS/pwmQ1yoM9HGdva2jMbJPe1kHQ9nUB/f6ktqk+uaxER34yIy4BNwIOlt6oeea7FHwH3R8TpCtpTpzzX4rt01qa5EvhjYGeZDXKgz2caWNXzeCVwrKa21C3XtZC0DtgBbIyINypqW9WG+lxExLeBD0q6qOyG1SDPtZgCHpf0t8CngUckbaqmeZUaeC0i4icR8Vb3593AkjI/Fw70+ewDLpG0VtJS4HZgV81tqsvAayFpNfAkcGdEvFxDG6uS51p8SJK6P19FZ3CujX/4Bl6LiFgbEWsiYg3wDeBfRESpPdma5Plc/ELP5+JqOrG4tM+Fbw6eQ0TMSroX2ENnRP3RiDgs6Z7u89sk/QKwH3gf8DNJX6Qz0v6T2hpegjzXAngAuJBOjw1gNlq4cmHOa3Er8DuSTgEngdt6BmdbI+e1GAs5r8Wngc9LmqXzubi9zM+Fl0AwM2s5p27MzFrOgd7MrOUc6M3MWs6B3sys5RzozcxazoHezKzlHOjNzFru/wMUZUuhmE2Y5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs1a = GridSearchCV(estimator=model1a, param_grid=params_rf, cv=kf, n_jobs=-1)\n",
    "fit_model(gs1a, 'GS_RF_MSE')\n",
    "plt.scatter(y_test, gs1a.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>4.636245e-05</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>-0.165044</td>\n",
       "      <td>-0.093514</td>\n",
       "      <td>0.075694</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.238362</td>\n",
       "      <td>0.017492</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>4.097799e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.098932</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.081984</td>\n",
       "      <td>0.077227</td>\n",
       "      <td>0.141930</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.085595</td>\n",
       "      <td>0.039688</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>2.943788e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.093426</td>\n",
       "      <td>0.225962</td>\n",
       "      <td>0.034992</td>\n",
       "      <td>0.055843</td>\n",
       "      <td>0.131221</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024665</td>\n",
       "      <td>0.007318</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003069</td>\n",
       "      <td>-0.020747</td>\n",
       "      <td>-0.013209</td>\n",
       "      <td>-0.012342</td>\n",
       "      <td>0.007243</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156999</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>4.899036e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002852</td>\n",
       "      <td>-0.029152</td>\n",
       "      <td>-0.017122</td>\n",
       "      <td>-0.016375</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.492008</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.077667</td>\n",
       "      <td>4.716513e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>-0.028274</td>\n",
       "      <td>-0.017968</td>\n",
       "      <td>-0.016257</td>\n",
       "      <td>0.010580</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022333</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.706399e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>-0.012987</td>\n",
       "      <td>-0.030458</td>\n",
       "      <td>-0.014958</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.152666</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>7.370010e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>-0.023443</td>\n",
       "      <td>-0.010705</td>\n",
       "      <td>-0.012011</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.504343</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>2.160421e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002603</td>\n",
       "      <td>-0.028601</td>\n",
       "      <td>-0.018792</td>\n",
       "      <td>-0.016665</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.710332e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.005611</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>0.124509</td>\n",
       "      <td>0.074517</td>\n",
       "      <td>0.057236</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.192333</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>1.885594e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.036191</td>\n",
       "      <td>0.261654</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.098914</td>\n",
       "      <td>0.123155</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.930351</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.077689</td>\n",
       "      <td>7.553403e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.024176</td>\n",
       "      <td>0.222084</td>\n",
       "      <td>0.063614</td>\n",
       "      <td>0.087174</td>\n",
       "      <td>0.101906</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.017666</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>2.247832e-07</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.000798</td>\n",
       "      <td>-0.022656</td>\n",
       "      <td>-0.015705</td>\n",
       "      <td>-0.013053</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.147349</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>4.837077e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>-0.022975</td>\n",
       "      <td>-0.015514</td>\n",
       "      <td>-0.013863</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.494684</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>0.075689</td>\n",
       "      <td>1.691568e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.026739</td>\n",
       "      <td>-0.018592</td>\n",
       "      <td>-0.015959</td>\n",
       "      <td>0.010051</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.017967</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>4.714828e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.023064</td>\n",
       "      <td>-0.050040</td>\n",
       "      <td>-0.024443</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.152636</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.011030</td>\n",
       "      <td>8.535735e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.004142</td>\n",
       "      <td>-0.029610</td>\n",
       "      <td>-0.024725</td>\n",
       "      <td>-0.019493</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.496017</td>\n",
       "      <td>0.011215</td>\n",
       "      <td>0.078023</td>\n",
       "      <td>3.526058e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002100</td>\n",
       "      <td>-0.027734</td>\n",
       "      <td>-0.022039</td>\n",
       "      <td>-0.017291</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.020333</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.009724</td>\n",
       "      <td>0.146160</td>\n",
       "      <td>0.107602</td>\n",
       "      <td>0.081346</td>\n",
       "      <td>0.066292</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.172333</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>8.172161e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>0.051697</td>\n",
       "      <td>0.237657</td>\n",
       "      <td>0.048080</td>\n",
       "      <td>0.112478</td>\n",
       "      <td>0.088527</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.530897</td>\n",
       "      <td>0.230015</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>6.507467e-03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>0.032862</td>\n",
       "      <td>0.220133</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.128265</td>\n",
       "      <td>0.076494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>4.879901e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002267</td>\n",
       "      <td>-0.064142</td>\n",
       "      <td>-0.041625</td>\n",
       "      <td>-0.036011</td>\n",
       "      <td>0.025570</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.149666</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002226</td>\n",
       "      <td>-0.042206</td>\n",
       "      <td>-0.019550</td>\n",
       "      <td>-0.021327</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.294271</td>\n",
       "      <td>0.281726</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>1.715246e-02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002709</td>\n",
       "      <td>-0.030070</td>\n",
       "      <td>-0.021025</td>\n",
       "      <td>-0.017935</td>\n",
       "      <td>0.011382</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.017999</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.005947</td>\n",
       "      <td>-0.009645</td>\n",
       "      <td>-0.040907</td>\n",
       "      <td>-0.018833</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.148022</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>4.878670e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>-0.029612</td>\n",
       "      <td>-0.008359</td>\n",
       "      <td>-0.013111</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.067147</td>\n",
       "      <td>0.179502</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>1.243770e-03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003808</td>\n",
       "      <td>-0.028915</td>\n",
       "      <td>-0.020543</td>\n",
       "      <td>-0.017755</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.024330      0.000472         0.004033    4.636245e-05   \n",
       "1        0.238362      0.017492         0.010664    4.097799e-04   \n",
       "2        2.085595      0.039688         0.084000    2.943788e-03   \n",
       "3        0.024665      0.007318         0.003667    4.713142e-04   \n",
       "4        0.156999      0.004900         0.010000    4.899036e-07   \n",
       "5        1.492008      0.019828         0.077667    4.716513e-04   \n",
       "6        0.022333      0.004714         0.003334    4.706399e-04   \n",
       "7        0.152666      0.001886         0.010000    7.370010e-07   \n",
       "8        1.504343      0.003846         0.077000    2.160421e-03   \n",
       "9        0.022000      0.000816         0.003667    4.710332e-04   \n",
       "10       0.192333      0.005734         0.012333    1.885594e-03   \n",
       "11       1.930351      0.007376         0.077689    7.553403e-03   \n",
       "12       0.017666      0.000471         0.004001    2.247832e-07   \n",
       "13       0.147349      0.003376         0.010317    4.837077e-04   \n",
       "14       1.494684      0.007028         0.075689    1.691568e-03   \n",
       "15       0.017967      0.000046         0.003333    4.714828e-04   \n",
       "16       0.152636      0.001240         0.011030    8.535735e-04   \n",
       "17       1.496017      0.011215         0.078023    3.526058e-03   \n",
       "18       0.020333      0.000471         0.004000    2.973602e-07   \n",
       "19       0.172333      0.000943         0.011000    8.172161e-04   \n",
       "20       1.530897      0.230015         0.074366    6.507467e-03   \n",
       "21       0.018666      0.000471         0.003690    4.879901e-04   \n",
       "22       0.149666      0.003682         0.010666    4.713142e-04   \n",
       "23       1.294271      0.281726         0.061667    1.715246e-02   \n",
       "24       0.017999      0.000817         0.003334    4.714266e-04   \n",
       "25       0.148022      0.003765         0.010311    4.878670e-04   \n",
       "26       1.067147      0.179502         0.043652    1.243770e-03   \n",
       "\n",
       "   param_max_samples param_min_impurity_decrease param_n_estimators  \\\n",
       "0               None                           0                 10   \n",
       "1               None                           0                100   \n",
       "2               None                           0               1000   \n",
       "3               None                        0.05                 10   \n",
       "4               None                        0.05                100   \n",
       "5               None                        0.05               1000   \n",
       "6               None                         0.1                 10   \n",
       "7               None                         0.1                100   \n",
       "8               None                         0.1               1000   \n",
       "9               0.66                           0                 10   \n",
       "10              0.66                           0                100   \n",
       "11              0.66                           0               1000   \n",
       "12              0.66                        0.05                 10   \n",
       "13              0.66                        0.05                100   \n",
       "14              0.66                        0.05               1000   \n",
       "15              0.66                         0.1                 10   \n",
       "16              0.66                         0.1                100   \n",
       "17              0.66                         0.1               1000   \n",
       "18              0.33                           0                 10   \n",
       "19              0.33                           0                100   \n",
       "20              0.33                           0               1000   \n",
       "21              0.33                        0.05                 10   \n",
       "22              0.33                        0.05                100   \n",
       "23              0.33                        0.05               1000   \n",
       "24              0.33                         0.1                 10   \n",
       "25              0.33                         0.1                100   \n",
       "26              0.33                         0.1               1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_samples': None, 'min_impurity_decrease':...          -0.126718   \n",
       "1   {'max_samples': None, 'min_impurity_decrease':...          -0.098932   \n",
       "2   {'max_samples': None, 'min_impurity_decrease':...          -0.093426   \n",
       "3   {'max_samples': None, 'min_impurity_decrease':...          -0.003069   \n",
       "4   {'max_samples': None, 'min_impurity_decrease':...          -0.002852   \n",
       "5   {'max_samples': None, 'min_impurity_decrease':...          -0.002529   \n",
       "6   {'max_samples': None, 'min_impurity_decrease':...          -0.001431   \n",
       "7   {'max_samples': None, 'min_impurity_decrease':...          -0.001887   \n",
       "8   {'max_samples': None, 'min_impurity_decrease':...          -0.002603   \n",
       "9   {'max_samples': 0.66, 'min_impurity_decrease':...          -0.005611   \n",
       "10  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.036191   \n",
       "11  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.024176   \n",
       "12  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.000798   \n",
       "13  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.003098   \n",
       "14  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.002546   \n",
       "15  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.000225   \n",
       "16  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.004142   \n",
       "17  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.002100   \n",
       "18  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.009724   \n",
       "19  {'max_samples': 0.33, 'min_impurity_decrease':...           0.051697   \n",
       "20  {'max_samples': 0.33, 'min_impurity_decrease':...           0.032862   \n",
       "21  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002267   \n",
       "22  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002226   \n",
       "23  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002709   \n",
       "24  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.005947   \n",
       "25  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.001360   \n",
       "26  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.003808   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.011222          -0.165044        -0.093514        0.075694   \n",
       "1            0.248627           0.081984         0.077227        0.141930   \n",
       "2            0.225962           0.034992         0.055843        0.131221   \n",
       "3           -0.020747          -0.013209        -0.012342        0.007243   \n",
       "4           -0.029152          -0.017122        -0.016375        0.010750   \n",
       "5           -0.028274          -0.017968        -0.016257        0.010580   \n",
       "6           -0.012987          -0.030458        -0.014958        0.011932   \n",
       "7           -0.023443          -0.010705        -0.012011        0.008848   \n",
       "8           -0.028601          -0.018792        -0.016665        0.010720   \n",
       "9            0.104653           0.124509         0.074517        0.057236   \n",
       "10           0.261654           0.071281         0.098914        0.123155   \n",
       "11           0.222084           0.063614         0.087174        0.101906   \n",
       "12          -0.022656          -0.015705        -0.013053        0.009118   \n",
       "13          -0.022975          -0.015514        -0.013863        0.008198   \n",
       "14          -0.026739          -0.018592        -0.015959        0.010051   \n",
       "15          -0.023064          -0.050040        -0.024443        0.020360   \n",
       "16          -0.029610          -0.024725        -0.019493        0.011036   \n",
       "17          -0.027734          -0.022039        -0.017291        0.010990   \n",
       "18           0.146160           0.107602         0.081346        0.066292   \n",
       "19           0.237657           0.048080         0.112478        0.088527   \n",
       "20           0.220133           0.131800         0.128265        0.076494   \n",
       "21          -0.064142          -0.041625        -0.036011        0.025570   \n",
       "22          -0.042206          -0.019550        -0.021327        0.016370   \n",
       "23          -0.030070          -0.021025        -0.017935        0.011382   \n",
       "24          -0.009645          -0.040907        -0.018833        0.015682   \n",
       "25          -0.029612          -0.008359        -0.013111        0.012013   \n",
       "26          -0.028915          -0.020543        -0.017755        0.010437   \n",
       "\n",
       "    rank_test_score  \n",
       "0                27  \n",
       "1                 6  \n",
       "2                 8  \n",
       "3                10  \n",
       "4                17  \n",
       "5                16  \n",
       "6                14  \n",
       "7                 9  \n",
       "8                18  \n",
       "9                 7  \n",
       "10                3  \n",
       "11                4  \n",
       "12               11  \n",
       "13               13  \n",
       "14               15  \n",
       "15               25  \n",
       "16               23  \n",
       "17               19  \n",
       "18                5  \n",
       "19                2  \n",
       "20                1  \n",
       "21               26  \n",
       "22               24  \n",
       "23               21  \n",
       "24               22  \n",
       "25               12  \n",
       "26               20  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs1a.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.571840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.136357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.074127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.571840\n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.136357\n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.074127\n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056393"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1b = RandomForestRegressor(criterion='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs1b = GridSearchCV(estimator=model1b, param_grid=params_rf, cv=kf, n_jobs=-1)\n",
    "fit_model(gs1b, 'GS_RF_MAE')\n",
    "plt.scatter(y_test, gs1b.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065008</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>1.113358e-05</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.213348</td>\n",
       "      <td>0.037401</td>\n",
       "      <td>0.036258</td>\n",
       "      <td>-0.046563</td>\n",
       "      <td>0.117936</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.665662</td>\n",
       "      <td>0.042499</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>1.037099e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.172132</td>\n",
       "      <td>0.228532</td>\n",
       "      <td>0.062725</td>\n",
       "      <td>0.039708</td>\n",
       "      <td>0.164378</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.967332</td>\n",
       "      <td>0.200390</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>2.054540e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.160049</td>\n",
       "      <td>0.237320</td>\n",
       "      <td>0.052194</td>\n",
       "      <td>0.043155</td>\n",
       "      <td>0.162351</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027998</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>8.155614e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.001355</td>\n",
       "      <td>-0.043282</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>-0.015650</td>\n",
       "      <td>0.019542</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>2.356627e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>-0.043215</td>\n",
       "      <td>-0.005091</td>\n",
       "      <td>-0.016493</td>\n",
       "      <td>0.018963</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.341333</td>\n",
       "      <td>0.058094</td>\n",
       "      <td>0.079666</td>\n",
       "      <td>8.379509e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003364</td>\n",
       "      <td>-0.042616</td>\n",
       "      <td>-0.003740</td>\n",
       "      <td>-0.016574</td>\n",
       "      <td>0.018416</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.004192</td>\n",
       "      <td>-0.021806</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>-0.013847</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.014514</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>4.716513e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.004643</td>\n",
       "      <td>-0.043904</td>\n",
       "      <td>-0.003198</td>\n",
       "      <td>-0.017248</td>\n",
       "      <td>0.018858</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.278666</td>\n",
       "      <td>0.045390</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>1.633264e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003394</td>\n",
       "      <td>-0.038156</td>\n",
       "      <td>-0.003808</td>\n",
       "      <td>-0.015119</td>\n",
       "      <td>0.016291</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.050666</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.163514</td>\n",
       "      <td>0.181442</td>\n",
       "      <td>-0.142957</td>\n",
       "      <td>-0.041676</td>\n",
       "      <td>0.157992</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.485666</td>\n",
       "      <td>0.032355</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>1.247660e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.050890</td>\n",
       "      <td>0.209440</td>\n",
       "      <td>0.055288</td>\n",
       "      <td>0.071279</td>\n",
       "      <td>0.106879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.417666</td>\n",
       "      <td>0.281799</td>\n",
       "      <td>0.071334</td>\n",
       "      <td>1.369523e-02</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.081373</td>\n",
       "      <td>0.217316</td>\n",
       "      <td>0.114445</td>\n",
       "      <td>0.083463</td>\n",
       "      <td>0.123892</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.024667</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>1.247596e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.000740</td>\n",
       "      <td>-0.057254</td>\n",
       "      <td>-0.006354</td>\n",
       "      <td>-0.021449</td>\n",
       "      <td>0.025421</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.212333</td>\n",
       "      <td>0.019568</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>4.715951e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.004125</td>\n",
       "      <td>-0.048200</td>\n",
       "      <td>-0.003591</td>\n",
       "      <td>-0.018639</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.959333</td>\n",
       "      <td>0.021313</td>\n",
       "      <td>0.074999</td>\n",
       "      <td>5.887927e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003509</td>\n",
       "      <td>-0.040558</td>\n",
       "      <td>-0.003768</td>\n",
       "      <td>-0.015945</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.715392e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.034523</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.011596</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.207333</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>4.719888e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.005628</td>\n",
       "      <td>-0.039785</td>\n",
       "      <td>-0.003514</td>\n",
       "      <td>-0.016309</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.983334</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>0.070334</td>\n",
       "      <td>3.856939e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003081</td>\n",
       "      <td>-0.043313</td>\n",
       "      <td>-0.003229</td>\n",
       "      <td>-0.016541</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.714829e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.061931</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.121775</td>\n",
       "      <td>0.024117</td>\n",
       "      <td>0.075446</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.289999</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.005809</td>\n",
       "      <td>0.173323</td>\n",
       "      <td>0.131410</td>\n",
       "      <td>0.099641</td>\n",
       "      <td>0.076503</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.713667</td>\n",
       "      <td>0.257817</td>\n",
       "      <td>0.071332</td>\n",
       "      <td>1.506283e-02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.197076</td>\n",
       "      <td>0.135253</td>\n",
       "      <td>0.114785</td>\n",
       "      <td>0.076920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>9.431341e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.011844</td>\n",
       "      <td>-0.082713</td>\n",
       "      <td>-0.019908</td>\n",
       "      <td>-0.038155</td>\n",
       "      <td>0.031679</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.173666</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>4.708648e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>-0.044807</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>-0.017518</td>\n",
       "      <td>0.019297</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.693333</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.074334</td>\n",
       "      <td>2.624207e-03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>-0.045795</td>\n",
       "      <td>-0.002846</td>\n",
       "      <td>-0.017041</td>\n",
       "      <td>0.020333</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.020666</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.709208e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-0.022284</td>\n",
       "      <td>-0.030175</td>\n",
       "      <td>-0.024654</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.175001</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.001301</td>\n",
       "      <td>-0.039313</td>\n",
       "      <td>-0.013460</td>\n",
       "      <td>-0.018025</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.632999</td>\n",
       "      <td>0.053242</td>\n",
       "      <td>0.057666</td>\n",
       "      <td>1.087303e-02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003966</td>\n",
       "      <td>-0.048762</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>-0.018315</td>\n",
       "      <td>0.021541</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.065008      0.003554         0.003993    1.113358e-05   \n",
       "1        0.665662      0.042499         0.017333    1.037099e-02   \n",
       "2        5.967332      0.200390         0.078333    2.054540e-03   \n",
       "3        0.027998      0.002161         0.004000    8.155614e-04   \n",
       "4        0.248000      0.009416         0.011666    2.356627e-03   \n",
       "5        2.341333      0.058094         0.079666    8.379509e-03   \n",
       "6        0.026000      0.000816         0.003667    4.714266e-04   \n",
       "7        0.239000      0.014514         0.009333    4.716513e-04   \n",
       "8        2.278666      0.045390         0.077000    1.633264e-03   \n",
       "9        0.050666      0.001700         0.003001    4.052337e-07   \n",
       "10       0.485666      0.032355         0.011668    1.247660e-03   \n",
       "11       4.417666      0.281799         0.071334    1.369523e-02   \n",
       "12       0.024667      0.001699         0.005334    1.247596e-03   \n",
       "13       0.212333      0.019568         0.009333    4.715951e-04   \n",
       "14       1.959333      0.021313         0.074999    5.887927e-03   \n",
       "15       0.022667      0.000472         0.003667    4.715392e-04   \n",
       "16       0.207333      0.009030         0.009334    4.719888e-04   \n",
       "17       1.983334      0.037250         0.070334    3.856939e-03   \n",
       "18       0.032000      0.000817         0.003334    4.714829e-04   \n",
       "19       0.289999      0.006532         0.010001    2.973602e-07   \n",
       "20       2.713667      0.257817         0.071332    1.506283e-02   \n",
       "21       0.019334      0.002356         0.003333    9.431341e-04   \n",
       "22       0.173666      0.005249         0.009666    4.708648e-04   \n",
       "23       1.693333      0.007845         0.074334    2.624207e-03   \n",
       "24       0.020666      0.000471         0.003667    4.709208e-04   \n",
       "25       0.175001      0.002828         0.009999    4.052337e-07   \n",
       "26       1.632999      0.053242         0.057666    1.087303e-02   \n",
       "\n",
       "   param_max_samples param_min_impurity_decrease param_n_estimators  \\\n",
       "0               None                           0                 10   \n",
       "1               None                           0                100   \n",
       "2               None                           0               1000   \n",
       "3               None                        0.05                 10   \n",
       "4               None                        0.05                100   \n",
       "5               None                        0.05               1000   \n",
       "6               None                         0.1                 10   \n",
       "7               None                         0.1                100   \n",
       "8               None                         0.1               1000   \n",
       "9               0.66                           0                 10   \n",
       "10              0.66                           0                100   \n",
       "11              0.66                           0               1000   \n",
       "12              0.66                        0.05                 10   \n",
       "13              0.66                        0.05                100   \n",
       "14              0.66                        0.05               1000   \n",
       "15              0.66                         0.1                 10   \n",
       "16              0.66                         0.1                100   \n",
       "17              0.66                         0.1               1000   \n",
       "18              0.33                           0                 10   \n",
       "19              0.33                           0                100   \n",
       "20              0.33                           0               1000   \n",
       "21              0.33                        0.05                 10   \n",
       "22              0.33                        0.05                100   \n",
       "23              0.33                        0.05               1000   \n",
       "24              0.33                         0.1                 10   \n",
       "25              0.33                         0.1                100   \n",
       "26              0.33                         0.1               1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_samples': None, 'min_impurity_decrease':...          -0.213348   \n",
       "1   {'max_samples': None, 'min_impurity_decrease':...          -0.172132   \n",
       "2   {'max_samples': None, 'min_impurity_decrease':...          -0.160049   \n",
       "3   {'max_samples': None, 'min_impurity_decrease':...          -0.001355   \n",
       "4   {'max_samples': None, 'min_impurity_decrease':...          -0.001173   \n",
       "5   {'max_samples': None, 'min_impurity_decrease':...          -0.003364   \n",
       "6   {'max_samples': None, 'min_impurity_decrease':...          -0.004192   \n",
       "7   {'max_samples': None, 'min_impurity_decrease':...          -0.004643   \n",
       "8   {'max_samples': None, 'min_impurity_decrease':...          -0.003394   \n",
       "9   {'max_samples': 0.66, 'min_impurity_decrease':...          -0.163514   \n",
       "10  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.050890   \n",
       "11  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.081373   \n",
       "12  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.000740   \n",
       "13  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.004125   \n",
       "14  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.003509   \n",
       "15  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.000046   \n",
       "16  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.005628   \n",
       "17  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.003081   \n",
       "18  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.061931   \n",
       "19  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.005809   \n",
       "20  {'max_samples': 0.33, 'min_impurity_decrease':...           0.012026   \n",
       "21  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.011844   \n",
       "22  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.003704   \n",
       "23  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002482   \n",
       "24  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.021504   \n",
       "25  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.001301   \n",
       "26  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.003966   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.037401           0.036258        -0.046563        0.117936   \n",
       "1            0.228532           0.062725         0.039708        0.164378   \n",
       "2            0.237320           0.052194         0.043155        0.162351   \n",
       "3           -0.043282          -0.002315        -0.015650        0.019542   \n",
       "4           -0.043215          -0.005091        -0.016493        0.018963   \n",
       "5           -0.042616          -0.003740        -0.016574        0.018416   \n",
       "6           -0.021806          -0.015544        -0.013847        0.007291   \n",
       "7           -0.043904          -0.003198        -0.017248        0.018858   \n",
       "8           -0.038156          -0.003808        -0.015119        0.016291   \n",
       "9            0.181442          -0.142957        -0.041676        0.157992   \n",
       "10           0.209440           0.055288         0.071279        0.106879   \n",
       "11           0.217316           0.114445         0.083463        0.123892   \n",
       "12          -0.057254          -0.006354        -0.021449        0.025421   \n",
       "13          -0.048200          -0.003591        -0.018639        0.020904   \n",
       "14          -0.040558          -0.003768        -0.015945        0.017404   \n",
       "15          -0.034523          -0.000219        -0.011596        0.016212   \n",
       "16          -0.039785          -0.003514        -0.016309        0.016622   \n",
       "17          -0.043313          -0.003229        -0.016541        0.018931   \n",
       "18           0.012509           0.121775         0.024117        0.075446   \n",
       "19           0.173323           0.131410         0.099641        0.076503   \n",
       "20           0.197076           0.135253         0.114785        0.076920   \n",
       "21          -0.082713          -0.019908        -0.038155        0.031679   \n",
       "22          -0.044807          -0.004043        -0.017518        0.019297   \n",
       "23          -0.045795          -0.002846        -0.017041        0.020333   \n",
       "24          -0.022284          -0.030175        -0.024654        0.003916   \n",
       "25          -0.039313          -0.013460        -0.018025        0.015850   \n",
       "26          -0.048762          -0.002217        -0.018315        0.021541   \n",
       "\n",
       "    rank_test_score  \n",
       "0                27  \n",
       "1                 6  \n",
       "2                 5  \n",
       "3                11  \n",
       "4                14  \n",
       "5                16  \n",
       "6                 9  \n",
       "7                18  \n",
       "8                10  \n",
       "9                26  \n",
       "10                4  \n",
       "11                3  \n",
       "12               23  \n",
       "13               22  \n",
       "14               12  \n",
       "15                8  \n",
       "16               13  \n",
       "17               15  \n",
       "18                7  \n",
       "19                2  \n",
       "20                1  \n",
       "21               25  \n",
       "22               19  \n",
       "23               17  \n",
       "24               24  \n",
       "25               20  \n",
       "26               21  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs1b.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.573450</td>\n",
       "      <td>0.567534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.140765</td>\n",
       "      <td>0.136509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073938</td>\n",
       "      <td>0.074121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>0.055853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.573450   0.567534\n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.140765   0.136509\n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073938   0.074121\n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056469   0.055853"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like MSE and MAE is fairly close. Probably means that the MSE isn't being impacted as heavily by the outliers as I feared. So I think I can keep going with MSE as my criteron. Interestingly, in both cases, using a max_samples of 0.33 worked best. I'm thinking this may help with overfitting. Also, more estimators seem to help, not fewer. Playing with the impurity decrease did not help at all. I may do one more grid search looking at some more estimators and switch to max_depth instead of min_impurity_decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf2 = {\n",
    "    'n_estimators': [1000, 10_000],\n",
    "    'max_samples': [0.33, 0.15],\n",
    "    'max_depth': [5, 10, 20, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs1c = GridSearchCV(estimator=model1a, param_grid=params_rf2, cv=kf, n_jobs=-1)\n",
    "fit_model(gs1c, 'GS_RF_MSE2')\n",
    "plt.scatter(y_test, gs1c.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.683064</td>\n",
       "      <td>0.080427</td>\n",
       "      <td>0.079333</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'max_samples': 0.33, 'n_estim...</td>\n",
       "      <td>0.037540</td>\n",
       "      <td>0.215369</td>\n",
       "      <td>0.106799</td>\n",
       "      <td>0.119903</td>\n",
       "      <td>0.073187</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.285233</td>\n",
       "      <td>0.174932</td>\n",
       "      <td>0.828305</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 5, 'max_samples': 0.33, 'n_estim...</td>\n",
       "      <td>0.043569</td>\n",
       "      <td>0.219722</td>\n",
       "      <td>0.105707</td>\n",
       "      <td>0.122999</td>\n",
       "      <td>0.072946</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.664008</td>\n",
       "      <td>0.111968</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'max_samples': 0.15, 'n_estim...</td>\n",
       "      <td>0.090170</td>\n",
       "      <td>0.222548</td>\n",
       "      <td>0.108334</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.058593</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.410473</td>\n",
       "      <td>0.105528</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.010078</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 5, 'max_samples': 0.15, 'n_estim...</td>\n",
       "      <td>0.086952</td>\n",
       "      <td>0.206894</td>\n",
       "      <td>0.129827</td>\n",
       "      <td>0.141224</td>\n",
       "      <td>0.049625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.675178</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.082334</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>10</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.037689</td>\n",
       "      <td>0.227377</td>\n",
       "      <td>0.103355</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.335254</td>\n",
       "      <td>0.390880</td>\n",
       "      <td>0.861695</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>10</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 10, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.040260</td>\n",
       "      <td>0.223026</td>\n",
       "      <td>0.106566</td>\n",
       "      <td>0.123284</td>\n",
       "      <td>0.075544</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.545644</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.082864</td>\n",
       "      <td>0.206191</td>\n",
       "      <td>0.137802</td>\n",
       "      <td>0.142285</td>\n",
       "      <td>0.050448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.883687</td>\n",
       "      <td>0.113555</td>\n",
       "      <td>0.837038</td>\n",
       "      <td>0.028807</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 10, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.085499</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.118217</td>\n",
       "      <td>0.137021</td>\n",
       "      <td>0.051491</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.675349</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.081983</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 20, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.028549</td>\n",
       "      <td>0.227731</td>\n",
       "      <td>0.103410</td>\n",
       "      <td>0.119897</td>\n",
       "      <td>0.082147</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.848842</td>\n",
       "      <td>0.102360</td>\n",
       "      <td>0.882514</td>\n",
       "      <td>0.024128</td>\n",
       "      <td>20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 20, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.227932</td>\n",
       "      <td>0.103563</td>\n",
       "      <td>0.123454</td>\n",
       "      <td>0.078456</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.537801</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.082347</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 20, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.088401</td>\n",
       "      <td>0.192723</td>\n",
       "      <td>0.112692</td>\n",
       "      <td>0.131272</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.278051</td>\n",
       "      <td>0.039422</td>\n",
       "      <td>0.828344</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 20, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.085533</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.102547</td>\n",
       "      <td>0.132534</td>\n",
       "      <td>0.054881</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.809349</td>\n",
       "      <td>0.080519</td>\n",
       "      <td>0.088333</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.037329</td>\n",
       "      <td>0.219629</td>\n",
       "      <td>0.091528</td>\n",
       "      <td>0.116162</td>\n",
       "      <td>0.076435</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.817974</td>\n",
       "      <td>0.281470</td>\n",
       "      <td>0.646848</td>\n",
       "      <td>0.058197</td>\n",
       "      <td>50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 50, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.039002</td>\n",
       "      <td>0.226535</td>\n",
       "      <td>0.115050</td>\n",
       "      <td>0.126862</td>\n",
       "      <td>0.077014</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.578514</td>\n",
       "      <td>0.035547</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.087667</td>\n",
       "      <td>0.207227</td>\n",
       "      <td>0.110599</td>\n",
       "      <td>0.135165</td>\n",
       "      <td>0.051809</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.953077</td>\n",
       "      <td>0.224843</td>\n",
       "      <td>0.489738</td>\n",
       "      <td>0.018738</td>\n",
       "      <td>50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 50, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.087424</td>\n",
       "      <td>0.212166</td>\n",
       "      <td>0.116104</td>\n",
       "      <td>0.138565</td>\n",
       "      <td>0.053344</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.683064      0.080427         0.079333        0.002868   \n",
       "1       16.285233      0.174932         0.828305        0.015178   \n",
       "2        1.664008      0.111968         0.078000        0.001633   \n",
       "3       15.410473      0.105528         0.828667        0.010078   \n",
       "4        1.675178      0.014558         0.082334        0.000471   \n",
       "5       17.335254      0.390880         0.861695        0.015214   \n",
       "6        1.545644      0.016412         0.083334        0.002625   \n",
       "7       15.883687      0.113555         0.837038        0.028807   \n",
       "8        1.675349      0.008742         0.081983        0.002138   \n",
       "9       17.848842      0.102360         0.882514        0.024128   \n",
       "10       1.537801      0.004816         0.082347        0.001705   \n",
       "11      16.278051      0.039422         0.828344        0.008184   \n",
       "12       1.809349      0.080519         0.088333        0.004191   \n",
       "13      16.817974      0.281470         0.646848        0.058197   \n",
       "14       1.578514      0.035547         0.084000        0.002944   \n",
       "15      13.953077      0.224843         0.489738        0.018738   \n",
       "\n",
       "   param_max_depth param_max_samples param_n_estimators  \\\n",
       "0                5              0.33               1000   \n",
       "1                5              0.33              10000   \n",
       "2                5              0.15               1000   \n",
       "3                5              0.15              10000   \n",
       "4               10              0.33               1000   \n",
       "5               10              0.33              10000   \n",
       "6               10              0.15               1000   \n",
       "7               10              0.15              10000   \n",
       "8               20              0.33               1000   \n",
       "9               20              0.33              10000   \n",
       "10              20              0.15               1000   \n",
       "11              20              0.15              10000   \n",
       "12              50              0.33               1000   \n",
       "13              50              0.33              10000   \n",
       "14              50              0.15               1000   \n",
       "15              50              0.15              10000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_depth': 5, 'max_samples': 0.33, 'n_estim...           0.037540   \n",
       "1   {'max_depth': 5, 'max_samples': 0.33, 'n_estim...           0.043569   \n",
       "2   {'max_depth': 5, 'max_samples': 0.15, 'n_estim...           0.090170   \n",
       "3   {'max_depth': 5, 'max_samples': 0.15, 'n_estim...           0.086952   \n",
       "4   {'max_depth': 10, 'max_samples': 0.33, 'n_esti...           0.037689   \n",
       "5   {'max_depth': 10, 'max_samples': 0.33, 'n_esti...           0.040260   \n",
       "6   {'max_depth': 10, 'max_samples': 0.15, 'n_esti...           0.082864   \n",
       "7   {'max_depth': 10, 'max_samples': 0.15, 'n_esti...           0.085499   \n",
       "8   {'max_depth': 20, 'max_samples': 0.33, 'n_esti...           0.028549   \n",
       "9   {'max_depth': 20, 'max_samples': 0.33, 'n_esti...           0.038868   \n",
       "10  {'max_depth': 20, 'max_samples': 0.15, 'n_esti...           0.088401   \n",
       "11  {'max_depth': 20, 'max_samples': 0.15, 'n_esti...           0.085533   \n",
       "12  {'max_depth': 50, 'max_samples': 0.33, 'n_esti...           0.037329   \n",
       "13  {'max_depth': 50, 'max_samples': 0.33, 'n_esti...           0.039002   \n",
       "14  {'max_depth': 50, 'max_samples': 0.15, 'n_esti...           0.087667   \n",
       "15  {'max_depth': 50, 'max_samples': 0.15, 'n_esti...           0.087424   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.215369           0.106799         0.119903        0.073187   \n",
       "1            0.219722           0.105707         0.122999        0.072946   \n",
       "2            0.222548           0.108334         0.140351        0.058593   \n",
       "3            0.206894           0.129827         0.141224        0.049625   \n",
       "4            0.227377           0.103355         0.122807        0.078652   \n",
       "5            0.223026           0.106566         0.123284        0.075544   \n",
       "6            0.206191           0.137802         0.142285        0.050448   \n",
       "7            0.207347           0.118217         0.137021        0.051491   \n",
       "8            0.227731           0.103410         0.119897        0.082147   \n",
       "9            0.227932           0.103563         0.123454        0.078456   \n",
       "10           0.192723           0.112692         0.131272        0.044570   \n",
       "11           0.209524           0.102547         0.132534        0.054881   \n",
       "12           0.219629           0.091528         0.116162        0.076435   \n",
       "13           0.226535           0.115050         0.126862        0.077014   \n",
       "14           0.207227           0.110599         0.135165        0.051809   \n",
       "15           0.212166           0.116104         0.138565        0.053344   \n",
       "\n",
       "    rank_test_score  \n",
       "0                14  \n",
       "1                12  \n",
       "2                 3  \n",
       "3                 2  \n",
       "4                13  \n",
       "5                11  \n",
       "6                 1  \n",
       "7                 5  \n",
       "8                15  \n",
       "9                10  \n",
       "10                8  \n",
       "11                7  \n",
       "12               16  \n",
       "13                9  \n",
       "14                6  \n",
       "15                4  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs1c.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "      <th>GS_RF_MSE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.573450</td>\n",
       "      <td>0.567534</td>\n",
       "      <td>0.389442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.140765</td>\n",
       "      <td>0.136509</td>\n",
       "      <td>0.148589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073938</td>\n",
       "      <td>0.074121</td>\n",
       "      <td>0.073601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>0.055853</td>\n",
       "      <td>0.055006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE  \\\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.573450   0.567534   \n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.140765   0.136509   \n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073938   0.074121   \n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056469   0.055853   \n",
       "\n",
       "             GS_RF_MSE2  \n",
       "score_train    0.389442  \n",
       "score_test     0.148589  \n",
       "rmse           0.073601  \n",
       "mae            0.055006  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, so n_estimator truly seems best at 1000, however max_sample did even better at 0.15 which just seem crazy low. Max_depth did best at 10. However, I will say, most of these scores are really close to each other, unlike the previous gridsearch, so I think I'm reaching a capping point. I'm going to run a randomforest with my optimized parameters to see how it does on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11049907720373686"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1c = RandomForestRegressor(n_estimators= 1000, max_features=0.33, max_depth=10, random_state=8)\n",
    "fit_model(model1c, 'rfr_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "      <th>GS_RF_MSE2</th>\n",
       "      <th>rfr_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.573450</td>\n",
       "      <td>0.567534</td>\n",
       "      <td>0.389442</td>\n",
       "      <td>0.863646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.140765</td>\n",
       "      <td>0.136509</td>\n",
       "      <td>0.148589</td>\n",
       "      <td>0.110499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073938</td>\n",
       "      <td>0.074121</td>\n",
       "      <td>0.073601</td>\n",
       "      <td>0.075229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>0.055853</td>\n",
       "      <td>0.055006</td>\n",
       "      <td>0.057204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE  \\\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.573450   0.567534   \n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.140765   0.136509   \n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073938   0.074121   \n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056469   0.055853   \n",
       "\n",
       "             GS_RF_MSE2    rfr_op  \n",
       "score_train    0.389442  0.863646  \n",
       "score_test     0.148589  0.110499  \n",
       "rmse           0.073601  0.075229  \n",
       "mae            0.055006  0.057204  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "* **n_estimators**\n",
    "* **max_samples**\n",
    "* **max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = {}\n",
    "\n",
    "def fit_model(model, name):\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "    fit_results[name] = (score, rmse)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = DummyRegressor()\n",
    "fit_model(model0, 'dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21859654846224486"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LinearRegression(n_jobs=-1)\n",
    "fit_model(model1, 'plain_linreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13740517005245223"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RandomForestRegressor(n_jobs=-1, random_state=123)\n",
    "fit_model(model2, 'RFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25126471106226456"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = HistGradientBoostingRegressor(max_iter=10_000, random_state=123)\n",
    "fit_model(model3, 'GradBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15359534479323111"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = BaggingRegressor(n_jobs=-1, n_estimators=100, random_state=123)\n",
    "fit_model(model4, 'bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25126471106226456"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = make_pipeline(StandardScaler(), HistGradientBoostingRegressor(max_iter=10_000, random_state=123))\n",
    "fit_model(model5, 'GB_w_scaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22099629888522287"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = make_pipeline(StandardScaler(),Ridge())\n",
    "fit_model(model6, 'plain_ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.005464464679645564"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = make_pipeline(StandardScaler(),Lasso())\n",
    "fit_model(model7, 'lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
