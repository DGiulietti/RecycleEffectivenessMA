{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file\n",
    "df_for_regression = pd.read_csv('data/data_for_regression.csv', index_col='Municipality Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, BaggingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach:\n",
    "\n",
    "NEW ANALYTICS: \n",
    "* score of the TRAIN and test set\n",
    "* plot all the residuals between y_test and y_preds, not just looking at the averages in MAE and RMSE\n",
    "* Test all models with cv\n",
    "\n",
    "NEW MODELS:\n",
    "* Repeat ever model with outliers removed\n",
    "* Try a large test split\n",
    "* Emphasis on all models with bootstraping \n",
    "* Jeff kept suggest gradboost even though that one sucked\n",
    "* NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "\n",
    "X0 = df_for_regression.drop(columns=['%recycle/hh'])\n",
    "y0 = df_for_regression['%recycle/hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data w/o outliers\n",
    "df_for_regression1 = df_for_regression[df_for_regression['%recycle/hh'] < 0.5]\n",
    "X1 = df_for_regression1.drop(columns=['%recycle/hh'])\n",
    "y1 = df_for_regression1['%recycle/hh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First** just going to look at fast models, (no grad boost) and just the raw data. I found [this nifty way of seeing the test train splits in the KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  0   1   2   5   6   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  21  24  27  28  29  31  32  33  35  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  54  55  57  58  59  60  61  63  64  65  66\n",
      "  67  68  69  70  72  73  74  75  76  81  83  84  85  86  88  89  90  91\n",
      "  92  95  96  97  98  99 101 102 104 105 106 107 108 109 112 115 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136\n",
      " 137 138 140 141 142 143 144 145 146 147 149 150 151 152 153 154 155 156\n",
      " 157 159 160 161 162 164 166 167 168 169 170 171 172 173 174 175 176 179\n",
      " 181 183 184 186 188 189 190 191 194 195 196 197 199 200 201 202 203 205\n",
      " 206 207 208 210 211 213 214 215 216 217 218 220 223 224 225 226 227 228\n",
      " 229 231 234 235 236 237 238 239 240 241 242 243 245 246 247 248 249 250\n",
      " 251 252 253 254 255 257 258 259 261 262 263 264 265 266 267 268 269 270]\n",
      "TEST: [  3   4  13  22  23  25  26  30  34  52  53  56  62  71  77  78  79  80\n",
      "  82  87  93  94 100 103 110 111 113 114 116 139 148 158 163 165 177 178\n",
      " 180 182 185 187 192 193 198 204 209 212 219 221 222 230 232 233 244 256\n",
      " 260]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  2   3   4   6   7   8   9  10  11  13  14  15  16  18  19  20  21  22\n",
      "  23  24  25  26  28  29  30  31  32  34  35  36  37  38  40  41  43  44\n",
      "  46  47  48  49  51  52  53  54  56  58  59  60  61  62  63  64  66  67\n",
      "  68  70  71  73  74  75  77  78  79  80  81  82  83  85  86  87  89  91\n",
      "  93  94  95  97  98  99 100 101 102 103 104 105 106 107 108 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 130 131\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 147 148 150 152 154\n",
      " 155 156 158 159 160 161 162 163 164 165 166 167 169 170 171 173 174 175\n",
      " 177 178 179 180 181 182 183 184 185 187 188 190 191 192 193 194 195 196\n",
      " 198 199 200 203 204 205 207 209 210 211 212 213 214 216 217 219 220 221\n",
      " 222 223 224 229 230 231 232 233 235 237 238 239 242 243 244 245 246 247\n",
      " 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 264 266 267\n",
      " 270]\n",
      "TEST: [  0   1   5  12  17  27  33  39  42  45  50  55  57  65  69  72  76  84\n",
      "  88  90  92  96 109 129 132 146 149 151 153 157 168 172 176 186 189 197\n",
      " 201 202 206 208 215 218 225 226 227 228 234 236 240 241 263 265 268 269]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  12  13  15  16  17  18  19  20\n",
      "  21  22  23  25  26  27  28  30  31  33  34  36  37  38  39  42  43  45\n",
      "  46  47  48  50  51  52  53  54  55  56  57  58  59  61  62  63  64  65\n",
      "  66  69  71  72  73  74  75  76  77  78  79  80  81  82  84  85  86  87\n",
      "  88  90  91  92  93  94  95  96  98  99 100 102 103 104 105 107 108 109\n",
      " 110 111 112 113 114 115 116 118 119 120 122 123 124 125 126 129 132 133\n",
      " 134 135 136 137 138 139 142 143 144 146 147 148 149 151 152 153 155 156\n",
      " 157 158 160 161 163 165 166 167 168 170 172 173 174 176 177 178 180 182\n",
      " 183 184 185 186 187 188 189 191 192 193 194 196 197 198 199 200 201 202\n",
      " 203 204 206 207 208 209 210 212 213 215 216 217 218 219 220 221 222 223\n",
      " 224 225 226 227 228 229 230 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 248 249 250 251 253 254 256 257 259 260 261 263 265 267 268 269\n",
      " 270]\n",
      "TEST: [  8  10  14  24  29  32  35  40  41  44  49  60  67  68  70  83  89  97\n",
      " 101 106 117 121 127 128 130 131 140 141 145 150 154 159 162 164 169 171\n",
      " 175 179 181 190 195 205 211 214 231 245 246 247 252 255 258 262 264 266]\n",
      "CV_KF set:  3\n",
      "TRAIN: [  0   1   2   3   4   5   8   9  10  12  13  14  15  17  18  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  39  40  41\n",
      "  42  44  45  47  48  49  50  51  52  53  55  56  57  60  61  62  63  64\n",
      "  65  67  68  69  70  71  72  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  96  97 100 101 102 103 106 107 108 109\n",
      " 110 111 113 114 115 116 117 120 121 123 125 127 128 129 130 131 132 133\n",
      " 135 136 138 139 140 141 143 145 146 148 149 150 151 153 154 155 157 158\n",
      " 159 162 163 164 165 166 168 169 170 171 172 173 175 176 177 178 179 180\n",
      " 181 182 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200\n",
      " 201 202 204 205 206 208 209 211 212 214 215 217 218 219 220 221 222 223\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 240 241 242 244\n",
      " 245 246 247 248 249 251 252 255 256 258 259 260 262 263 264 265 266 268\n",
      " 269]\n",
      "TEST: [  6   7  11  16  19  38  43  46  54  58  59  66  73  74  75  95  98  99\n",
      " 104 105 112 118 119 122 124 126 134 137 142 144 147 152 156 160 161 167\n",
      " 174 183 184 203 207 210 213 216 224 239 243 250 253 254 257 261 267 270]\n",
      "CV_KF set:  4\n",
      "TRAIN: [  0   1   3   4   5   6   7   8  10  11  12  13  14  16  17  19  22  23\n",
      "  24  25  26  27  29  30  32  33  34  35  38  39  40  41  42  43  44  45\n",
      "  46  49  50  52  53  54  55  56  57  58  59  60  62  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  82  83  84  87  88  89  90\n",
      "  92  93  94  95  96  97  98  99 100 101 103 104 105 106 109 110 111 112\n",
      " 113 114 116 117 118 119 121 122 124 126 127 128 129 130 131 132 134 137\n",
      " 139 140 141 142 144 145 146 147 148 149 150 151 152 153 154 156 157 158\n",
      " 159 160 161 162 163 164 165 167 168 169 171 172 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 189 190 192 193 195 197 198 201 202 203\n",
      " 204 205 206 207 208 209 210 211 212 213 214 215 216 218 219 221 222 224\n",
      " 225 226 227 228 230 231 232 233 234 236 239 240 241 243 244 245 246 247\n",
      " 250 252 253 254 255 256 257 258 260 261 262 263 264 265 266 267 268 269\n",
      " 270]\n",
      "TEST: [  2   9  15  18  20  21  28  31  36  37  47  48  51  61  63  64  81  85\n",
      "  86  91 102 107 108 115 120 123 125 133 135 136 138 143 155 166 170 173\n",
      " 188 191 194 196 199 200 217 220 223 229 235 237 238 242 248 249 251 259]\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "cv_kf = KFold(n_splits=5, shuffle=True, random_state=8)\n",
    "\n",
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X0):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00262471, -0.01296429, -0.03149499, -0.03040279, -0.074853  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08579309, -0.42197651,  0.12508735, -0.01904092, -0.46782195])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02700948, -0.38914783,  0.13313634,  0.00084912, -0.44299328])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02981099,  0.02036987, -0.01632682, -0.04080895, -0.30929207])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03086535,  0.19833803,  0.11729076, -0.17294445,  0.21163409])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0169631 , -0.08887127,  0.04728323, -0.211642  ,  0.03888159])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.085793</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>0.029811</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>-0.016963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.012964</td>\n",
       "      <td>-0.421977</td>\n",
       "      <td>-0.389148</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>-0.088871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.031495</td>\n",
       "      <td>0.125087</td>\n",
       "      <td>0.133136</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.047283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold4</th>\n",
       "      <td>-0.030403</td>\n",
       "      <td>-0.019041</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>-0.040809</td>\n",
       "      <td>-0.172944</td>\n",
       "      <td>-0.211642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold5</th>\n",
       "      <td>-0.074853</td>\n",
       "      <td>-0.467822</td>\n",
       "      <td>-0.442993</td>\n",
       "      <td>-0.309292</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.038882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.030468</td>\n",
       "      <td>-0.173909</td>\n",
       "      <td>-0.145033</td>\n",
       "      <td>-0.063249</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>-0.046262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging\n",
       "Fold1   -0.002625 -0.085793 -0.027009  0.029811  0.030865   -0.016963\n",
       "Fold2   -0.012964 -0.421977 -0.389148  0.020370  0.198338   -0.088871\n",
       "Fold3   -0.031495  0.125087  0.133136 -0.016327  0.117291    0.047283\n",
       "Fold4   -0.030403 -0.019041  0.000849 -0.040809 -0.172944   -0.211642\n",
       "Fold5   -0.074853 -0.467822 -0.442993 -0.309292  0.211634    0.038882\n",
       "CV_mean -0.030468 -0.173909 -0.145033 -0.063249  0.077037   -0.046262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3','Fold4','Fold5','CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, looks like Random Forest did best. However, if I used the train test split in fold 3, I could potentially get away with using linear regressions. **Next**, let's look at the same models but on the data with no outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  0   1   2   5   6   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  21  24  27  28  29  31  32  33  35  36  37  38  39  40  41  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  57  58  59  60  61  63  64  65  66\n",
      "  67  68  70  71  72  73  74  75  76  79  81  83  85  86  88  89  90  91\n",
      "  93  95  97  98  99 100 101 102 104 105 106 107 108 112 113 114 115 118\n",
      " 119 120 121 122 123 124 125 126 127 129 130 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 146 147 148 150 151 152 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 170 171 173 174 177 178 179 180 181 182\n",
      " 183 184 185 188 190 191 192 193 194 195 196 199 200 201 202 203 204 205\n",
      " 206 208 209 211 212 213 214 215 216 217 219 220 221 222 223 224 225 226\n",
      " 227 228 229 230 231 232 233 234 235 236 237 240 241 242 243 244 245 248\n",
      " 249 250 251 252 254 255 256 257 258 260 262 263 264 265 266]\n",
      "TEST: [  3   4  13  22  23  25  26  30  34  42  55  56  62  69  77  78  80  82\n",
      "  84  87  92  94  96 103 109 110 111 116 117 128 131 132 145 149 153 169\n",
      " 172 175 176 186 187 189 197 198 207 210 218 238 239 246 247 253 259 261]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  2   3   4   6   7   8   9  10  11  13  14  15  16  18  19  20  21  22\n",
      "  23  24  25  26  28  29  30  31  32  34  35  36  37  38  40  41  42  43\n",
      "  44  46  47  48  49  50  51  52  53  54  55  56  58  59  60  61  62  63\n",
      "  64  66  67  68  69  70  71  73  74  75  77  78  80  81  82  83  84  85\n",
      "  86  87  91  92  93  94  95  96  97  98  99 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 115 116 117 118 119 120 122 123 124 125 126 127 128\n",
      " 130 131 132 133 134 135 136 137 138 142 143 144 145 147 148 149 150 152\n",
      " 153 154 155 156 160 162 163 165 166 167 168 169 170 172 173 174 175 176\n",
      " 179 180 181 183 184 185 186 187 188 189 190 191 192 194 196 197 198 199\n",
      " 200 202 203 205 207 208 210 211 215 216 217 218 219 220 221 223 227 228\n",
      " 229 230 231 232 233 234 235 236 237 238 239 240 241 243 244 245 246 247\n",
      " 249 250 251 252 253 254 255 257 258 259 260 261 262 263 266]\n",
      "TEST: [  0   1   5  12  17  27  33  39  45  57  65  72  76  79  88  89  90 100\n",
      " 113 114 121 129 139 140 141 146 151 157 158 159 161 164 171 177 178 182\n",
      " 193 195 201 204 206 209 212 213 214 222 224 225 226 242 248 256 264 265]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  30  31  33  34  36  37  38  39  42  43\n",
      "  45  46  47  48  51  53  54  55  56  57  58  59  61  62  63  64  65  66\n",
      "  69  71  72  73  75  76  77  78  79  80  81  82  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  98 100 102 103 104 105 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 128 129 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 145 146 147 149 151 152\n",
      " 153 154 155 156 157 158 159 160 161 164 166 167 169 170 171 172 173 174\n",
      " 175 176 177 178 181 182 183 184 185 186 187 188 189 191 192 193 194 195\n",
      " 196 197 198 199 200 201 202 204 206 207 209 210 212 213 214 215 218 220\n",
      " 222 224 225 226 227 228 229 232 233 235 237 238 239 240 241 242 243 244\n",
      " 245 246 247 248 249 251 253 254 256 257 259 261 263 264 265 266]\n",
      "TEST: [  8  10  24  29  32  35  40  41  44  49  50  52  60  67  68  70  74  83\n",
      "  97  99 101 106 127 130 144 148 150 162 163 165 168 179 180 190 203 205\n",
      " 208 211 216 217 219 221 223 230 231 234 236 250 252 255 258 260 262]\n",
      "CV_KF set:  3\n",
      "TRAIN: [  0   1   2   3   4   5   8   9  10  12  13  14  15  17  18  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  39  40  41  42\n",
      "  44  45  47  48  49  50  51  52  53  55  56  57  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  74  76  77  78  79  80  81  82  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  96  97  99 100 101 102 103 105\n",
      " 106 107 108 109 110 111 113 114 115 116 117 121 125 127 128 129 130 131\n",
      " 132 133 135 136 138 139 140 141 143 144 145 146 148 149 150 151 153 154\n",
      " 155 157 158 159 161 162 163 164 165 166 168 169 170 171 172 173 175 176\n",
      " 177 178 179 180 181 182 184 186 187 189 190 191 193 195 196 197 198 199\n",
      " 200 201 203 204 205 206 207 208 209 210 211 212 213 214 216 217 218 219\n",
      " 220 221 222 223 224 225 226 227 229 230 231 233 234 236 238 239 242 246\n",
      " 247 248 250 251 252 253 254 255 256 258 259 260 261 262 264 265]\n",
      "TEST: [  6   7  11  16  19  37  38  43  46  54  58  73  75  95  98 104 112 118\n",
      " 119 120 122 123 124 126 134 137 142 147 152 156 160 167 174 183 185 188\n",
      " 192 194 202 215 228 232 235 237 240 241 243 244 245 249 257 263 266]\n",
      "CV_KF set:  4\n",
      "TRAIN: [  0   1   3   4   5   6   7   8  10  11  12  13  16  17  19  22  23  24\n",
      "  25  26  27  29  30  32  33  34  35  37  38  39  40  41  42  43  44  45\n",
      "  46  49  50  52  54  55  56  57  58  60  62  65  67  68  69  70  72  73\n",
      "  74  75  76  77  78  79  80  82  83  84  87  88  89  90  92  94  95  96\n",
      "  97  98  99 100 101 103 104 106 109 110 111 112 113 114 116 117 118 119\n",
      " 120 121 122 123 124 126 127 128 129 130 131 132 134 137 139 140 141 142\n",
      " 144 145 146 147 148 149 150 151 152 153 156 157 158 159 160 161 162 163\n",
      " 164 165 167 168 169 171 172 174 175 176 177 178 179 180 182 183 185 186\n",
      " 187 188 189 190 192 193 194 195 197 198 201 202 203 204 205 206 207 208\n",
      " 209 210 211 212 213 214 215 216 217 218 219 221 222 223 224 225 226 228\n",
      " 230 231 232 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248\n",
      " 249 250 252 253 255 256 257 258 259 260 261 262 263 264 265 266]\n",
      "TEST: [  2   9  14  15  18  20  21  28  31  36  47  48  51  53  59  61  63  64\n",
      "  66  71  81  85  86  91  93 102 105 107 108 115 125 133 135 136 138 143\n",
      " 154 155 166 170 173 181 184 191 196 199 200 220 227 229 233 251 254]\n"
     ]
    }
   ],
   "source": [
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X1):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05338701, -0.03622173, -0.07998282, -0.00190992, -0.00161515])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11681536, -0.02302504, -0.60246096,  0.14584508,  0.16238194])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2425074 ,  0.00398809, -0.63989767,  0.19700119,  0.18435423])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03725743, -0.00609516, -0.42253981,  0.02625488,  0.00080746])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2165107 , 0.14495103, 0.09073038, 0.30272136, 0.23477095])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32835449, 0.08558503, 0.06803691, 0.34382283, 0.18444288])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X1, y1, cv=cv_kf)\n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "      <th>X1_dummy</th>\n",
       "      <th>X1_lr</th>\n",
       "      <th>X1_ridge</th>\n",
       "      <th>X1_lasso</th>\n",
       "      <th>X1_RF</th>\n",
       "      <th>X1_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.085793</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>0.029811</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>-0.016963</td>\n",
       "      <td>-0.053387</td>\n",
       "      <td>0.116815</td>\n",
       "      <td>0.242507</td>\n",
       "      <td>-0.037257</td>\n",
       "      <td>0.216511</td>\n",
       "      <td>0.328354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.012964</td>\n",
       "      <td>-0.421977</td>\n",
       "      <td>-0.389148</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>-0.088871</td>\n",
       "      <td>-0.036222</td>\n",
       "      <td>-0.023025</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>0.144951</td>\n",
       "      <td>0.085585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.031495</td>\n",
       "      <td>0.125087</td>\n",
       "      <td>0.133136</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.047283</td>\n",
       "      <td>-0.079983</td>\n",
       "      <td>-0.602461</td>\n",
       "      <td>-0.639898</td>\n",
       "      <td>-0.422540</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold4</th>\n",
       "      <td>-0.030403</td>\n",
       "      <td>-0.019041</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>-0.040809</td>\n",
       "      <td>-0.172944</td>\n",
       "      <td>-0.211642</td>\n",
       "      <td>-0.001910</td>\n",
       "      <td>0.145845</td>\n",
       "      <td>0.197001</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.302721</td>\n",
       "      <td>0.343823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold5</th>\n",
       "      <td>-0.074853</td>\n",
       "      <td>-0.467822</td>\n",
       "      <td>-0.442993</td>\n",
       "      <td>-0.309292</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>-0.001615</td>\n",
       "      <td>0.162382</td>\n",
       "      <td>0.184354</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.234771</td>\n",
       "      <td>0.184443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.030468</td>\n",
       "      <td>-0.173909</td>\n",
       "      <td>-0.145033</td>\n",
       "      <td>-0.063249</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>-0.046262</td>\n",
       "      <td>-0.034623</td>\n",
       "      <td>-0.040089</td>\n",
       "      <td>-0.002409</td>\n",
       "      <td>-0.087766</td>\n",
       "      <td>0.197937</td>\n",
       "      <td>0.202048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging  \\\n",
       "Fold1   -0.002625 -0.085793 -0.027009  0.029811  0.030865   -0.016963   \n",
       "Fold2   -0.012964 -0.421977 -0.389148  0.020370  0.198338   -0.088871   \n",
       "Fold3   -0.031495  0.125087  0.133136 -0.016327  0.117291    0.047283   \n",
       "Fold4   -0.030403 -0.019041  0.000849 -0.040809 -0.172944   -0.211642   \n",
       "Fold5   -0.074853 -0.467822 -0.442993 -0.309292  0.211634    0.038882   \n",
       "CV_mean -0.030468 -0.173909 -0.145033 -0.063249  0.077037   -0.046262   \n",
       "\n",
       "         X1_dummy     X1_lr  X1_ridge  X1_lasso     X1_RF  X1_bagging  \n",
       "Fold1   -0.053387  0.116815  0.242507 -0.037257  0.216511    0.328354  \n",
       "Fold2   -0.036222 -0.023025  0.003988 -0.006095  0.144951    0.085585  \n",
       "Fold3   -0.079983 -0.602461 -0.639898 -0.422540  0.090730    0.068037  \n",
       "Fold4   -0.001910  0.145845  0.197001  0.026255  0.302721    0.343823  \n",
       "Fold5   -0.001615  0.162382  0.184354  0.000807  0.234771    0.184443  \n",
       "CV_mean -0.034623 -0.040089 -0.002409 -0.087766  0.197937    0.202048  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3','Fold4','Fold5','CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, everything does seem to improve when removing the outliers. Looks like the non-linear regression based models still faired best but the set from fold 4 performed well across all models. The outliers, however, are in the positive direction: higher recyclers. So if I do go with a model with the outliers removed, I still need to go back and see what is unique about those outliers; I shouldn't just throw them out and forget about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:Train Ratio\n",
    "\n",
    "I can kinda of informally see how the dataset does with a higher test ratio by changing the n_split during the cross validation. Above, I used the default of 5, however, this only leaves us with 54 test points. We may increase our odds of success by increasing this quantity so I'll change the n_split to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  2   6   7   8   9  10  11  12  14  15  16  18  19  20  21  24  27  28\n",
      "  29  31  32  35  36  37  38  40  41  43  44  46  47  48  49  50  51  54\n",
      "  58  59  60  61  63  64  66  67  68  70  73  74  75  76  81  83  85  86\n",
      "  89  90  91  92  95  97  98  99 101 102 104 105 106 107 108 112 115 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 130 131 132 133 134 135 136\n",
      " 137 138 140 141 142 143 144 145 147 150 152 153 154 155 156 159 160 161\n",
      " 162 164 166 167 168 169 170 171 173 174 175 176 179 181 183 184 188 190\n",
      " 191 194 195 196 199 200 201 203 205 206 207 210 211 213 214 216 217 220\n",
      " 223 224 225 226 228 229 231 234 235 236 237 238 239 242 243 245 246 247\n",
      " 248 249 250 251 252 253 254 255 257 258 259 261 262 264 266 267 269 270]\n",
      "TEST: [  0   1   3   4   5  13  17  22  23  25  26  30  33  34  39  42  45  52\n",
      "  53  55  56  57  62  65  69  71  72  77  78  79  80  82  84  87  88  93\n",
      "  94  96 100 103 109 110 111 113 114 116 129 139 146 148 149 151 157 158\n",
      " 163 165 172 177 178 180 182 185 186 187 189 192 193 197 198 202 204 208\n",
      " 209 212 215 218 219 221 222 227 230 232 233 240 241 244 256 260 263 265\n",
      " 268]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  11  13  15  16  17  18  19  20  21\n",
      "  22  23  25  26  28  30  31  33  34  36  37  38  39  42  45  46  47  48\n",
      "  51  52  53  54  55  56  57  59  61  62  63  64  65  66  69  71  72  73\n",
      "  75  77  78  79  80  81  82  84  85  86  87  88  91  93  94  95  96  98\n",
      " 100 102 103 105 107 108 109 110 111 112 113 114 115 116 118 120 122 123\n",
      " 125 126 129 133 134 135 136 137 138 139 143 146 147 148 149 151 152 155\n",
      " 156 157 158 160 163 165 166 167 170 172 173 174 177 178 180 182 183 185\n",
      " 186 187 188 189 191 192 193 194 196 197 198 199 200 202 203 204 208 209\n",
      " 210 212 215 216 217 218 219 220 221 222 223 224 227 229 230 232 233 235\n",
      " 237 238 240 241 242 243 244 248 249 251 256 257 259 260 263 265 267 268\n",
      " 270]\n",
      "TEST: [  8  10  12  14  24  27  29  32  35  40  41  43  44  49  50  58  60  67\n",
      "  68  70  74  76  83  89  90  92  97  99 101 104 106 117 119 121 124 127\n",
      " 128 130 131 132 140 141 142 144 145 150 153 154 159 161 162 164 168 169\n",
      " 171 175 176 179 181 184 190 195 201 205 206 207 211 213 214 225 226 228\n",
      " 231 234 236 239 245 246 247 250 252 253 254 255 258 261 262 264 266 269]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   3   4   5   8  10  12  13  14  17  22  23  24  25  26  27  29\n",
      "  30  32  33  34  35  39  40  41  42  43  44  45  49  50  52  53  55  56\n",
      "  57  58  60  62  65  67  68  69  70  71  72  74  76  77  78  79  80  82\n",
      "  83  84  87  88  89  90  92  93  94  96  97  99 100 101 103 104 106 109\n",
      " 110 111 113 114 116 117 119 121 124 127 128 129 130 131 132 139 140 141\n",
      " 142 144 145 146 148 149 150 151 153 154 157 158 159 161 162 163 164 165\n",
      " 168 169 171 172 175 176 177 178 179 180 181 182 184 185 186 187 189 190\n",
      " 192 193 195 197 198 201 202 204 205 206 207 208 209 211 212 213 214 215\n",
      " 218 219 221 222 225 226 227 228 230 231 232 233 234 236 239 240 241 244\n",
      " 245 246 247 250 252 253 254 255 256 258 260 261 262 263 264 265 266 268\n",
      " 269]\n",
      "TEST: [  2   6   7   9  11  15  16  18  19  20  21  28  31  36  37  38  46  47\n",
      "  48  51  54  59  61  63  64  66  73  75  81  85  86  91  95  98 102 105\n",
      " 107 108 112 115 118 120 122 123 125 126 133 134 135 136 137 138 143 147\n",
      " 152 155 156 160 166 167 170 173 174 183 188 191 194 196 199 200 203 210\n",
      " 216 217 220 223 224 229 235 237 238 242 243 248 249 251 257 259 267 270]\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "cv_kf = KFold(n_splits=3, shuffle=True, random_state=8)\n",
    "\n",
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X0):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01458113, -0.01553683, -0.09007735])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08721139,  0.15905641, -0.75862946])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01603247,  0.16700945, -0.74216146])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01745458,  0.00209897, -0.74093297])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11768537, 0.2370164 , 0.11437933])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04694505,  0.11108638,  0.03541457])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X0, y0, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X0_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_KF set:  0\n",
      "TRAIN: [  2   6   7   8   9  10  11  12  14  15  16  18  19  20  21  24  27  28\n",
      "  29  31  32  35  36  37  38  40  41  43  44  46  47  48  49  50  51  52\n",
      "  53  54  58  59  60  61  63  64  66  67  68  70  71  73  74  75  76  81\n",
      "  83  85  86  89  90  91  93  95  97  98  99 101 102 104 105 106 107 108\n",
      " 112 114 115 118 119 120 122 123 124 125 126 127 129 130 133 134 135 136\n",
      " 137 138 140 142 143 144 147 148 150 152 154 155 156 158 159 160 162 163\n",
      " 165 166 167 168 170 173 174 177 178 179 180 181 182 183 184 185 188 190\n",
      " 191 192 194 195 196 199 200 202 203 205 208 209 211 213 215 216 217 219\n",
      " 220 221 223 225 227 228 229 230 231 232 233 234 235 236 237 240 241 243\n",
      " 244 245 249 250 251 252 254 255 257 258 260 262 263 264 265 266]\n",
      "TEST: [  0   1   3   4   5  13  17  22  23  25  26  30  33  34  39  42  45  55\n",
      "  56  57  62  65  69  72  77  78  79  80  82  84  87  88  92  94  96 100\n",
      " 103 109 110 111 113 116 117 121 128 131 132 139 141 145 146 149 151 153\n",
      " 157 161 164 169 171 172 175 176 186 187 189 193 197 198 201 204 206 207\n",
      " 210 212 214 218 222 224 226 238 239 242 246 247 248 253 256 259 261]\n",
      "CV_KF set:  1\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  13  14  15  16  17  18  19  20  21\n",
      "  22  23  25  26  28  30  31  33  34  36  37  38  39  42  45  46  47  48\n",
      "  51  53  54  55  56  57  59  61  62  63  64  65  66  69  71  72  73  77\n",
      "  78  79  80  81  82  84  85  86  87  88  91  92  93  94  95  96  98 100\n",
      " 102 103 105 107 108 109 110 111 112 113 115 116 117 118 120 121 122 123\n",
      " 125 126 128 131 132 133 134 135 136 137 138 139 141 143 145 146 149 151\n",
      " 152 153 154 155 157 160 161 164 166 167 169 170 171 172 173 175 176 181\n",
      " 183 184 186 187 188 189 191 192 193 194 196 197 198 199 200 201 204 206\n",
      " 207 210 212 214 215 218 220 222 224 226 227 228 229 232 233 235 238 239\n",
      " 240 242 243 244 245 246 247 248 249 251 253 254 256 259 261 263]\n",
      "TEST: [  8  10  11  12  24  27  29  32  35  40  41  43  44  49  50  52  58  60\n",
      "  67  68  70  74  75  76  83  89  90  97  99 101 104 106 114 119 124 127\n",
      " 129 130 140 142 144 147 148 150 156 158 159 162 163 165 168 174 177 178\n",
      " 179 180 182 185 190 195 202 203 205 208 209 211 213 216 217 219 221 223\n",
      " 225 230 231 234 236 237 241 250 252 255 257 258 260 262 264 265 266]\n",
      "CV_KF set:  2\n",
      "TRAIN: [  0   1   3   4   5   8  10  11  12  13  17  22  23  24  25  26  27  29\n",
      "  30  32  33  34  35  39  40  41  42  43  44  45  49  50  52  55  56  57\n",
      "  58  60  62  65  67  68  69  70  72  74  75  76  77  78  79  80  82  83\n",
      "  84  87  88  89  90  92  94  96  97  99 100 101 103 104 106 109 110 111\n",
      " 113 114 116 117 119 121 124 127 128 129 130 131 132 139 140 141 142 144\n",
      " 145 146 147 148 149 150 151 153 156 157 158 159 161 162 163 164 165 168\n",
      " 169 171 172 174 175 176 177 178 179 180 182 185 186 187 189 190 193 195\n",
      " 197 198 201 202 203 204 205 206 207 208 209 210 211 212 213 214 216 217\n",
      " 218 219 221 222 223 224 225 226 230 231 234 236 237 238 239 241 242 246\n",
      " 247 248 250 252 253 255 256 257 258 259 260 261 262 264 265 266]\n",
      "TEST: [  2   6   7   9  14  15  16  18  19  20  21  28  31  36  37  38  46  47\n",
      "  48  51  53  54  59  61  63  64  66  71  73  81  85  86  91  93  95  98\n",
      " 102 105 107 108 112 115 118 120 122 123 125 126 133 134 135 136 137 138\n",
      " 143 152 154 155 160 166 167 170 173 181 183 184 188 191 192 194 196 199\n",
      " 200 215 220 227 228 229 232 233 235 240 243 244 245 249 251 254 263]\n"
     ]
    }
   ],
   "source": [
    "cv_set = 0\n",
    "for train_index, test_index in cv_kf.split(X1):\n",
    "    print(\"CV_KF set: \", cv_set)\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    cv_set = cv_set + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08957878, -0.1209515 , -0.01201351])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(DummyRegressor(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_dummy'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01517724, -0.38834619,  0.10209835])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(LinearRegression(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lr'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08972173, -0.38117819,  0.16464953])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_ridge'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06988468, -0.23457381,  0.00298756])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(Lasso(), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_lasso'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19785585, 0.00528953, 0.20736793])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestRegressor(random_state=8), X1, y1, cv=cv_kf) \n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_RF'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16058833, -0.06794259,  0.13272154])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(BaggingRegressor(random_state=8), X1, y1, cv=cv_kf)\n",
    "cv_mean = cv.mean()\n",
    "cv_results['X1_bagging'] = np.append(cv,cv_mean)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0_dummy</th>\n",
       "      <th>X0_lr</th>\n",
       "      <th>X0_ridge</th>\n",
       "      <th>X0_lasso</th>\n",
       "      <th>X0_RF</th>\n",
       "      <th>X0_bagging</th>\n",
       "      <th>X1_dummy</th>\n",
       "      <th>X1_lr</th>\n",
       "      <th>X1_ridge</th>\n",
       "      <th>X1_lasso</th>\n",
       "      <th>X1_RF</th>\n",
       "      <th>X1_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold1</th>\n",
       "      <td>-0.014581</td>\n",
       "      <td>-0.087211</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>0.117685</td>\n",
       "      <td>-0.046945</td>\n",
       "      <td>-0.089579</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.089722</td>\n",
       "      <td>-0.069885</td>\n",
       "      <td>0.197856</td>\n",
       "      <td>0.160588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold2</th>\n",
       "      <td>-0.015537</td>\n",
       "      <td>0.159056</td>\n",
       "      <td>0.167009</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.237016</td>\n",
       "      <td>0.111086</td>\n",
       "      <td>-0.120952</td>\n",
       "      <td>-0.388346</td>\n",
       "      <td>-0.381178</td>\n",
       "      <td>-0.234574</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>-0.067943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold3</th>\n",
       "      <td>-0.090077</td>\n",
       "      <td>-0.758629</td>\n",
       "      <td>-0.742161</td>\n",
       "      <td>-0.740933</td>\n",
       "      <td>0.114379</td>\n",
       "      <td>0.035415</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>0.102098</td>\n",
       "      <td>0.164650</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.207368</td>\n",
       "      <td>0.132722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_mean</th>\n",
       "      <td>-0.040065</td>\n",
       "      <td>-0.228928</td>\n",
       "      <td>-0.197061</td>\n",
       "      <td>-0.240460</td>\n",
       "      <td>0.156360</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>-0.074181</td>\n",
       "      <td>-0.090357</td>\n",
       "      <td>-0.042269</td>\n",
       "      <td>-0.100490</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>0.075122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0_dummy     X0_lr  X0_ridge  X0_lasso     X0_RF  X0_bagging  \\\n",
       "Fold1   -0.014581 -0.087211 -0.016032  0.017455  0.117685   -0.046945   \n",
       "Fold2   -0.015537  0.159056  0.167009  0.002099  0.237016    0.111086   \n",
       "Fold3   -0.090077 -0.758629 -0.742161 -0.740933  0.114379    0.035415   \n",
       "CV_mean -0.040065 -0.228928 -0.197061 -0.240460  0.156360    0.033185   \n",
       "\n",
       "         X1_dummy     X1_lr  X1_ridge  X1_lasso     X1_RF  X1_bagging  \n",
       "Fold1   -0.089579  0.015177  0.089722 -0.069885  0.197856    0.160588  \n",
       "Fold2   -0.120952 -0.388346 -0.381178 -0.234574  0.005290   -0.067943  \n",
       "Fold3   -0.012014  0.102098  0.164650  0.002988  0.207368    0.132722  \n",
       "CV_mean -0.074181 -0.090357 -0.042269 -0.100490  0.136838    0.075122  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index = ['Fold1','Fold2','Fold3', 'CV_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the averages definitely seem better. It does mean I've only tested 3 configurations rather than 5 but RF consistently is positive and bagging does fairly well. It also seems like the difference between the data with the outliers and without the outliers has fewer differences in fit. It seems like increasing the test_split will be helpful.\n",
    "\n",
    "---\n",
    "\n",
    "### Take Aways\n",
    "\n",
    "There probably is no linear relationship between my dependent variable and the rest of the dataset; this means that tree-based regressors will fair much better *consistently*. This intuitively makes sense to me because I have so many binary features that this inheriently lends itself better to decision trees, not so much for linear regression. This also gives me more hope that a neural network may fair well (more on that later).\n",
    "\n",
    "I think moving forward, I'm going to do the normal train_test_split method, including the outliers for now, but with a test_split = 0.34 and I will only look at models based on decision trees. I am especially interested in models that support bootstrapping since my dataset isn't huge. So the models I'll look at are: RandomForests (bootstrapping), Bagging (bootstrapping), and Gradient Boosting (adding this one in). [Source to look at other tree-based ensembles](https://scikit-learn.org/stable/modules/classes.html?highlight=ensemble#module-sklearn.ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with outliers\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X0, y0, test_size= 0.33, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results = {}\n",
    "\n",
    "def fit_model(model, name):\n",
    "    model.fit(X_train, y_train)\n",
    "    score_train = model.score(X_train, y_train)\n",
    "    score_test = model.score(X_test, y_test)\n",
    "    rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "    mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "    fit_results[name] = (score_train, score_test, rmse, mae)\n",
    "    return score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model0 = DummyRegressor()\n",
    "fit_model(model0, 'dummy')\n",
    "plt.scatter(y_test, model0.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = RandomForestRegressor(n_jobs=-1, random_state=8)\n",
    "fit_model(model1, 'RFR')\n",
    "plt.scatter(y_test, model1.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.21908731e-03, 1.41392732e-02, 5.11290889e-02, 5.09517312e-02,\n",
       "       4.32052711e-03, 1.88302807e-01, 2.16567243e-02, 1.80636731e-03,\n",
       "       0.00000000e+00, 9.82460978e-03, 3.42804462e-03, 9.53273395e-03,\n",
       "       1.02778411e-02, 2.06227412e-02, 1.03038633e-03, 1.15723703e-04,\n",
       "       4.53915605e-03, 7.64041716e-03, 5.38307061e-03, 1.61630951e-02,\n",
       "       1.24252200e-02, 1.21377290e-02, 1.93832520e-01, 2.34203429e-02,\n",
       "       3.04247726e-03, 1.43080458e-03, 6.24619378e-04, 1.62113979e-01,\n",
       "       3.85736366e-03, 5.48298672e-03, 1.01963983e-02, 4.22366087e-03,\n",
       "       1.33053191e-02, 1.47615075e-02, 4.72040612e-03, 1.26289271e-02,\n",
       "       2.08174168e-02, 1.01537570e-02, 1.32201147e-02, 9.92270280e-03,\n",
       "       9.55974439e-03, 1.39598793e-02, 1.50786986e-02])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_coefs = np.mean([\n",
    "    tree.feature_importances_ for tree in model1.estimators_\n",
    "], axis=0)\n",
    "rf_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = BaggingRegressor(n_jobs=-1, random_state=8)\n",
    "fit_model(model2, 'bagging')\n",
    "plt.scatter(y_test, model2.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     8.394927e-03\n",
       "1     2.390779e-03\n",
       "2     5.542693e-02\n",
       "3     3.771260e-02\n",
       "4     1.278880e-03\n",
       "5     2.130453e-01\n",
       "6     2.750059e-02\n",
       "7     1.796184e-03\n",
       "8     0.000000e+00\n",
       "9     5.166699e-03\n",
       "10    2.163966e-03\n",
       "11    5.380050e-03\n",
       "12    7.413926e-03\n",
       "13    1.976614e-02\n",
       "14    9.327901e-07\n",
       "15    0.000000e+00\n",
       "16    1.049729e-02\n",
       "17    6.583321e-03\n",
       "18    2.515717e-03\n",
       "19    1.688590e-02\n",
       "20    1.021607e-02\n",
       "21    1.045474e-02\n",
       "22    2.068838e-01\n",
       "23    2.245821e-02\n",
       "24    4.459899e-03\n",
       "25    2.440632e-03\n",
       "26    2.956332e-04\n",
       "27    1.585876e-01\n",
       "28    2.273090e-03\n",
       "29    3.717140e-03\n",
       "30    6.627974e-03\n",
       "31    4.342766e-03\n",
       "32    1.193994e-02\n",
       "33    8.741214e-03\n",
       "34    8.328112e-04\n",
       "35    7.769267e-03\n",
       "36    5.178665e-02\n",
       "37    3.300383e-03\n",
       "38    1.329637e-02\n",
       "39    1.252077e-02\n",
       "40    6.648315e-03\n",
       "41    5.161594e-03\n",
       "42    2.132500e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_trees_coefs = {}\n",
    "for tree in range(len(model2.estimators_)):\n",
    "    bagging_trees_coefs[tree] = dict(zip(model2.estimators_features_[tree], model2.estimators_[tree].feature_importances_))\n",
    "\n",
    "bagging_trees_coefs = pd.DataFrame(bagging_trees_coefs).sort_index()\n",
    "bagging_coefs = bagging_trees_coefs.mean(axis=1)\n",
    "bagging_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = HistGradientBoostingRegressor(max_iter=10_000, random_state=8)\n",
    "fit_model(model3, 'GradBoost')\n",
    "plt.scatter(y_test, model3.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradboost_coefs = np.mean([\n",
    "    tree.feature_importances_ for tree in model1.estimators_\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost\n",
       "score_train  0.000000  0.880999  0.809259   0.998480\n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776\n",
       "rmse         0.080172  0.076054  0.080895   0.093898\n",
       "mae          0.060118  0.058374  0.062488   0.068800"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like in each model we have a very decent train fit but the test fit is horrible, especially with GradBoost (which is the only model that doesn't have bootstrapping... not sure if that's why or not). What confuses me is that the residuals scatter plots make it seem like Boosting is the cleanest fit... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "[Hyperparameters](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor) of interest:\n",
    "\n",
    "* **n_estimators**-- how many trees in forest. Seems simple enough to test a few.\n",
    "* **max_samples** -- By default, it's all of the X's in the training set. However, I'm curious to see how decreasing this quantity may impact the residuals of y_preds vs y_test.\n",
    "* **criterion** {“mse”, “mae”}, default=”mse” -- according to the docs, \"The function to measure the quality of a split. Supported criteria are “mse” for the mean squared error, which is equal to variance reduction as feature selection criterion, and “mae” for the mean absolute error.\" I think this may be suggesting that if I have issues with model-variance (overfitting), I may want to change the criterion to MAE.\n",
    "* **max_features** -- this could be an interesting pseudo RFE\n",
    "* **min_impurity_decrease** -- this may be better than looking at max leave nodes if I care more about how much the model is improve, rather than complexity (which may be driving up model complexity). Otherwise, I may want to look at **max_depth**\n",
    "* **ccp_alpha** -- This parameter is used to effectively prune out any highly complex models. I don't really know how to use this but I may study this more if model-variance still seems to be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "    'n_estimators': [10,100,1000],\n",
    "    'max_samples': [None, 0.66, 0.33],\n",
    "    'min_impurity_decrease': [0.0, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle = True, random_state= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1a = RandomForestRegressor(criterion='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs1a = GridSearchCV(estimator=model1a, param_grid=params_rf, cv=kf, n_jobs=-1)\n",
    "fit_model(gs1a, 'GS_RF_MSE')\n",
    "plt.scatter(y_test, gs1a.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027329</td>\n",
       "      <td>4.712580e-04</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>9.429656e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.139751</td>\n",
       "      <td>0.055065</td>\n",
       "      <td>-0.019830</td>\n",
       "      <td>-0.034839</td>\n",
       "      <td>0.080238</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219998</td>\n",
       "      <td>4.548091e-03</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>4.717077e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.097904</td>\n",
       "      <td>0.258091</td>\n",
       "      <td>-0.034348</td>\n",
       "      <td>0.041947</td>\n",
       "      <td>0.155024</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.179332</td>\n",
       "      <td>6.182466e-02</td>\n",
       "      <td>0.083667</td>\n",
       "      <td>1.699721e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.090551</td>\n",
       "      <td>0.235521</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.067052</td>\n",
       "      <td>0.133340</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017999</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003367</td>\n",
       "      <td>-0.027564</td>\n",
       "      <td>-0.028915</td>\n",
       "      <td>-0.019949</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170332</td>\n",
       "      <td>2.242481e-02</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>4.715951e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>-0.021941</td>\n",
       "      <td>-0.017996</td>\n",
       "      <td>-0.014051</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.529999</td>\n",
       "      <td>3.187516e-02</td>\n",
       "      <td>0.078667</td>\n",
       "      <td>3.858786e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002824</td>\n",
       "      <td>-0.026800</td>\n",
       "      <td>-0.018997</td>\n",
       "      <td>-0.016207</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026666</td>\n",
       "      <td>1.225709e-02</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.715952e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>-0.053149</td>\n",
       "      <td>-0.018736</td>\n",
       "      <td>-0.024248</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.162000</td>\n",
       "      <td>1.714777e-02</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>1.246364e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.004350</td>\n",
       "      <td>-0.033712</td>\n",
       "      <td>-0.018835</td>\n",
       "      <td>-0.018966</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.529000</td>\n",
       "      <td>3.747865e-02</td>\n",
       "      <td>0.089667</td>\n",
       "      <td>1.820889e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002859</td>\n",
       "      <td>-0.029859</td>\n",
       "      <td>-0.019789</td>\n",
       "      <td>-0.017503</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.032666</td>\n",
       "      <td>1.369548e-02</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.710899e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.059393</td>\n",
       "      <td>0.229266</td>\n",
       "      <td>-0.151615</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.162241</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.198999</td>\n",
       "      <td>1.632973e-03</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.632486e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.057747</td>\n",
       "      <td>0.212192</td>\n",
       "      <td>0.069461</td>\n",
       "      <td>0.074636</td>\n",
       "      <td>0.110263</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.077666</td>\n",
       "      <td>9.749370e-02</td>\n",
       "      <td>0.089666</td>\n",
       "      <td>4.989811e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.044349</td>\n",
       "      <td>0.227060</td>\n",
       "      <td>0.055957</td>\n",
       "      <td>0.079556</td>\n",
       "      <td>0.112052</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.019332</td>\n",
       "      <td>4.715952e-04</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.718761e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>-0.030779</td>\n",
       "      <td>-0.015382</td>\n",
       "      <td>-0.015492</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.161666</td>\n",
       "      <td>8.993862e-03</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002908</td>\n",
       "      <td>-0.023065</td>\n",
       "      <td>-0.016871</td>\n",
       "      <td>-0.014281</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.560333</td>\n",
       "      <td>5.470749e-02</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>1.416655e-02</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002932</td>\n",
       "      <td>-0.027476</td>\n",
       "      <td>-0.018269</td>\n",
       "      <td>-0.016225</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.018332</td>\n",
       "      <td>4.722696e-04</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.709209e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.008299</td>\n",
       "      <td>-0.077530</td>\n",
       "      <td>-0.042083</td>\n",
       "      <td>-0.042637</td>\n",
       "      <td>0.028266</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.152332</td>\n",
       "      <td>3.090948e-03</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>9.433027e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>-0.030684</td>\n",
       "      <td>-0.022633</td>\n",
       "      <td>-0.018491</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.495998</td>\n",
       "      <td>7.872791e-03</td>\n",
       "      <td>0.074666</td>\n",
       "      <td>1.700423e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002771</td>\n",
       "      <td>-0.028586</td>\n",
       "      <td>-0.020088</td>\n",
       "      <td>-0.017148</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.024332</td>\n",
       "      <td>1.885313e-03</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>4.719325e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>0.014637</td>\n",
       "      <td>0.262074</td>\n",
       "      <td>-0.008023</td>\n",
       "      <td>0.089562</td>\n",
       "      <td>0.122334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.192332</td>\n",
       "      <td>1.239196e-02</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>4.713142e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>0.045104</td>\n",
       "      <td>0.255467</td>\n",
       "      <td>-0.035652</td>\n",
       "      <td>0.088306</td>\n",
       "      <td>0.122712</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.888999</td>\n",
       "      <td>5.426396e-02</td>\n",
       "      <td>0.083332</td>\n",
       "      <td>2.129671e-02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>0.042121</td>\n",
       "      <td>0.224792</td>\n",
       "      <td>0.095257</td>\n",
       "      <td>0.120723</td>\n",
       "      <td>0.076719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.021999</td>\n",
       "      <td>5.656725e-03</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>8.920806e-07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>-0.029786</td>\n",
       "      <td>-0.008753</td>\n",
       "      <td>-0.013841</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.151665</td>\n",
       "      <td>4.921046e-03</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>-0.038467</td>\n",
       "      <td>-0.018405</td>\n",
       "      <td>-0.019527</td>\n",
       "      <td>0.015027</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.525667</td>\n",
       "      <td>5.253690e-02</td>\n",
       "      <td>0.078999</td>\n",
       "      <td>2.828784e-03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002374</td>\n",
       "      <td>-0.029225</td>\n",
       "      <td>-0.021548</td>\n",
       "      <td>-0.017716</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.019664</td>\n",
       "      <td>9.429657e-04</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>1.486801e-06</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.008377</td>\n",
       "      <td>-0.048304</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>-0.019031</td>\n",
       "      <td>0.020953</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.152666</td>\n",
       "      <td>1.247936e-03</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003272</td>\n",
       "      <td>-0.028463</td>\n",
       "      <td>-0.020588</td>\n",
       "      <td>-0.017441</td>\n",
       "      <td>0.010522</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.112346</td>\n",
       "      <td>1.472157e-01</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>9.429655e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>-0.028461</td>\n",
       "      <td>-0.020418</td>\n",
       "      <td>-0.017084</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.027329  4.712580e-04         0.004667    9.429656e-04   \n",
       "1        0.219998  4.548091e-03         0.011667    4.717077e-04   \n",
       "2        2.179332  6.182466e-02         0.083667    1.699721e-03   \n",
       "3        0.017999  1.123916e-07         0.004000    1.123916e-07   \n",
       "4        0.170332  2.242481e-02         0.010666    4.715951e-04   \n",
       "5        1.529999  3.187516e-02         0.078667    3.858786e-03   \n",
       "6        0.026666  1.225709e-02         0.003667    4.715952e-04   \n",
       "7        0.162000  1.714777e-02         0.011332    1.246364e-03   \n",
       "8        1.529000  3.747865e-02         0.089667    1.820889e-02   \n",
       "9        0.032666  1.369548e-02         0.003667    4.710899e-04   \n",
       "10       0.198999  1.632973e-03         0.013000    1.632486e-03   \n",
       "11       2.077666  9.749370e-02         0.089666    4.989811e-03   \n",
       "12       0.019332  4.715952e-04         0.003334    4.718761e-04   \n",
       "13       0.161666  8.993862e-03         0.010000    4.052337e-07   \n",
       "14       1.560333  5.470749e-02         0.088000    1.416655e-02   \n",
       "15       0.018332  4.722696e-04         0.003667    4.709209e-04   \n",
       "16       0.152332  3.090948e-03         0.010333    9.433027e-04   \n",
       "17       1.495998  7.872791e-03         0.074666    1.700423e-03   \n",
       "18       0.024332  1.885313e-03         0.003333    4.719325e-04   \n",
       "19       0.192332  1.239196e-02         0.010667    4.713142e-04   \n",
       "20       1.888999  5.426396e-02         0.083332    2.129671e-02   \n",
       "21       0.021999  5.656725e-03         0.004000    8.920806e-07   \n",
       "22       0.151665  4.921046e-03         0.010667    4.714266e-04   \n",
       "23       1.525667  5.253690e-02         0.078999    2.828784e-03   \n",
       "24       0.019664  9.429657e-04         0.004001    1.486801e-06   \n",
       "25       0.152666  1.247936e-03         0.010000    4.052337e-07   \n",
       "26       1.112346  1.472157e-01         0.041667    9.429655e-04   \n",
       "\n",
       "   param_max_samples param_min_impurity_decrease param_n_estimators  \\\n",
       "0               None                           0                 10   \n",
       "1               None                           0                100   \n",
       "2               None                           0               1000   \n",
       "3               None                        0.05                 10   \n",
       "4               None                        0.05                100   \n",
       "5               None                        0.05               1000   \n",
       "6               None                         0.1                 10   \n",
       "7               None                         0.1                100   \n",
       "8               None                         0.1               1000   \n",
       "9               0.66                           0                 10   \n",
       "10              0.66                           0                100   \n",
       "11              0.66                           0               1000   \n",
       "12              0.66                        0.05                 10   \n",
       "13              0.66                        0.05                100   \n",
       "14              0.66                        0.05               1000   \n",
       "15              0.66                         0.1                 10   \n",
       "16              0.66                         0.1                100   \n",
       "17              0.66                         0.1               1000   \n",
       "18              0.33                           0                 10   \n",
       "19              0.33                           0                100   \n",
       "20              0.33                           0               1000   \n",
       "21              0.33                        0.05                 10   \n",
       "22              0.33                        0.05                100   \n",
       "23              0.33                        0.05               1000   \n",
       "24              0.33                         0.1                 10   \n",
       "25              0.33                         0.1                100   \n",
       "26              0.33                         0.1               1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_samples': None, 'min_impurity_decrease':...          -0.139751   \n",
       "1   {'max_samples': None, 'min_impurity_decrease':...          -0.097904   \n",
       "2   {'max_samples': None, 'min_impurity_decrease':...          -0.090551   \n",
       "3   {'max_samples': None, 'min_impurity_decrease':...          -0.003367   \n",
       "4   {'max_samples': None, 'min_impurity_decrease':...          -0.002217   \n",
       "5   {'max_samples': None, 'min_impurity_decrease':...          -0.002824   \n",
       "6   {'max_samples': None, 'min_impurity_decrease':...          -0.000859   \n",
       "7   {'max_samples': None, 'min_impurity_decrease':...          -0.004350   \n",
       "8   {'max_samples': None, 'min_impurity_decrease':...          -0.002859   \n",
       "9   {'max_samples': 0.66, 'min_impurity_decrease':...          -0.059393   \n",
       "10  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.057747   \n",
       "11  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.044349   \n",
       "12  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.000317   \n",
       "13  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.002908   \n",
       "14  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.002932   \n",
       "15  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.008299   \n",
       "16  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.002157   \n",
       "17  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.002771   \n",
       "18  {'max_samples': 0.33, 'min_impurity_decrease':...           0.014637   \n",
       "19  {'max_samples': 0.33, 'min_impurity_decrease':...           0.045104   \n",
       "20  {'max_samples': 0.33, 'min_impurity_decrease':...           0.042121   \n",
       "21  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002983   \n",
       "22  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.001709   \n",
       "23  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002374   \n",
       "24  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.008377   \n",
       "25  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.003272   \n",
       "26  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002371   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.055065          -0.019830        -0.034839        0.080238   \n",
       "1            0.258091          -0.034348         0.041947        0.155024   \n",
       "2            0.235521           0.056186         0.067052        0.133340   \n",
       "3           -0.027564          -0.028915        -0.019949        0.011738   \n",
       "4           -0.021941          -0.017996        -0.014051        0.008522   \n",
       "5           -0.026800          -0.018997        -0.016207        0.009985   \n",
       "6           -0.053149          -0.018736        -0.024248        0.021700   \n",
       "7           -0.033712          -0.018835        -0.018966        0.011988   \n",
       "8           -0.029859          -0.019789        -0.017503        0.011140   \n",
       "9            0.229266          -0.151615         0.006086        0.162241   \n",
       "10           0.212192           0.069461         0.074636        0.110263   \n",
       "11           0.227060           0.055957         0.079556        0.112052   \n",
       "12          -0.030779          -0.015382        -0.015492        0.012436   \n",
       "13          -0.023065          -0.016871        -0.014281        0.008430   \n",
       "14          -0.027476          -0.018269        -0.016225        0.010124   \n",
       "15          -0.077530          -0.042083        -0.042637        0.028266   \n",
       "16          -0.030684          -0.022633        -0.018491        0.012009   \n",
       "17          -0.028586          -0.020088        -0.017148        0.010742   \n",
       "18           0.262074          -0.008023         0.089562        0.122334   \n",
       "19           0.255467          -0.035652         0.088306        0.122712   \n",
       "20           0.224792           0.095257         0.120723        0.076719   \n",
       "21          -0.029786          -0.008753        -0.013841        0.011518   \n",
       "22          -0.038467          -0.018405        -0.019527        0.015027   \n",
       "23          -0.029225          -0.021548        -0.017716        0.011292   \n",
       "24          -0.048304          -0.000410        -0.019031        0.020953   \n",
       "25          -0.028463          -0.020588        -0.017441        0.010522   \n",
       "26          -0.028461          -0.020418        -0.017084        0.010909   \n",
       "\n",
       "    rank_test_score  \n",
       "0                26  \n",
       "1                 7  \n",
       "2                 6  \n",
       "3                24  \n",
       "4                10  \n",
       "5                13  \n",
       "6                25  \n",
       "7                21  \n",
       "8                18  \n",
       "9                 8  \n",
       "10                5  \n",
       "11                4  \n",
       "12               12  \n",
       "13               11  \n",
       "14               14  \n",
       "15               27  \n",
       "16               20  \n",
       "17               16  \n",
       "18                2  \n",
       "19                3  \n",
       "20                1  \n",
       "21                9  \n",
       "22               23  \n",
       "23               19  \n",
       "24               22  \n",
       "25               17  \n",
       "26               15  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs1a.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.565859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.148285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.565859\n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.148285\n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073614\n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056166"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1b = RandomForestRegressor(criterion='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdaElEQVR4nO3df4xd5X3n8feH8bixYVNTcNUytmuXsGbJYnA0hTZGm0AWGZft2vkh8atEq1Ahd5duglovk1VEKyVdvMpq26qCRRabbSVQACWOhQqsV1pHioJr5CF2oIYYObjBM84qU2qTkkzL2Hz3j3sdX4/PnXvuj/Pzfl6SJd9zz5l57rl3vvc53+f7PEcRgZmZ1dcFRTfAzMyy5UBvZlZzDvRmZjXnQG9mVnMO9GZmNbeo6AYkufTSS2P16tVFN8PMrDJeeumlv4uI5UnPlTLQr169msnJyaKbYWZWGZJ+0O45p27MzGrOgd7MrOYc6M3Mas6B3sys5hzozcxqrpRVN1YOuw5M8+Xdhzl+cpbLli1h28a1bFk/VnSzzKxLDvSWaNeBaT6/8xVm504DMH1yls/vfAXAwd6sYpy6sURf3n34Z0H+jNm503x59+GCWmRmvXKgt0THT852td3MysuB3hJdtmxJV9vNrLwc6C3Rto1rWTI6cs62JaMjbNu4tqAWmVmvPBhric4MuLrqxqz6HOitrS3rxxzYzWrAqRszs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac9WNmQ2EF8Err1Q9ekm3SDos6YikiYTnN0t6WdJBSZOSbmhuXynpm5Jek3RI0mcH/QLMrHhnFsGbPjlLcHYRvF0HpotumpEi0EsaAR4GNgFXAXdIumrebv8XuCYirgU+AzzW3H4K+P2I+BfArwP/IeFYM6s4L4JXbmlSN9cBRyLiDQBJTwKbgVfP7BAR77TsfyEQze0/BH7Y/P8/SHoNGGs91qxOhjV94UXwyi1NoB8DjrU8ngKun7+TpI8DDwG/CNya8PxqYD3wYtIvkXQvcC/AqlWrUjTLrFzKvIZ/1l9Aly1bwnRCUPcieOWQJkevhG1x3oaIb0TElcAW4Ivn/ADpIuDrwOci4sdJvyQidkTEeESML1++PEWzrAi7DkyzYfse1kw8y4bte5yDbZF3+iLte5FH/tyL4JVbmkA/BaxsebwCON5u54j4FnC5pEsBJI3SCPJPRMTOPtpqBfOA28LyTF90817k8QW0Zf0YD33iasaWLUHA2LIlPPSJqwu/krGGNKmb/cAVktYA08DtwJ2tO0j6APD9iAhJHwIWA29JEvA/gdci4r8PtumWt4UChv+g26cvfn7JKBu27xlo2qSb96LdF830yVl2HZge2HvnRfDKq2Ogj4hTku4DdgMjwFci4pCkrc3nHwU+CXxa0hwwC9zWDPo3AHcDr0g62PyR/zkinsvixVi26jjgNsjc9baNa8/J0QOMXiB+8u4pTs7OAYPL23fzXrT7AgJKM4Yw7LIeQ0lVRx8Rz0XEP4+IyyPij5vbHm0GeSLiv0bEByPi2oj4jYj4dnP7tyNCEbGu+dy1DvLVVbe7Tg06FZWUvrjofYuYO33ukNYg0ibdvBdJ+fNBtsX6k0dK1EsgWGp1G3DLIne9Zf0YL0zcxNHtt/LCxE2c/Olc4n7Hm2mTXge2u3kvznwBtVPlK7I6yGMMxUsgWGp1u+vUQumPQV1Kt0ubLFs62lcpZrfvxZb1Y3x592GXQJZQHilRB3rrSp0G3LIKwq2S8vZLRkeIoO+B7W7fi3ZtqeoVWV3kMQfBqRsbSrsOTPOTfzp13vZOQbhb7coO355tn9LJiksgyymPlKh79DZ05s9gPePipaP84W99kPufOph4XK9BOKnnXVQapU5XZHWRR0rUgd6GTtLgF8DSxYtyy2U7jWKtsv4CdurGhk6nwa88LqWdRrE8uUdvQ6fT4Fde1UV1SqMM66qdVeFAb0MnTdqkTkE4a2VetdMaHOgtN2Xp9ZVtPkBZzkuvvAZS+TnQWy7K1usrS4+9bOelF3VcA6luPBhruajqreayXn+/quelVd3WQKojB3rLRRV7fXksNlXF8zJf3dZAqiMHestFWXt9C/XY8+htl/W8dMOlouXnHL3loowThDrlx/PobZfxvPSiLGMelsw9estFGXt9nXrsefS255+Xi5eO8nOLLuD+pw76nrw2MO7RW27lfWXr9aWZIZtVb/sLu17hqy8e43QEIxJ3XL+S8V/5hcpX4Fg5uUc/5Ib5ht+deuxZXYV8YdcrPL7vTU5H485TpyN4fN+bfH7ny5WvwLFyco9+yA3zZJeiZsh+9cVjidtn595L3F6lChwrJwf6IVeH8r5eFTVD9kxPPq0qVeBYOTnQD7k87m5TZkWMG4xIicH+AsHPLRoppAKn6ssw2MJS5egl3SLpsKQjkiYSnt8s6WVJByVNSroh7bFWLE92yd8d169M3H7n9asKqUwa5nGaYaHocBkpaQR4HbgZmAL2A3dExKst+1wE/CQiQtI64OmIuDLNsUnGx8djcnKyj5dl3XBvLn9JVTdf2nJ1IW3ZsH1P4lXd2LIlvDBxU+Ix/syUj6SXImI86bk0qZvrgCMR8Ubzhz0JbAZ+Fqwj4p2W/S8EIu2xVryylT0OSpmD0Ze2XF1YYJ+v23GaOizENmzSpG7GgNYyganmtnNI+rik7wHPAp/p5tjm8fc20z6TMzMzadpu1pbTEel1OzGsDguxDZs0gV4J287L90TENyLiSmAL8MVujm0evyMixiNifPny5SmaZdZeu2D0+09/N7OVKKuq23GaYa7Uqqo0gX4KaB09WgEcb7dzRHwLuFzSpd0eazYo7YLO6Qj38OfpdmJYHRZiGzZpcvT7gSskrQGmgduBO1t3kPQB4PvNwdgPAYuBt4CTnY41y0K7stFWwzIxLI1uxmnqshDbMOnYo4+IU8B9wG7gNRoVNYckbZW0tbnbJ4G/kXQQeBi4LRoSj83ihZi1SkpHJHG6oXtlXKDOFtaxvLIILq+0QWiturmgzSSlhUoILV9lrpKqgoXKKx3oLVdF/THPLwkEGB0RFy5exNuzcw4sBUt6f5aMjvhKoQsLBXqvXmm5KbLkMWnddwJOzs55cLYEXLKZLQd6y03Rf8xb1o/xwsRNHN1+K0sXL2LuvXOvZh1YiuOSzWx5UTPLTZn+mItoi3PQ7Q374npZc4/eclOm+uu82+KZugvz4nrZcqC33PTzx7zrwDQbtu8Z2KzWvANL0WmrInTznrlkM1tO3Vgqg0g79HqjjywW0cr7piNlSlvloZf3rK6L65WBA711NMhA28sfc1a3O8wzsAxbDnqYb1FZRk7dWEdFpx3q0Bsethx0Hd6zOnGgt46K/qMt0yBur4YtB12H96xOnLqxjopOO9RlEa1eUkVlLcns1K66vGd14R69dVR02mHYesNnlLUkM027hvU9KyuvdWOplLVnWRZZnJ9e7uWah7K2a9j1e89YM5e+LSCre6gWPTbSTlnbZe05dWPWp05VSb1O9mo3BrJs6Wh/De6TB1qrx4HerE8L9XD7ybNv27iW0ZHzb7v8zj+eKjRPX/SYjXXPgd6sTwv1cPuZg7Bl/RgXLj4/uzr3XhS6dELagdZBL1thvXOO3qxPC5US3v/UwcRj0uaz356d6+v4rHQas8lq3MJ64x69WZ8W6uH2m8+uaj686NnUdi736M0GoF0Pt9+JQ1WdeOTKnHJxoDfLUL+rZOa9yuagZDGb2nM5eucJU2Y2cIO+2bdvHt5Z3zcHl3SLpMOSjkiaSHj+LkkvN//tlXRNy3P3Szok6W8kfVXS+3p/KWZWBYNeAsE5//50TN1IGgEeBm4GpoD9kp6JiFdbdjsKfCQiTkjaBOwArpc0BvxH4KqImJX0NHA78BcDfh1mVjKDnE3tnH9/0vTorwOORMQbEfEu8CSwuXWHiNgbESeaD/cBK1qeXgQskbQIWAoc77/ZZjZMqlp9VBZpAv0YcKzl8VRzWzv3AM8DRMQ08N+AN4EfAm9HxP9JOkjSvZImJU3OzMykabuZDQnPxu1PmkB//hxsSBzBlXQjjUD/QPPxxTR6/2uAy4ALJf120rERsSMixiNifPny5WnabmZDwsse9ydNeeUUsLLl8QoS0i+S1gGPAZsi4q3m5n8NHI2ImeY+O4EPA4/302gzGz5eQbV3aXr0+4ErJK2RtJjGYOozrTtIWgXsBO6OiNdbnnoT+HVJSyUJ+Bjw2mCabmZmaXTs0UfEKUn3AbuBEeArEXFI0tbm848CDwKXAI804jmnmmmYFyV9DfgOcAo4QKMix8zMcuIJU2ZmNdD3hCkzM6suB3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oa841HzCrCN96wXjnQm1WAb7Zt/XDqxqwCfOMN64cDvVkF+MYb1g+nbsxy0G9+PYubbdvwcI/eLGNn8uvTJ2cJzubXdx2YTv0zfOMN64d79BlzpYQtlF9P+1k4s58/S9YLB/oMuVLCYHD5dd94w3rl1E2GXClRDbsOTLNh+x7WTDzLhu17ukqppOEbW1vRHOgz5EqJ8htE/rwT59etaA70GXJPrvzyuOryja1tIVlfUYJz9JnatnHtOTl6cE+ubPK66nJ+3ZLkNY7nHn2G3JMrP191WZHyGsdzjz5j7smVm6+6rEh5XVE60FtuyjinwPXpVqS8ZjynCvSSbgH+DBgBHouI7fOevwt4oPnwHeB3I+K7zeeWAY8B/xII4DMR8deDab5VRZnnFPiqy4qS1xVlxxy9pBHgYWATcBVwh6Sr5u12FPhIRKwDvgjsaHnuz4D/HRFXAtcArw2i4VYtnlNgdr68xvHS9OivA45ExBsAkp4ENgOvntkhIva27L8PWNHc9/3AvwL+XXO/d4F3B9Fwq5ayzCmYnz668crlfPN7M07bWGHyuKJMU3UzBhxreTzV3NbOPcDzzf//KjAD/C9JByQ9JunCpIMk3StpUtLkzMxMimZZlZShuiVpctTj+97MdLKUWRmkCfRK2BaJO0o30gj0Z/L1i4APAf8jItYDPwEmko6NiB0RMR4R48uXL0/RLKuSMswOTUofzed0ktVRmkA/BaxsebwCOD5/J0nraAy6bo6It1qOnYqIF5uPv0Yj8NuQKcOcgrRpIi9RYXWTJke/H7hC0hpgGrgduLN1B0mrgJ3A3RHx+pntEfH/JB2TtDYiDgMfoyW3b8Mly1xkmtLNdqVs83mylNVNxx59RJwC7gN206iYeToiDknaKmlrc7cHgUuARyQdlDTZ8iN+D3hC0svAtcB/GegrsKGXdmGypPTRfJ4sZXWkiMR0e6HGx8djcnKy845mwIbtexJ76mPLlvDCxE3nbHPVjdWVpJciYjzpOc+MtcrrpnTTk6NsGHlRM6u8MpRumpWZA72VQj9rcpehdNOszJy6scL1uw6OFyYzW5gDvRVuoXVw0gZr597N2nPqxgrXbjA1Tc27mXXmQG+FazdoKvC6M2YD4EBvhdu2cW3bBZW87oxZ/xzorXBb1o8lr5KH150xGwQHeiuFMdfCm2XGgd5KwbXwZtlxeaWVgmvhzbLjQG+l4Vp4s2w40FutpVmn3qzuHOittvpdWsGsLjwYa7W10NIKZsPEPXorhSxSLN2sU29WZ+7RW+HS3gqwW16n3qzBgd4Kl1WKJa/a/H7W0jfLg1M3NlC9pGDSpli6/dl51OZ7wNeqwIF+CORVYthr0Lts2ZLEJYlbUyy9/uxOtfn9npt2VyN/9Mwhl3VaaTh1U3NZ5b+T9JqCSZNiySK9M4hz0+5q5OTsXC7n3CyNVIFe0i2SDks6Imki4fm7JL3c/LdX0jXznh+RdEDSXw2q4ZZOniWGvVa5bFk/xkOfuJqxZUsQjQXOHvrE1ef0gLOooBnEuUk7sOuyTitSx9SNpBHgYeBmYArYL+mZiHi1ZbejwEci4oSkTcAO4PqW5z8LvAa8f2Att1TyLDFMk4Jpp1OKpd3PXrZ0tLtGthjEudm2ce05KaVefp9Z1tL06K8DjkTEGxHxLvAksLl1h4jYGxEnmg/3ASvOPCdpBXAr8NhgmpzMlQ/J8iwxzLLKZdvGtYyOnH97knf+8VTP7/VC5ybt5ynpauTiNl8+Luu0oqQJ9GPAsZbHU81t7dwDPN/y+E+B/wS8t9AvkXSvpElJkzMzMymadVaeeeiqyXP53zQpmH5+9oWLz78AnXsvek6JtDs3N165vKvP05b1Y7wwcRNHt9/KCxM38Ye/9UEvuWylkqbqpt1d3s7fUbqRRqC/ofn43wA/ioiXJH10oV8SETtopHwYHx9vd8OhRAvlWoe90iHv5X+zXIHy7dm5xO1nUiKDKr/s9/PkJZetbNIE+ilgZcvjFcDx+TtJWkcjPbMpIt5qbt4A/FtJvwm8D3i/pMcj4rf7a/a5PNV9YXVZ/nehMYBBll/e/9TBxH2Tfnc3P9esKGlSN/uBKyStkbQYuB14pnUHSauAncDdEfH6me0R8fmIWBERq5vH7Rl0kAdPdR8WC6WhBlld1O5zI3A60CqpY6CPiFPAfcBuGpUzT0fEIUlbJW1t7vYgcAnwiKSDkiYza3EC34ZuOCw0BjDIq7ptG9e2zVe6RNKqSBFdpcNzMT4+HpOT3X1X+AYTxSnDud+wfU9iamVs2RJemLip65+3euLZxO0Cjm6/teufZ5Y1SS9FxHjSc7VZAsE50WKUZa2XpHr2fq7qxvqYE2BWNl4CwfqS98092tW3D7q0c5jTgZ6TUj+16dFbMfKseOp09TDIq7phLZEsyxWaDZYDvfWln2UPupX3fIlhTAd6Tko9OXVjfckzxeH5EtnzOa4n9+itJ62VNj+/ZJT3jV7AyZ/OZZriyPPqoQhlqF6q+zkeVg701rX5edyTs3MsGR3hT267NlVg6jWgLVRZU4Yg2Y+y5MYHXb1k5eDUjXWtn0qbfhaga1dZA1R+Ubu8q5fayXJhOiuOe/TWtX7yuINYMGz+fhu276n8AGKZcuPDOAhdd+7RW9f6WVsoi4BWpiDZK6/XZFlyoLeu9VNpk0VAq0OQHOYJWpY9B3rrWpo8brvZlVkEtDoESefGLUu1WdRsWFShumR+BQk0Au+ZwJXFa6jCeTHL0kKLmjnQV0inAFoWg15J0sw6G4rVK4dBVaanFzE46h69WXsO9BVSleqSvGdXJk02uv+pg0z+4O/50parM/mdrb876QvGXzxWJh6MrZCqVJfkPTiadKUTwBP73sx00lS7yV9f2PVK5SdwWb040FdIVapL8q4gaXdFk/Wt/9ql0r764rFSzHI1O8Opmwqp0hrpec6ubJcqgmzTWu1+9uk2BQ5lS7HZ8HCgr5hhnZ7emvNetnSUCHh7trFa5o1XLueJfW+SFF6zTGu1+4IZkRKDfdlSbDY8nLqx0pufCz/x0zlOzs79LP/99Zem+fDlv4DmHZd1WqtdKu2O61f2lWLzrfxs0FIFekm3SDos6YikiYTn75L0cvPfXknXNLevlPRNSa9JOiTps4N+AVZ/SbnwVrNzp/nbt2b5k9uuzXVmabuxiC9tubrnMYp+Vvc0a6fjhClJI8DrwM3AFLAfuCMiXm3Z58PAaxFxQtIm4I8i4npJvwz8ckR8R9I/A14CtrQem8QTpqzVmolnE9MyrQQc3X5rHs3JlCebWa8WmjCVpkd/HXAkIt6IiHeBJ4HNrTtExN6IONF8uA9Y0dz+w4j4TvP//wC8Bgxfgtn6kia3XZf8d1XmSli1pAn0Y8CxlsdTLBys7wGen79R0mpgPfBi0kGS7pU0KWlyZmYmRbNsWCTlwluVscS0V1WZK2HVkqbqZv4YF5B8JS3pRhqB/oZ52y8Cvg58LiJ+nHRsROwAdkAjdZOiXaVR51mQZXht88tK51fd1Ol8+1Z+loU0gX4KWNnyeAVwfP5OktYBjwGbIuKtlu2jNIL8ExGxs7/mlk9Z7vWZhTK9trRlpWX4YupHleZKWHWkGYxdRGMw9mPANI3B2Dsj4lDLPquAPcCnI2Jvy3YBfwn8fUR8Lm2jqjQYW+fBs6q9tqqs7mmWhb4GYyPiFHAfsJvGYOrTEXFI0lZJW5u7PQhcAjwi6aCkM1F6A3A3cFNz+0FJv9nvCyqTOg+eVe21leUG22Zlk2pmbEQ8Bzw3b9ujLf//HeB3Eo77Nsk5/trIe6XGPFXttVXti8ksL54Z26eqLDTWi6q9NlesmCVzoO9Tne/1WbXXVrUvJrO8+FaCVitVr7ox65VvJWhDY1hX9zRbiFM3ZmY150BvZlZzDvRmZjXnQG9mVnMO9GZmNeeqG0ulLmWLdXkdZt1woLeOyrSK5XzdBO4yvw6zLDl1Yx2VdbGwbu+vWtbXYZY1B3rrqKyLhXUbuMv6Osyy5tSNdVTWVSy7DdxlfR3zeRzBBs09euuorIuFdbtaZdrXsevANBu272HNxLNs2L6nbSooC92mo8zScKC3jsq6imW3X0BpXkfRgdbjCJYFp24yUrfL7zIuFtbL/VU7vY6FAm0er9/jCJYFB/oMuIwvP4P+Aio60FZlHMGqxambDPjyu7qKvktVWcdDrNoc6DNQdK/Qeld0oC3reIhVm1M3GfDld3X1kvfPog0O7DZIDvQZ2LZx7Tk5evDld5U40FrdpErdSLpF0mFJRyRNJDx/l6SXm//2Srom7bF15MtvMyuTjj16SSPAw8DNwBSwX9IzEfFqy25HgY9ExAlJm4AdwPUpj60l9wrTq1spqlnZpOnRXwcciYg3IuJd4Elgc+sOEbE3Ik40H+4DVqQ91oZb0ROUzIZBmkA/BhxreTzV3NbOPcDz3R4r6V5Jk5ImZ2ZmUjTL6sClqGbZSxPolbAtEneUbqQR6B/o9tiI2BER4xExvnz58hTNsjpwKapZ9tIE+ilgZcvjFcDx+TtJWgc8BmyOiLe6OdaGV9ETlMyGQZpAvx+4QtIaSYuB24FnWneQtArYCdwdEa93c6wNt6InKJkNg45VNxFxStJ9wG5gBPhKRByStLX5/KPAg8AlwCOSAE410zCJx2b0WqyCyjBByazuFJGYMi/U+Ph4TE5OFt0MM7PKkPRSRIwnPee1bszMas6B3sys5hzozcxqzoHezKzmHOjNzGqulFU3kmaAHxTdjpQuBf6u6EaUhM/FWT4X5/L5OCurc/ErEZG4rEApA32VSJpsV9I0bHwuzvK5OJfPx1lFnAunbszMas6B3sys5hzo+7ej6AaUiM/FWT4X5/L5OCv3c+EcvZlZzblHb2ZWcw70ZmY150CfkqRbJB2WdETSRMLzV0r6a0n/JOkPimhjXlKci7skvdz8t1fSNUW0Mw8pzsXm5nk42LxV5g1FtDMPnc5Fy36/Jum0pE/l2b48pfhcfFTS283PxUFJD2baoIjwvw7/aKyl/33gV4HFwHeBq+bt84vArwF/DPxB0W0u+Fx8GLi4+f9NwItFt7vAc3ERZ8fC1gHfK7rdRZ2Llv32AM8Bnyq63QV+Lj4K/FVebXKPPp3rgCMR8UZEvAs8CWxu3SEifhQR+4G5IhqYozTnYm9EnGg+3EfjFpJ1lOZcvBPNv2zgQtrcM7kGOp6Lpt8Dvg78KM/G5SztuciNA306Y8CxlsdTzW3DqNtzcQ/wfKYtKk6qcyHp45K+BzwLfCantuWt47mQNAZ8HHg0x3YVIe3fyG9I+q6k5yV9MMsGOdCno4Rtde2ZdZL6XEi6kUagfyDTFhUn1bmIiG9ExJXAFuCLmbeqGGnOxZ8CD0TE6RzaU6Q05+I7NNamuQb4c2BXlg1yoE9nCljZ8ngFcLygthQt1bmQtA54DNgcEW/l1La8dfW5iIhvAZdLujTrhhUgzbkYB56U9LfAp2jcY3pLPs3LVcdzERE/joh3mv9/DhjN8nPhQJ/OfuAKSWskLQZuB54puE1F6XguJK0CdgJ3R8TrBbQxL2nOxQckqfn/D9EYnKvjF1/HcxERayJidUSsBr4G/PuIyLQnW5A0n4tfavlcXEcjFmf2uViU1Q+uk4g4Jek+YDeNEfWvRMQhSVubzz8q6ZeASeD9wHuSPkdjpP3HhTU8A2nOBfAgcAmNHhvAqajhyoUpz8UngU9LmgNmgdtaBmdrI+W5GAopz8WngN+VdIrG5+L2LD8XXgLBzKzmnLoxM6s5B3ozs5pzoDczqzkHejOzmnOgNzOrOQd6M7Oac6A3M6u5/w/ziW/a9XUP1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs1b = GridSearchCV(estimator=model1b, param_grid=params_rf, cv=kf, n_jobs=-1)\n",
    "fit_model(gs1b, 'GS_RF_MAE')\n",
    "plt.scatter(y_test, gs1b.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_min_impurity_decrease</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074331</td>\n",
       "      <td>0.017557</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>9.898834e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.191868</td>\n",
       "      <td>0.123570</td>\n",
       "      <td>-0.003642</td>\n",
       "      <td>-0.023980</td>\n",
       "      <td>0.129578</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.658843</td>\n",
       "      <td>0.012283</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>4.709208e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.172405</td>\n",
       "      <td>0.237464</td>\n",
       "      <td>-0.087570</td>\n",
       "      <td>-0.007504</td>\n",
       "      <td>0.176647</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.684200</td>\n",
       "      <td>0.387083</td>\n",
       "      <td>0.092667</td>\n",
       "      <td>1.228358e-02</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.175264</td>\n",
       "      <td>0.244458</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>0.171462</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043667</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>4.722701e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002492</td>\n",
       "      <td>-0.042341</td>\n",
       "      <td>-0.001537</td>\n",
       "      <td>-0.015456</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.261007</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.004056</td>\n",
       "      <td>-0.045292</td>\n",
       "      <td>-0.002137</td>\n",
       "      <td>-0.017162</td>\n",
       "      <td>0.019906</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.240341</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.073334</td>\n",
       "      <td>2.054604e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003915</td>\n",
       "      <td>-0.043457</td>\n",
       "      <td>-0.003548</td>\n",
       "      <td>-0.016973</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026334</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>4.716516e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003171</td>\n",
       "      <td>-0.031808</td>\n",
       "      <td>-0.009943</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.276666</td>\n",
       "      <td>0.014974</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>1.699644e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003424</td>\n",
       "      <td>-0.044216</td>\n",
       "      <td>-0.003939</td>\n",
       "      <td>-0.017193</td>\n",
       "      <td>0.019110</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.349510</td>\n",
       "      <td>0.164539</td>\n",
       "      <td>0.079334</td>\n",
       "      <td>7.542544e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': None, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003552</td>\n",
       "      <td>-0.044173</td>\n",
       "      <td>-0.003328</td>\n",
       "      <td>-0.017018</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>9.434158e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.147430</td>\n",
       "      <td>0.214253</td>\n",
       "      <td>0.090318</td>\n",
       "      <td>0.052380</td>\n",
       "      <td>0.150073</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.549333</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>4.702465e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.087335</td>\n",
       "      <td>0.230544</td>\n",
       "      <td>0.069623</td>\n",
       "      <td>0.070944</td>\n",
       "      <td>0.129777</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.701202</td>\n",
       "      <td>0.355410</td>\n",
       "      <td>0.070173</td>\n",
       "      <td>1.606407e-02</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.080458</td>\n",
       "      <td>0.231476</td>\n",
       "      <td>0.106391</td>\n",
       "      <td>0.085803</td>\n",
       "      <td>0.128176</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>4.722138e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.017331</td>\n",
       "      <td>-0.033199</td>\n",
       "      <td>-0.002576</td>\n",
       "      <td>-0.017702</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.215001</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>1.886212e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.004757</td>\n",
       "      <td>-0.047068</td>\n",
       "      <td>-0.002141</td>\n",
       "      <td>-0.017989</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.164675</td>\n",
       "      <td>0.109177</td>\n",
       "      <td>0.087334</td>\n",
       "      <td>1.407966e-02</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003623</td>\n",
       "      <td>-0.041279</td>\n",
       "      <td>-0.004030</td>\n",
       "      <td>-0.016311</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.023332</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>4.899036e-07</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.019367</td>\n",
       "      <td>-0.004491</td>\n",
       "      <td>-0.007979</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.200999</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>9.436961e-04</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>-0.054096</td>\n",
       "      <td>-0.002905</td>\n",
       "      <td>-0.019495</td>\n",
       "      <td>0.024474</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.012009</td>\n",
       "      <td>0.039218</td>\n",
       "      <td>0.070333</td>\n",
       "      <td>1.247129e-03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.66, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003040</td>\n",
       "      <td>-0.042572</td>\n",
       "      <td>-0.003378</td>\n",
       "      <td>-0.016330</td>\n",
       "      <td>0.018556</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>7.370010e-07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.014383</td>\n",
       "      <td>0.159478</td>\n",
       "      <td>0.092331</td>\n",
       "      <td>0.079142</td>\n",
       "      <td>0.071588</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.325332</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>4.712019e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003129</td>\n",
       "      <td>0.205631</td>\n",
       "      <td>0.136995</td>\n",
       "      <td>0.113166</td>\n",
       "      <td>0.086876</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.700040</td>\n",
       "      <td>0.484369</td>\n",
       "      <td>0.058170</td>\n",
       "      <td>7.172945e-03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.207774</td>\n",
       "      <td>0.117453</td>\n",
       "      <td>0.116945</td>\n",
       "      <td>0.074370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>4.730564e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.016289</td>\n",
       "      <td>-0.051224</td>\n",
       "      <td>-0.012140</td>\n",
       "      <td>-0.026551</td>\n",
       "      <td>0.017529</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.173999</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002697</td>\n",
       "      <td>-0.046636</td>\n",
       "      <td>-0.006256</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>0.019927</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.833026</td>\n",
       "      <td>0.055539</td>\n",
       "      <td>0.078334</td>\n",
       "      <td>2.867151e-03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002908</td>\n",
       "      <td>-0.038644</td>\n",
       "      <td>-0.004844</td>\n",
       "      <td>-0.015466</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.021666</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>5.150430e-07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.052390</td>\n",
       "      <td>-0.045052</td>\n",
       "      <td>-0.032482</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.189333</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>4.711456e-04</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.003269</td>\n",
       "      <td>-0.040353</td>\n",
       "      <td>-0.003022</td>\n",
       "      <td>-0.015548</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.409541</td>\n",
       "      <td>0.069230</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>5.353426e-03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_samples': 0.33, 'min_impurity_decrease':...</td>\n",
       "      <td>-0.002146</td>\n",
       "      <td>-0.045698</td>\n",
       "      <td>-0.003066</td>\n",
       "      <td>-0.016970</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.074331      0.017557         0.011000    9.898834e-03   \n",
       "1        0.658843      0.012283         0.010334    4.709208e-04   \n",
       "2        6.684200      0.387083         0.092667    1.228358e-02   \n",
       "3        0.043667      0.015326         0.003667    4.722701e-04   \n",
       "4        0.261007      0.018876         0.010000    1.123916e-07   \n",
       "5        2.240341      0.013594         0.073334    2.054604e-03   \n",
       "6        0.026334      0.000472         0.003333    4.716516e-04   \n",
       "7        0.276666      0.014974         0.011666    1.699644e-03   \n",
       "8        2.349510      0.164539         0.079334    7.542544e-03   \n",
       "9        0.063503      0.006182         0.004667    9.434158e-04   \n",
       "10       0.549333      0.021297         0.011333    4.702465e-04   \n",
       "11       4.701202      0.355410         0.070173    1.606407e-02   \n",
       "12       0.029333      0.006847         0.003334    4.722138e-04   \n",
       "13       0.215001      0.007789         0.010333    1.886212e-03   \n",
       "14       2.164675      0.109177         0.087334    1.407966e-02   \n",
       "15       0.023332      0.000470         0.003001    4.899036e-07   \n",
       "16       0.200999      0.005100         0.009667    9.436961e-04   \n",
       "17       2.012009      0.039218         0.070333    1.247129e-03   \n",
       "18       0.036000      0.001634         0.004000    7.370010e-07   \n",
       "19       0.325332      0.016418         0.010667    4.712019e-04   \n",
       "20       2.700040      0.484369         0.058170    7.172945e-03   \n",
       "21       0.025667      0.011324         0.004334    4.730564e-04   \n",
       "22       0.173999      0.002944         0.009999    1.123916e-07   \n",
       "23       1.833026      0.055539         0.078334    2.867151e-03   \n",
       "24       0.021666      0.000943         0.003000    5.150430e-07   \n",
       "25       0.189333      0.006944         0.010333    4.711456e-04   \n",
       "26       1.409541      0.069230         0.049000    5.353426e-03   \n",
       "\n",
       "   param_max_samples param_min_impurity_decrease param_n_estimators  \\\n",
       "0               None                           0                 10   \n",
       "1               None                           0                100   \n",
       "2               None                           0               1000   \n",
       "3               None                        0.05                 10   \n",
       "4               None                        0.05                100   \n",
       "5               None                        0.05               1000   \n",
       "6               None                         0.1                 10   \n",
       "7               None                         0.1                100   \n",
       "8               None                         0.1               1000   \n",
       "9               0.66                           0                 10   \n",
       "10              0.66                           0                100   \n",
       "11              0.66                           0               1000   \n",
       "12              0.66                        0.05                 10   \n",
       "13              0.66                        0.05                100   \n",
       "14              0.66                        0.05               1000   \n",
       "15              0.66                         0.1                 10   \n",
       "16              0.66                         0.1                100   \n",
       "17              0.66                         0.1               1000   \n",
       "18              0.33                           0                 10   \n",
       "19              0.33                           0                100   \n",
       "20              0.33                           0               1000   \n",
       "21              0.33                        0.05                 10   \n",
       "22              0.33                        0.05                100   \n",
       "23              0.33                        0.05               1000   \n",
       "24              0.33                         0.1                 10   \n",
       "25              0.33                         0.1                100   \n",
       "26              0.33                         0.1               1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_samples': None, 'min_impurity_decrease':...          -0.191868   \n",
       "1   {'max_samples': None, 'min_impurity_decrease':...          -0.172405   \n",
       "2   {'max_samples': None, 'min_impurity_decrease':...          -0.175264   \n",
       "3   {'max_samples': None, 'min_impurity_decrease':...          -0.002492   \n",
       "4   {'max_samples': None, 'min_impurity_decrease':...          -0.004056   \n",
       "5   {'max_samples': None, 'min_impurity_decrease':...          -0.003915   \n",
       "6   {'max_samples': None, 'min_impurity_decrease':...          -0.003171   \n",
       "7   {'max_samples': None, 'min_impurity_decrease':...          -0.003424   \n",
       "8   {'max_samples': None, 'min_impurity_decrease':...          -0.003552   \n",
       "9   {'max_samples': 0.66, 'min_impurity_decrease':...          -0.147430   \n",
       "10  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.087335   \n",
       "11  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.080458   \n",
       "12  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.017331   \n",
       "13  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.004757   \n",
       "14  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.003623   \n",
       "15  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.000080   \n",
       "16  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.001483   \n",
       "17  {'max_samples': 0.66, 'min_impurity_decrease':...          -0.003040   \n",
       "18  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.014383   \n",
       "19  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.003129   \n",
       "20  {'max_samples': 0.33, 'min_impurity_decrease':...           0.025608   \n",
       "21  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.016289   \n",
       "22  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002697   \n",
       "23  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002908   \n",
       "24  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.000003   \n",
       "25  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.003269   \n",
       "26  {'max_samples': 0.33, 'min_impurity_decrease':...          -0.002146   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.123570          -0.003642        -0.023980        0.129578   \n",
       "1            0.237464          -0.087570        -0.007504        0.176647   \n",
       "2            0.244458           0.047710         0.038968        0.171462   \n",
       "3           -0.042341          -0.001537        -0.015456        0.019014   \n",
       "4           -0.045292          -0.002137        -0.017162        0.019906   \n",
       "5           -0.043457          -0.003548        -0.016973        0.018727   \n",
       "6           -0.031808          -0.009943        -0.014974        0.012220   \n",
       "7           -0.044216          -0.003939        -0.017193        0.019110   \n",
       "8           -0.044173          -0.003328        -0.017018        0.019202   \n",
       "9            0.214253           0.090318         0.052380        0.150073   \n",
       "10           0.230544           0.069623         0.070944        0.129777   \n",
       "11           0.231476           0.106391         0.085803        0.128176   \n",
       "12          -0.033199          -0.002576        -0.017702        0.012505   \n",
       "13          -0.047068          -0.002141        -0.017989        0.020590   \n",
       "14          -0.041279          -0.004030        -0.016311        0.017656   \n",
       "15          -0.019367          -0.004491        -0.007979        0.008251   \n",
       "16          -0.054096          -0.002905        -0.019495        0.024474   \n",
       "17          -0.042572          -0.003378        -0.016330        0.018556   \n",
       "18           0.159478           0.092331         0.079142        0.071588   \n",
       "19           0.205631           0.136995         0.113166        0.086876   \n",
       "20           0.207774           0.117453         0.116945        0.074370   \n",
       "21          -0.051224          -0.012140        -0.026551        0.017529   \n",
       "22          -0.046636          -0.006256        -0.018529        0.019927   \n",
       "23          -0.038644          -0.004844        -0.015466        0.016409   \n",
       "24          -0.052390          -0.045052        -0.032482        0.023160   \n",
       "25          -0.040353          -0.003022        -0.015548        0.017540   \n",
       "26          -0.045698          -0.003066        -0.016970        0.020317   \n",
       "\n",
       "    rank_test_score  \n",
       "0                25  \n",
       "1                 8  \n",
       "2                 7  \n",
       "3                11  \n",
       "4                19  \n",
       "5                17  \n",
       "6                10  \n",
       "7                20  \n",
       "8                18  \n",
       "9                 6  \n",
       "10                5  \n",
       "11                3  \n",
       "12               21  \n",
       "13               22  \n",
       "14               14  \n",
       "15                9  \n",
       "16               24  \n",
       "17               15  \n",
       "18                4  \n",
       "19                2  \n",
       "20                1  \n",
       "21               26  \n",
       "22               23  \n",
       "23               12  \n",
       "24               27  \n",
       "25               13  \n",
       "26               16  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs1b.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.565859</td>\n",
       "      <td>0.570668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.148285</td>\n",
       "      <td>0.145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.073736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056166</td>\n",
       "      <td>0.055663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.565859   0.570668\n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.148285   0.145455\n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073614   0.073736\n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056166   0.055663"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like MSE and MAE is fairly close. Probably means that the MSE isn't being impacted as heavily by the outliers as I feared. So I think I can keep going with MSE as my criteron. Interestingly, in both cases, using a max_samples of 0.33 worked best. I'm thinking this may help with overfitting. Also, more estimators seem to help, not fewer. Playing with the impurity decrease did not help at all. I may do one more grid search looking at some more estimators and switch to max_depth instead of min_impurity_decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf2 = {\n",
    "    'n_estimators': [1000, 10_000],\n",
    "    'max_samples': [0.33, 0.15],\n",
    "    'max_depth': [5, 10, 20, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs1c = GridSearchCV(estimator=model1a, param_grid=params_rf2, cv=kf, n_jobs=-1)\n",
    "fit_model(gs1c, 'GS_RF_MSE2')\n",
    "plt.scatter(y_test, gs1c.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.657178</td>\n",
       "      <td>0.029330</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'max_samples': 0.33, 'n_estim...</td>\n",
       "      <td>0.037163</td>\n",
       "      <td>0.225910</td>\n",
       "      <td>0.079284</td>\n",
       "      <td>0.114119</td>\n",
       "      <td>0.080897</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.138446</td>\n",
       "      <td>0.336798</td>\n",
       "      <td>0.864333</td>\n",
       "      <td>0.105838</td>\n",
       "      <td>5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 5, 'max_samples': 0.33, 'n_estim...</td>\n",
       "      <td>0.041110</td>\n",
       "      <td>0.225248</td>\n",
       "      <td>0.092164</td>\n",
       "      <td>0.119507</td>\n",
       "      <td>0.077620</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.567511</td>\n",
       "      <td>0.076893</td>\n",
       "      <td>0.082335</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'max_samples': 0.15, 'n_estim...</td>\n",
       "      <td>0.091639</td>\n",
       "      <td>0.207624</td>\n",
       "      <td>0.129992</td>\n",
       "      <td>0.143085</td>\n",
       "      <td>0.048247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.031934</td>\n",
       "      <td>0.492153</td>\n",
       "      <td>0.867334</td>\n",
       "      <td>0.098008</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 5, 'max_samples': 0.15, 'n_estim...</td>\n",
       "      <td>0.086767</td>\n",
       "      <td>0.204736</td>\n",
       "      <td>0.113861</td>\n",
       "      <td>0.135122</td>\n",
       "      <td>0.050452</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.701352</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.083516</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>10</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.037638</td>\n",
       "      <td>0.233883</td>\n",
       "      <td>0.096064</td>\n",
       "      <td>0.122528</td>\n",
       "      <td>0.082273</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.108962</td>\n",
       "      <td>0.439888</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>0.057249</td>\n",
       "      <td>10</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 10, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.036841</td>\n",
       "      <td>0.226217</td>\n",
       "      <td>0.105131</td>\n",
       "      <td>0.122730</td>\n",
       "      <td>0.078308</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.604998</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>0.089667</td>\n",
       "      <td>0.010143</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 10, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.089391</td>\n",
       "      <td>0.206397</td>\n",
       "      <td>0.138860</td>\n",
       "      <td>0.144883</td>\n",
       "      <td>0.047957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.197398</td>\n",
       "      <td>0.571655</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.059201</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 10, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.085704</td>\n",
       "      <td>0.209623</td>\n",
       "      <td>0.117109</td>\n",
       "      <td>0.137479</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.717357</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.080667</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 20, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>0.223598</td>\n",
       "      <td>0.091504</td>\n",
       "      <td>0.120217</td>\n",
       "      <td>0.075470</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.852096</td>\n",
       "      <td>0.357074</td>\n",
       "      <td>0.837019</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 20, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.039036</td>\n",
       "      <td>0.224793</td>\n",
       "      <td>0.110535</td>\n",
       "      <td>0.124788</td>\n",
       "      <td>0.076502</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.738666</td>\n",
       "      <td>0.133562</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 20, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.080204</td>\n",
       "      <td>0.199343</td>\n",
       "      <td>0.115407</td>\n",
       "      <td>0.131652</td>\n",
       "      <td>0.049976</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.637964</td>\n",
       "      <td>0.474878</td>\n",
       "      <td>0.776870</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 20, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.085709</td>\n",
       "      <td>0.205680</td>\n",
       "      <td>0.117353</td>\n",
       "      <td>0.136247</td>\n",
       "      <td>0.050768</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.030377</td>\n",
       "      <td>0.102199</td>\n",
       "      <td>0.091333</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.034446</td>\n",
       "      <td>0.224963</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>0.125177</td>\n",
       "      <td>0.078041</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.982842</td>\n",
       "      <td>0.398032</td>\n",
       "      <td>0.593172</td>\n",
       "      <td>0.069987</td>\n",
       "      <td>50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 50, 'max_samples': 0.33, 'n_esti...</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>0.222129</td>\n",
       "      <td>0.106119</td>\n",
       "      <td>0.122625</td>\n",
       "      <td>0.075415</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.582090</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>0.087679</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.083208</td>\n",
       "      <td>0.210875</td>\n",
       "      <td>0.105333</td>\n",
       "      <td>0.133139</td>\n",
       "      <td>0.055705</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.857339</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>0.462334</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_depth': 50, 'max_samples': 0.15, 'n_esti...</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>0.214135</td>\n",
       "      <td>0.122251</td>\n",
       "      <td>0.140170</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.657178      0.029330         0.084000        0.005888   \n",
       "1       17.138446      0.336798         0.864333        0.105838   \n",
       "2        1.567511      0.076893         0.082335        0.003400   \n",
       "3       16.031934      0.492153         0.867334        0.098008   \n",
       "4        1.701352      0.008884         0.083516        0.003929   \n",
       "5       18.108962      0.439888         0.878667        0.057249   \n",
       "6        1.604998      0.017455         0.089667        0.010143   \n",
       "7       17.197398      0.571655         0.900667        0.059201   \n",
       "8        1.717357      0.005423         0.080667        0.000942   \n",
       "9       17.852096      0.357074         0.837019        0.003564   \n",
       "10       1.738666      0.133562         0.096667        0.009877   \n",
       "11      16.637964      0.474878         0.776870        0.079400   \n",
       "12       2.030377      0.102199         0.091333        0.015326   \n",
       "13      16.982842      0.398032         0.593172        0.069987   \n",
       "14       1.582090      0.016259         0.087679        0.003286   \n",
       "15      13.857339      0.332912         0.462334        0.012660   \n",
       "\n",
       "   param_max_depth param_max_samples param_n_estimators  \\\n",
       "0                5              0.33               1000   \n",
       "1                5              0.33              10000   \n",
       "2                5              0.15               1000   \n",
       "3                5              0.15              10000   \n",
       "4               10              0.33               1000   \n",
       "5               10              0.33              10000   \n",
       "6               10              0.15               1000   \n",
       "7               10              0.15              10000   \n",
       "8               20              0.33               1000   \n",
       "9               20              0.33              10000   \n",
       "10              20              0.15               1000   \n",
       "11              20              0.15              10000   \n",
       "12              50              0.33               1000   \n",
       "13              50              0.33              10000   \n",
       "14              50              0.15               1000   \n",
       "15              50              0.15              10000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_depth': 5, 'max_samples': 0.33, 'n_estim...           0.037163   \n",
       "1   {'max_depth': 5, 'max_samples': 0.33, 'n_estim...           0.041110   \n",
       "2   {'max_depth': 5, 'max_samples': 0.15, 'n_estim...           0.091639   \n",
       "3   {'max_depth': 5, 'max_samples': 0.15, 'n_estim...           0.086767   \n",
       "4   {'max_depth': 10, 'max_samples': 0.33, 'n_esti...           0.037638   \n",
       "5   {'max_depth': 10, 'max_samples': 0.33, 'n_esti...           0.036841   \n",
       "6   {'max_depth': 10, 'max_samples': 0.15, 'n_esti...           0.089391   \n",
       "7   {'max_depth': 10, 'max_samples': 0.15, 'n_esti...           0.085704   \n",
       "8   {'max_depth': 20, 'max_samples': 0.33, 'n_esti...           0.045549   \n",
       "9   {'max_depth': 20, 'max_samples': 0.33, 'n_esti...           0.039036   \n",
       "10  {'max_depth': 20, 'max_samples': 0.15, 'n_esti...           0.080204   \n",
       "11  {'max_depth': 20, 'max_samples': 0.15, 'n_esti...           0.085709   \n",
       "12  {'max_depth': 50, 'max_samples': 0.33, 'n_esti...           0.034446   \n",
       "13  {'max_depth': 50, 'max_samples': 0.33, 'n_esti...           0.039626   \n",
       "14  {'max_depth': 50, 'max_samples': 0.15, 'n_esti...           0.083208   \n",
       "15  {'max_depth': 50, 'max_samples': 0.15, 'n_esti...           0.084125   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.225910           0.079284         0.114119        0.080897   \n",
       "1            0.225248           0.092164         0.119507        0.077620   \n",
       "2            0.207624           0.129992         0.143085        0.048247   \n",
       "3            0.204736           0.113861         0.135122        0.050452   \n",
       "4            0.233883           0.096064         0.122528        0.082273   \n",
       "5            0.226217           0.105131         0.122730        0.078308   \n",
       "6            0.206397           0.138860         0.144883        0.047957   \n",
       "7            0.209623           0.117109         0.137479        0.052600   \n",
       "8            0.223598           0.091504         0.120217        0.075470   \n",
       "9            0.224793           0.110535         0.124788        0.076502   \n",
       "10           0.199343           0.115407         0.131652        0.049976   \n",
       "11           0.205680           0.117353         0.136247        0.050768   \n",
       "12           0.224963           0.116123         0.125177        0.078041   \n",
       "13           0.222129           0.106119         0.122625        0.075415   \n",
       "14           0.210875           0.105333         0.133139        0.055705   \n",
       "15           0.214135           0.122251         0.140170        0.054568   \n",
       "\n",
       "    rank_test_score  \n",
       "0                16  \n",
       "1                15  \n",
       "2                 2  \n",
       "3                 6  \n",
       "4                13  \n",
       "5                11  \n",
       "6                 1  \n",
       "7                 4  \n",
       "8                14  \n",
       "9                10  \n",
       "10                8  \n",
       "11                5  \n",
       "12                9  \n",
       "13               12  \n",
       "14                7  \n",
       "15                3  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs1c.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "      <th>GS_RF_MSE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.565859</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.387818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.148285</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.132343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.074299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056166</td>\n",
       "      <td>0.055663</td>\n",
       "      <td>0.056118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE  \\\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.565859   0.570668   \n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.148285   0.145455   \n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073614   0.073736   \n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056166   0.055663   \n",
       "\n",
       "             GS_RF_MSE2  \n",
       "score_train    0.387818  \n",
       "score_test     0.132343  \n",
       "rmse           0.074299  \n",
       "mae            0.056118  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, so n_estimator truly seems best at 1000, however max_sample did even better at 0.15 which just seem crazy low. Max_depth did best at 10. However, I will say, most of these scores are really close to each other, unlike the previous gridsearch, so I think I'm reaching a capping point. I'm going to run a randomforest with my optimized parameters to see how it does on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12851265748650254"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1c = RandomForestRegressor(n_estimators= 1000, max_samples=0.33, max_depth=10, random_state=8)\n",
    "fit_model(model1c, 'rfr_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_op_coefs = np.mean([\n",
    "    tree.feature_importances_ for tree in model1c.estimators_\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "      <th>GS_RF_MSE2</th>\n",
       "      <th>rfr_op</th>\n",
       "      <th>GS_bagging</th>\n",
       "      <th>bagging_op</th>\n",
       "      <th>GS_boosting</th>\n",
       "      <th>boosting_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.565859</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.575200</td>\n",
       "      <td>0.558013</td>\n",
       "      <td>0.576620</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.898064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.148285</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.132343</td>\n",
       "      <td>0.128513</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.139168</td>\n",
       "      <td>0.085775</td>\n",
       "      <td>-0.076738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.074299</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.073488</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>0.076267</td>\n",
       "      <td>0.082769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056166</td>\n",
       "      <td>0.055663</td>\n",
       "      <td>0.056118</td>\n",
       "      <td>0.056970</td>\n",
       "      <td>0.055929</td>\n",
       "      <td>0.055768</td>\n",
       "      <td>0.059735</td>\n",
       "      <td>0.059563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE  \\\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.565859   0.570668   \n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.148285   0.145455   \n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073614   0.073736   \n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056166   0.055663   \n",
       "\n",
       "             GS_RF_MSE2    rfr_op  GS_bagging  bagging_op  GS_boosting  \\\n",
       "score_train    0.387818  0.575200    0.558013    0.576620     0.495300   \n",
       "score_test     0.132343  0.128513    0.151202    0.139168     0.085775   \n",
       "rmse           0.074299  0.074463    0.073488    0.074007     0.076267   \n",
       "mae            0.056118  0.056970    0.055929    0.055768     0.059735   \n",
       "\n",
       "             boosting_op  \n",
       "score_train     0.898064  \n",
       "score_test     -0.076738  \n",
       "rmse            0.082769  \n",
       "mae             0.059563  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "[Hyperparameters of interest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor):\n",
    "* **n_estimators** -- how many weak estimators\n",
    "* **max_samples** -- max samples drawn\n",
    "* **max_features** -- how many samples to look at\n",
    "* **bootstrap_features** -- this one is new, I can bootstrap the features, not just the datapoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_bagging = {\n",
    "    'n_estimators': [100,1000],\n",
    "    'max_samples': [1.0, 0.66, 0.33],\n",
    "    'max_features': [1.0, 0.75, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle = True, random_state= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BaggingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs2 = GridSearchCV(estimator=model2, param_grid=params_bagging, cv=kf, n_jobs=-1)\n",
    "fit_model(gs2, 'GS_bagging')\n",
    "plt.scatter(y_test, gs2.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.255666</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>4.705286e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 1.0, 'max_samples': 1.0, 'n_e...</td>\n",
       "      <td>-0.056237</td>\n",
       "      <td>0.249624</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.132244</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.488695</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.109001</td>\n",
       "      <td>1.633361e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 1.0, 'max_samples': 1.0, 'n_e...</td>\n",
       "      <td>-0.085858</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.029429</td>\n",
       "      <td>0.055549</td>\n",
       "      <td>0.127468</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261343</td>\n",
       "      <td>0.020026</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>7.867412e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 1.0, 'max_samples': 0.66, 'n_...</td>\n",
       "      <td>-0.092596</td>\n",
       "      <td>0.239645</td>\n",
       "      <td>0.035098</td>\n",
       "      <td>0.060716</td>\n",
       "      <td>0.136841</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.355030</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>1.247171e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 1.0, 'max_samples': 0.66, 'n_...</td>\n",
       "      <td>-0.031539</td>\n",
       "      <td>0.230011</td>\n",
       "      <td>0.068481</td>\n",
       "      <td>0.088984</td>\n",
       "      <td>0.107757</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214344</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>4.718200e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 1.0, 'max_samples': 0.33, 'n_...</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.249976</td>\n",
       "      <td>0.145035</td>\n",
       "      <td>0.141213</td>\n",
       "      <td>0.090406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.100677</td>\n",
       "      <td>0.048297</td>\n",
       "      <td>0.110344</td>\n",
       "      <td>1.710807e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 1.0, 'max_samples': 0.33, 'n_...</td>\n",
       "      <td>0.033489</td>\n",
       "      <td>0.230970</td>\n",
       "      <td>0.106835</td>\n",
       "      <td>0.123765</td>\n",
       "      <td>0.081505</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.240999</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>4.715953e-04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.75, 'max_samples': 1.0, 'n_...</td>\n",
       "      <td>-0.014423</td>\n",
       "      <td>0.213370</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.071198</td>\n",
       "      <td>0.101229</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.369537</td>\n",
       "      <td>0.028903</td>\n",
       "      <td>0.105505</td>\n",
       "      <td>2.670668e-03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 0.75, 'max_samples': 1.0, 'n_...</td>\n",
       "      <td>-0.008225</td>\n",
       "      <td>0.223374</td>\n",
       "      <td>0.027914</td>\n",
       "      <td>0.081021</td>\n",
       "      <td>0.101734</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.223032</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>0.012667</td>\n",
       "      <td>4.717075e-04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.75, 'max_samples': 0.66, 'n...</td>\n",
       "      <td>-0.006490</td>\n",
       "      <td>0.241157</td>\n",
       "      <td>-0.020287</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.120126</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.242848</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.115668</td>\n",
       "      <td>1.366974e-02</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 0.75, 'max_samples': 0.66, 'n...</td>\n",
       "      <td>0.024079</td>\n",
       "      <td>0.205347</td>\n",
       "      <td>0.066311</td>\n",
       "      <td>0.098579</td>\n",
       "      <td>0.077440</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.206666</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.013667</td>\n",
       "      <td>9.418416e-04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.33</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.75, 'max_samples': 0.33, 'n...</td>\n",
       "      <td>0.074415</td>\n",
       "      <td>0.252333</td>\n",
       "      <td>-0.026320</td>\n",
       "      <td>0.100143</td>\n",
       "      <td>0.115205</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.045858</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>2.018050e-03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 0.75, 'max_samples': 0.33, 'n...</td>\n",
       "      <td>0.081475</td>\n",
       "      <td>0.213882</td>\n",
       "      <td>0.115994</td>\n",
       "      <td>0.137117</td>\n",
       "      <td>0.056081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.244665</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>0.014668</td>\n",
       "      <td>4.712583e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.5, 'max_samples': 1.0, 'n_e...</td>\n",
       "      <td>0.043204</td>\n",
       "      <td>0.195564</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>0.070284</td>\n",
       "      <td>0.093223</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.278028</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.101667</td>\n",
       "      <td>1.247108e-03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 0.5, 'max_samples': 1.0, 'n_e...</td>\n",
       "      <td>0.047443</td>\n",
       "      <td>0.193682</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.088911</td>\n",
       "      <td>0.074618</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.226170</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.66</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.5, 'max_samples': 0.66, 'n_...</td>\n",
       "      <td>0.019706</td>\n",
       "      <td>0.217953</td>\n",
       "      <td>0.032199</td>\n",
       "      <td>0.089953</td>\n",
       "      <td>0.090653</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.053685</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>4.966995e-03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 0.5, 'max_samples': 0.66, 'n_...</td>\n",
       "      <td>0.058385</td>\n",
       "      <td>0.185981</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>0.107232</td>\n",
       "      <td>0.056219</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.199000</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>6.836514e-07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.5, 'max_samples': 0.33, 'n_...</td>\n",
       "      <td>0.083867</td>\n",
       "      <td>0.169684</td>\n",
       "      <td>0.104848</td>\n",
       "      <td>0.119466</td>\n",
       "      <td>0.036528</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.339506</td>\n",
       "      <td>0.105366</td>\n",
       "      <td>0.057001</td>\n",
       "      <td>8.165354e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_features': 0.5, 'max_samples': 0.33, 'n_...</td>\n",
       "      <td>0.070601</td>\n",
       "      <td>0.167632</td>\n",
       "      <td>0.079673</td>\n",
       "      <td>0.105969</td>\n",
       "      <td>0.043759</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.255666      0.008180         0.013666    4.705286e-04   \n",
       "1        2.488695      0.005558         0.109001    1.633361e-03   \n",
       "2        0.261343      0.020026         0.013000    7.867412e-07   \n",
       "3        2.355030      0.015122         0.106667    1.247171e-03   \n",
       "4        0.214344      0.004774         0.013333    4.718200e-04   \n",
       "5        2.100677      0.048297         0.110344    1.710807e-03   \n",
       "6        0.240999      0.008602         0.012667    4.715953e-04   \n",
       "7        2.369537      0.028903         0.105505    2.670668e-03   \n",
       "8        0.223032      0.004321         0.012667    4.717075e-04   \n",
       "9        2.242848      0.019738         0.115668    1.366974e-02   \n",
       "10       0.206666      0.002054         0.013667    9.418416e-04   \n",
       "11       2.045858      0.014103         0.100677    2.018050e-03   \n",
       "12       0.244665      0.011954         0.014668    4.712583e-04   \n",
       "13       2.278028      0.009933         0.101667    1.247108e-03   \n",
       "14       0.226170      0.012393         0.013000    1.946680e-07   \n",
       "15       2.053685      0.025568         0.088000    4.966995e-03   \n",
       "16       0.199000      0.001414         0.013001    6.836514e-07   \n",
       "17       1.339506      0.105366         0.057001    8.165354e-04   \n",
       "\n",
       "   param_max_features param_max_samples param_n_estimators  \\\n",
       "0                   1                 1                100   \n",
       "1                   1                 1               1000   \n",
       "2                   1              0.66                100   \n",
       "3                   1              0.66               1000   \n",
       "4                   1              0.33                100   \n",
       "5                   1              0.33               1000   \n",
       "6                0.75                 1                100   \n",
       "7                0.75                 1               1000   \n",
       "8                0.75              0.66                100   \n",
       "9                0.75              0.66               1000   \n",
       "10               0.75              0.33                100   \n",
       "11               0.75              0.33               1000   \n",
       "12                0.5                 1                100   \n",
       "13                0.5                 1               1000   \n",
       "14                0.5              0.66                100   \n",
       "15                0.5              0.66               1000   \n",
       "16                0.5              0.33                100   \n",
       "17                0.5              0.33               1000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_features': 1.0, 'max_samples': 1.0, 'n_e...          -0.056237   \n",
       "1   {'max_features': 1.0, 'max_samples': 1.0, 'n_e...          -0.085858   \n",
       "2   {'max_features': 1.0, 'max_samples': 0.66, 'n_...          -0.092596   \n",
       "3   {'max_features': 1.0, 'max_samples': 0.66, 'n_...          -0.031539   \n",
       "4   {'max_features': 1.0, 'max_samples': 0.33, 'n_...           0.028627   \n",
       "5   {'max_features': 1.0, 'max_samples': 0.33, 'n_...           0.033489   \n",
       "6   {'max_features': 0.75, 'max_samples': 1.0, 'n_...          -0.014423   \n",
       "7   {'max_features': 0.75, 'max_samples': 1.0, 'n_...          -0.008225   \n",
       "8   {'max_features': 0.75, 'max_samples': 0.66, 'n...          -0.006490   \n",
       "9   {'max_features': 0.75, 'max_samples': 0.66, 'n...           0.024079   \n",
       "10  {'max_features': 0.75, 'max_samples': 0.33, 'n...           0.074415   \n",
       "11  {'max_features': 0.75, 'max_samples': 0.33, 'n...           0.081475   \n",
       "12  {'max_features': 0.5, 'max_samples': 1.0, 'n_e...           0.043204   \n",
       "13  {'max_features': 0.5, 'max_samples': 1.0, 'n_e...           0.047443   \n",
       "14  {'max_features': 0.5, 'max_samples': 0.66, 'n_...           0.019706   \n",
       "15  {'max_features': 0.5, 'max_samples': 0.66, 'n_...           0.058385   \n",
       "16  {'max_features': 0.5, 'max_samples': 0.33, 'n_...           0.083867   \n",
       "17  {'max_features': 0.5, 'max_samples': 0.33, 'n_...           0.070601   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.249624           0.004311         0.065900        0.132244   \n",
       "1            0.223077           0.029429         0.055549        0.127468   \n",
       "2            0.239645           0.035098         0.060716        0.136841   \n",
       "3            0.230011           0.068481         0.088984        0.107757   \n",
       "4            0.249976           0.145035         0.141213        0.090406   \n",
       "5            0.230970           0.106835         0.123765        0.081505   \n",
       "6            0.213370           0.014648         0.071198        0.101229   \n",
       "7            0.223374           0.027914         0.081021        0.101734   \n",
       "8            0.241157          -0.020287         0.071460        0.120126   \n",
       "9            0.205347           0.066311         0.098579        0.077440   \n",
       "10           0.252333          -0.026320         0.100143        0.115205   \n",
       "11           0.213882           0.115994         0.137117        0.056081   \n",
       "12           0.195564          -0.027916         0.070284        0.093223   \n",
       "13           0.193682           0.025608         0.088911        0.074618   \n",
       "14           0.217953           0.032199         0.089953        0.090653   \n",
       "15           0.185981           0.077330         0.107232        0.056219   \n",
       "16           0.169684           0.104848         0.119466        0.036528   \n",
       "17           0.167632           0.079673         0.105969        0.043759   \n",
       "\n",
       "    rank_test_score  \n",
       "0                16  \n",
       "1                18  \n",
       "2                17  \n",
       "3                10  \n",
       "4                 1  \n",
       "5                 3  \n",
       "6                14  \n",
       "7                12  \n",
       "8                13  \n",
       "9                 8  \n",
       "10                7  \n",
       "11                2  \n",
       "12               15  \n",
       "13               11  \n",
       "14                9  \n",
       "15                5  \n",
       "16                4  \n",
       "17                6  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "      <th>GS_RF_MSE2</th>\n",
       "      <th>rfr_op</th>\n",
       "      <th>GS_bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.565859</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.863646</td>\n",
       "      <td>0.558013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.148285</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.132343</td>\n",
       "      <td>0.110499</td>\n",
       "      <td>0.151202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.074299</td>\n",
       "      <td>0.075229</td>\n",
       "      <td>0.073488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056166</td>\n",
       "      <td>0.055663</td>\n",
       "      <td>0.056118</td>\n",
       "      <td>0.057204</td>\n",
       "      <td>0.055929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE  \\\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.565859   0.570668   \n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.148285   0.145455   \n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073614   0.073736   \n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056166   0.055663   \n",
       "\n",
       "             GS_RF_MSE2    rfr_op  GS_bagging  \n",
       "score_train    0.387818  0.863646    0.558013  \n",
       "score_test     0.132343  0.110499    0.151202  \n",
       "rmse           0.074299  0.075229    0.073488  \n",
       "mae            0.056118  0.057204    0.055929  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13916781420289093"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = BaggingRegressor(n_estimators= 1000, max_samples = 0.33, max_features = 0.75, random_state=8)\n",
    "fit_model(model2, 'bagging_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.020667\n",
       "1     0.019627\n",
       "2     0.059818\n",
       "3     0.069137\n",
       "4     0.012762\n",
       "5     0.196072\n",
       "6     0.025529\n",
       "7     0.003114\n",
       "8     0.000000\n",
       "9     0.021775\n",
       "10    0.005297\n",
       "11    0.017265\n",
       "12    0.021790\n",
       "13    0.024686\n",
       "14    0.000326\n",
       "15    0.000463\n",
       "16    0.010161\n",
       "17    0.011320\n",
       "18    0.008735\n",
       "19    0.027460\n",
       "20    0.020610\n",
       "21    0.018835\n",
       "22    0.247902\n",
       "23    0.024390\n",
       "24    0.006053\n",
       "25    0.006289\n",
       "26    0.002002\n",
       "27    0.200968\n",
       "28    0.009149\n",
       "29    0.012732\n",
       "30    0.019497\n",
       "31    0.011505\n",
       "32    0.019770\n",
       "33    0.025009\n",
       "34    0.012167\n",
       "35    0.019705\n",
       "36    0.017151\n",
       "37    0.013136\n",
       "38    0.026812\n",
       "39    0.014506\n",
       "40    0.013819\n",
       "41    0.027307\n",
       "42    0.022013\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_trees_coefs = {}\n",
    "for tree in range(len(model2.estimators_)):\n",
    "    bagging_trees_coefs[tree] = dict(zip(model2.estimators_features_[tree], model2.estimators_[tree].feature_importances_))\n",
    "\n",
    "bagging_trees_coefs = pd.DataFrame(bagging_trees_coefs).sort_index()\n",
    "bagging_op_coefs = bagging_trees_coefs.mean(axis=1)\n",
    "bagging_op_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model2.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.28103005e-03, 3.92736265e-04, 3.58212094e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 8.97070707e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.52266827e-02, 5.05889365e-01, 5.25996672e-05, 2.23225452e-02,\n",
       "       7.83086453e-03, 0.00000000e+00, 3.69832577e-04, 1.44495259e-02,\n",
       "       1.86197297e-02, 0.00000000e+00, 5.19575659e-07, 2.04977208e-04,\n",
       "       9.66667830e-03, 3.17371675e-05, 2.68303563e-02, 9.77954305e-05,\n",
       "       7.44960774e-03, 0.00000000e+00, 0.00000000e+00, 2.08091182e-01,\n",
       "       0.00000000e+00, 1.19034953e-02, 7.60459110e-04, 0.00000000e+00])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.estimators_[0].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "      <th>GS_RF_MSE2</th>\n",
       "      <th>rfr_op</th>\n",
       "      <th>GS_bagging</th>\n",
       "      <th>bagging_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.565859</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.863646</td>\n",
       "      <td>0.558013</td>\n",
       "      <td>0.576620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.148285</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.132343</td>\n",
       "      <td>0.110499</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.139168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.074299</td>\n",
       "      <td>0.075229</td>\n",
       "      <td>0.073488</td>\n",
       "      <td>0.074007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056166</td>\n",
       "      <td>0.055663</td>\n",
       "      <td>0.056118</td>\n",
       "      <td>0.057204</td>\n",
       "      <td>0.055929</td>\n",
       "      <td>0.055768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE  \\\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.565859   0.570668   \n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.148285   0.145455   \n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073614   0.073736   \n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056166   0.055663   \n",
       "\n",
       "             GS_RF_MSE2    rfr_op  GS_bagging  bagging_op  \n",
       "score_train    0.387818  0.863646    0.558013    0.576620  \n",
       "score_test     0.132343  0.110499    0.151202    0.139168  \n",
       "rmse           0.074299  0.075229    0.073488    0.074007  \n",
       "mae            0.056118  0.057204    0.055929    0.055768  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "[Hyperparameters of interest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor):\n",
    "* **learning_rate**, default=0.1 -- According to the docs, \"Learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators.\"\n",
    "* **n_estimators** -- how many weak estimators\n",
    "* **subsample** -- subs samples to be drawn for fitting (sort of like max_samples)\n",
    "* **max_depth** -- default is three but this is a recommended feature to play with\n",
    "* **min_impurity_decrease** --\n",
    "\n",
    "things to try outside of gs\n",
    "* **n_iter_no_change**\n",
    "* **validation_fraction**\n",
    "* **tol**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_boosting = {\n",
    "     'n_estimators': [100, 1000],\n",
    "     'subsample': [1.0, 0.66, 0.33],\n",
    "     'max_depth': [3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle = True, random_state= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = GradientBoostingRegressor(loss='lad', random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs3 = GridSearchCV(estimator=model3, param_grid=params_boosting, cv=kf, n_jobs=-1)\n",
    "fit_model(gs3, 'GS_boosting')\n",
    "plt.scatter(y_test, gs3.predict(X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.173666</td>\n",
       "      <td>0.025720</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.030086e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100, 'subsamp...</td>\n",
       "      <td>-0.090242</td>\n",
       "      <td>0.251848</td>\n",
       "      <td>0.193882</td>\n",
       "      <td>0.118496</td>\n",
       "      <td>0.149485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187666</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>7.018853e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.66</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100, 'subsamp...</td>\n",
       "      <td>-0.024714</td>\n",
       "      <td>0.271463</td>\n",
       "      <td>0.099161</td>\n",
       "      <td>0.115303</td>\n",
       "      <td>0.121452</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.026869</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>8.778064e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.33</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100, 'subsamp...</td>\n",
       "      <td>-0.041983</td>\n",
       "      <td>0.166778</td>\n",
       "      <td>0.229993</td>\n",
       "      <td>0.118263</td>\n",
       "      <td>0.116212</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.341997</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>4.715390e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 1000, 'subsam...</td>\n",
       "      <td>-0.166516</td>\n",
       "      <td>0.251773</td>\n",
       "      <td>0.207335</td>\n",
       "      <td>0.097531</td>\n",
       "      <td>0.187588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.404332</td>\n",
       "      <td>0.044034</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>4.709770e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 1000, 'subsam...</td>\n",
       "      <td>-0.145554</td>\n",
       "      <td>0.169262</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.128932</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.250333</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>4.716514e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 1000, 'subsam...</td>\n",
       "      <td>-0.201139</td>\n",
       "      <td>0.151232</td>\n",
       "      <td>-0.167665</td>\n",
       "      <td>-0.072524</td>\n",
       "      <td>0.158809</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.262665</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>7.370010e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100, 'subsamp...</td>\n",
       "      <td>-0.052407</td>\n",
       "      <td>0.256593</td>\n",
       "      <td>0.106698</td>\n",
       "      <td>0.103628</td>\n",
       "      <td>0.126168</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.243999</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>4.715953e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.66</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100, 'subsamp...</td>\n",
       "      <td>-0.163828</td>\n",
       "      <td>0.172571</td>\n",
       "      <td>0.093069</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.143558</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.183666</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.33</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100, 'subsamp...</td>\n",
       "      <td>-0.077815</td>\n",
       "      <td>0.133411</td>\n",
       "      <td>0.090785</td>\n",
       "      <td>0.048794</td>\n",
       "      <td>0.091201</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.000096</td>\n",
       "      <td>0.351993</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>9.425160e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000, 'subsam...</td>\n",
       "      <td>-0.103319</td>\n",
       "      <td>0.221320</td>\n",
       "      <td>0.022204</td>\n",
       "      <td>0.046735</td>\n",
       "      <td>0.133664</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.912764</td>\n",
       "      <td>0.327426</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>8.169241e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000, 'subsam...</td>\n",
       "      <td>-0.252853</td>\n",
       "      <td>0.132741</td>\n",
       "      <td>-0.072221</td>\n",
       "      <td>-0.064111</td>\n",
       "      <td>0.157523</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.703031</td>\n",
       "      <td>0.059335</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>8.259637e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000, 'subsam...</td>\n",
       "      <td>-0.157730</td>\n",
       "      <td>0.058802</td>\n",
       "      <td>-0.233649</td>\n",
       "      <td>-0.110859</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.173666      0.025720         0.003000    1.030086e-06   \n",
       "1        0.187666      0.003399         0.003000    7.018853e-07   \n",
       "2        0.161000      0.026869         0.003000    8.778064e-07   \n",
       "3        1.341997      0.019816         0.004333    4.715390e-04   \n",
       "4        1.404332      0.044034         0.004334    4.709770e-04   \n",
       "5        1.250333      0.020072         0.004333    4.716514e-04   \n",
       "6        0.262665      0.004028         0.003001    7.370010e-07   \n",
       "7        0.243999      0.005353         0.002667    4.715953e-04   \n",
       "8        0.183666      0.004643         0.003000    2.973602e-07   \n",
       "9        2.000096      0.351993         0.004333    9.425160e-04   \n",
       "10       1.912764      0.327426         0.004000    8.169241e-04   \n",
       "11       1.703031      0.059335         0.010333    8.259637e-03   \n",
       "\n",
       "   param_max_depth param_n_estimators param_subsample  \\\n",
       "0                3                100               1   \n",
       "1                3                100            0.66   \n",
       "2                3                100            0.33   \n",
       "3                3               1000               1   \n",
       "4                3               1000            0.66   \n",
       "5                3               1000            0.33   \n",
       "6                5                100               1   \n",
       "7                5                100            0.66   \n",
       "8                5                100            0.33   \n",
       "9                5               1000               1   \n",
       "10               5               1000            0.66   \n",
       "11               5               1000            0.33   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_depth': 3, 'n_estimators': 100, 'subsamp...          -0.090242   \n",
       "1   {'max_depth': 3, 'n_estimators': 100, 'subsamp...          -0.024714   \n",
       "2   {'max_depth': 3, 'n_estimators': 100, 'subsamp...          -0.041983   \n",
       "3   {'max_depth': 3, 'n_estimators': 1000, 'subsam...          -0.166516   \n",
       "4   {'max_depth': 3, 'n_estimators': 1000, 'subsam...          -0.145554   \n",
       "5   {'max_depth': 3, 'n_estimators': 1000, 'subsam...          -0.201139   \n",
       "6   {'max_depth': 5, 'n_estimators': 100, 'subsamp...          -0.052407   \n",
       "7   {'max_depth': 5, 'n_estimators': 100, 'subsamp...          -0.163828   \n",
       "8   {'max_depth': 5, 'n_estimators': 100, 'subsamp...          -0.077815   \n",
       "9   {'max_depth': 5, 'n_estimators': 1000, 'subsam...          -0.103319   \n",
       "10  {'max_depth': 5, 'n_estimators': 1000, 'subsam...          -0.252853   \n",
       "11  {'max_depth': 5, 'n_estimators': 1000, 'subsam...          -0.157730   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.251848           0.193882         0.118496        0.149485   \n",
       "1            0.271463           0.099161         0.115303        0.121452   \n",
       "2            0.166778           0.229993         0.118263        0.116212   \n",
       "3            0.251773           0.207335         0.097531        0.187588   \n",
       "4            0.169262          -0.009901         0.004603        0.128932   \n",
       "5            0.151232          -0.167665        -0.072524        0.158809   \n",
       "6            0.256593           0.106698         0.103628        0.126168   \n",
       "7            0.172571           0.093069         0.033937        0.143558   \n",
       "8            0.133411           0.090785         0.048794        0.091201   \n",
       "9            0.221320           0.022204         0.046735        0.133664   \n",
       "10           0.132741          -0.072221        -0.064111        0.157523   \n",
       "11           0.058802          -0.233649        -0.110859        0.123907   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 2  \n",
       "3                 5  \n",
       "4                 9  \n",
       "5                11  \n",
       "6                 4  \n",
       "7                 8  \n",
       "8                 6  \n",
       "9                 7  \n",
       "10               10  \n",
       "11               12  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs3.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>RFR</th>\n",
       "      <th>bagging</th>\n",
       "      <th>GradBoost</th>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <th>GS_RF_MAE</th>\n",
       "      <th>GS_RF_MSE2</th>\n",
       "      <th>rfr_op</th>\n",
       "      <th>GS_bagging</th>\n",
       "      <th>bagging_op</th>\n",
       "      <th>GS_boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score_train</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.565859</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.863646</td>\n",
       "      <td>0.558013</td>\n",
       "      <td>0.576620</td>\n",
       "      <td>0.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_test</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.148285</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.132343</td>\n",
       "      <td>0.110499</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.139168</td>\n",
       "      <td>0.085775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.074299</td>\n",
       "      <td>0.075229</td>\n",
       "      <td>0.073488</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>0.076267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.058374</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.056166</td>\n",
       "      <td>0.055663</td>\n",
       "      <td>0.056118</td>\n",
       "      <td>0.057204</td>\n",
       "      <td>0.055929</td>\n",
       "      <td>0.055768</td>\n",
       "      <td>0.059735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dummy       RFR   bagging  GradBoost  GS_RF_MSE  GS_RF_MAE  \\\n",
       "score_train  0.000000  0.880999  0.809259   0.998480   0.565859   0.570668   \n",
       "score_test  -0.010230  0.090887 -0.028548  -0.385776   0.148285   0.145455   \n",
       "rmse         0.080172  0.076054  0.080895   0.093898   0.073614   0.073736   \n",
       "mae          0.060118  0.058374  0.062488   0.068800   0.056166   0.055663   \n",
       "\n",
       "             GS_RF_MSE2    rfr_op  GS_bagging  bagging_op  GS_boosting  \n",
       "score_train    0.387818  0.863646    0.558013    0.576620     0.495300  \n",
       "score_test     0.132343  0.110499    0.151202    0.139168     0.085775  \n",
       "rmse           0.074299  0.075229    0.073488    0.074007     0.076267  \n",
       "mae            0.056118  0.057204    0.055929    0.055768     0.059735  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07673753776862857"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = GradientBoostingRegressor(loss='ls', random_state=8)\n",
    "fit_model(model3, 'boosting_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradboost_op_coefs = model3.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GS_bagging</th>\n",
       "      <td>0.558013</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.073488</td>\n",
       "      <td>0.055929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS_RF_MSE</th>\n",
       "      <td>0.565859</td>\n",
       "      <td>0.148285</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.056166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS_RF_MAE</th>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.055663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging_op</th>\n",
       "      <td>0.576620</td>\n",
       "      <td>0.139168</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>0.055768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS_RF_MSE2</th>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.132343</td>\n",
       "      <td>0.074299</td>\n",
       "      <td>0.056118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfr_op</th>\n",
       "      <td>0.575200</td>\n",
       "      <td>0.128513</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.056970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFR</th>\n",
       "      <td>0.880999</td>\n",
       "      <td>0.090887</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>0.058374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS_boosting</th>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.085775</td>\n",
       "      <td>0.076267</td>\n",
       "      <td>0.059735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010230</td>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.060118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging</th>\n",
       "      <td>0.809259</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.062488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting_op</th>\n",
       "      <td>0.898064</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>0.082769</td>\n",
       "      <td>0.059563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradBoost</th>\n",
       "      <td>0.998480</td>\n",
       "      <td>-0.385776</td>\n",
       "      <td>0.093898</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             score_train  score_test      rmse       mae\n",
       "GS_bagging      0.558013    0.151202  0.073488  0.055929\n",
       "GS_RF_MSE       0.565859    0.148285  0.073614  0.056166\n",
       "GS_RF_MAE       0.570668    0.145455  0.073736  0.055663\n",
       "bagging_op      0.576620    0.139168  0.074007  0.055768\n",
       "GS_RF_MSE2      0.387818    0.132343  0.074299  0.056118\n",
       "rfr_op          0.575200    0.128513  0.074463  0.056970\n",
       "RFR             0.880999    0.090887  0.076054  0.058374\n",
       "GS_boosting     0.495300    0.085775  0.076267  0.059735\n",
       "dummy           0.000000   -0.010230  0.080172  0.060118\n",
       "bagging         0.809259   -0.028548  0.080895  0.062488\n",
       "boosting_op     0.898064   -0.076738  0.082769  0.059563\n",
       "GradBoost       0.998480   -0.385776  0.093898  0.068800"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_scores = pd.DataFrame(fit_results,index=['score_train', 'score_test', 'rmse', 'mae']).T.sort_values(by='score_test', ascending = False)\n",
    "models_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Imporances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefs = pd.DataFrame(data={'RFR':rf_coefs, 'RFR_op':rf_op_coefs, 'bagging':list(bagging_coefs), \"bagging_op\":list(bagging_op_coefs), 'gradboost':gradboost_coefs, 'gradboost_op':gradboost_op_coefs},index=X0.columns).round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RFR</th>\n",
       "      <th>RFR_op</th>\n",
       "      <th>bagging</th>\n",
       "      <th>bagging_op</th>\n",
       "      <th>gradboost</th>\n",
       "      <th>gradboost_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tip Fee as of 1/1/2020</th>\n",
       "      <td>0.194</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Households Served by Municipal Recycling Program</th>\n",
       "      <td>0.162</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYT/ SMART</th>\n",
       "      <td>0.188</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the transfer station access fee?</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the annual fee?</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recycling Collection Frequency_Weekly</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does trash disposal tonnage include bulky waste?</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Hours Enforcement Personnel on Street</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Municipal Buildings Trash and Recycling Service_Both</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applies to Residential Generators not Eligible to be Served by the Municipal Program</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-resident Trash and Recycling Service_Both</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximum # bags/ barrels per week</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School Trash and Recycling Service_Both</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recycle Bin Size Ranking</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Trash and Recycling Service_Both</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste program funded by property tax?</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fee for bulky waste?</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste program funded by transfer station access fee?</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recycling Enforced by Muni</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applies to Residential Generators Eligible to be Served by Municipal Program</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SS Recycling</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual Bulky Waste Limit</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recycling Enforced by Hauler</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Trash and Recycling Service_Recycling</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private Hauler regulations that require recycling</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recycling Collection Frequency_Bi-weekly</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recycling Service Type_Both</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the per-visit fee?</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dedicated Mandatory Recycling Enforcement Personnel</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carts for Recycling</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Applies to Commercial Generators</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trash Service Type_Both</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trash Service Type_Curbside</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recycling Service Type_Curbside</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carts for Trash</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trash Enforced by Hauler</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trash Enforced by Muni</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School Trash and Recycling Service_Recycling</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Municipal Buildings Trash and Recycling Service_Recycling</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dedicated Trash Enforcement Personnel</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-resident Trash and Recycling Service_Trash</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-resident Trash and Recycling Service_Recycling</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Municipal Buildings Trash and Recycling Service_Trash</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      RFR  RFR_op  bagging  \\\n",
       "Tip Fee as of 1/1/2020                              0.194   0.201    0.207   \n",
       "Households Served by Municipal Recycling Program    0.162   0.148    0.159   \n",
       "PAYT/ SMART                                         0.188   0.198    0.213   \n",
       "What is the transfer station access fee?            0.051   0.051    0.038   \n",
       "What is the annual fee?                             0.051   0.040    0.055   \n",
       "Recycling Collection Frequency_Weekly               0.014   0.016    0.005   \n",
       "Does trash disposal tonnage include bulky waste?    0.016   0.020    0.017   \n",
       "# Hours Enforcement Personnel on Street             0.013   0.011    0.013   \n",
       "Municipal Buildings Trash and Recycling Service...  0.022   0.015    0.028   \n",
       "Applies to Residential Generators not Eligible ...  0.015   0.016    0.009   \n",
       "Non-resident Trash and Recycling Service_Both       0.021   0.017    0.020   \n",
       "Maximum # bags/ barrels per week                    0.023   0.017    0.022   \n",
       "School Trash and Recycling Service_Both             0.010   0.011    0.005   \n",
       "Recycle Bin Size Ranking                            0.015   0.016    0.021   \n",
       "Business Trash and Recycling Service_Both           0.010   0.015    0.007   \n",
       "Solid Waste program funded by property tax?         0.008   0.014    0.008   \n",
       "Fee for bulky waste?                                0.012   0.013    0.010   \n",
       "Solid Waste program funded by transfer station ...  0.014   0.010    0.002   \n",
       "Recycling Enforced by Muni                          0.013   0.015    0.008   \n",
       "Applies to Residential Generators Eligible to b...  0.013   0.012    0.012   \n",
       "SS Recycling                                        0.010   0.011    0.007   \n",
       "Annual Bulky Waste Limit                            0.012   0.016    0.010   \n",
       "Recycling Enforced by Hauler                        0.021   0.013    0.052   \n",
       "Business Trash and Recycling Service_Recycling      0.010   0.013    0.005   \n",
       "Private Hauler regulations that require recycling   0.010   0.007    0.013   \n",
       "Recycling Collection Frequency_Bi-weekly            0.010   0.009    0.007   \n",
       "Recycling Service Type_Both                         0.005   0.008    0.004   \n",
       "What is the per-visit fee?                          0.004   0.006    0.001   \n",
       "Dedicated Mandatory Recycling Enforcement Perso...  0.010   0.010    0.003   \n",
       "Carts for Recycling                                 0.004   0.008    0.004   \n",
       "Applies to Commercial Generators                    0.005   0.007    0.001   \n",
       "Trash Service Type_Both                             0.008   0.008    0.007   \n",
       "Trash Service Type_Curbside                         0.005   0.005    0.010   \n",
       "Recycling Service Type_Curbside                     0.004   0.006    0.002   \n",
       "Carts for Trash                                     0.005   0.004    0.003   \n",
       "Trash Enforced by Hauler                            0.001   0.004    0.002   \n",
       "Trash Enforced by Muni                              0.003   0.002    0.004   \n",
       "School Trash and Recycling Service_Recycling        0.003   0.003    0.002   \n",
       "Municipal Buildings Trash and Recycling Service...  0.002   0.002    0.002   \n",
       "Dedicated Trash Enforcement Personnel               0.001   0.001    0.000   \n",
       "Non-resident Trash and Recycling Service_Trash      0.000   0.000    0.000   \n",
       "Non-resident Trash and Recycling Service_Recycling  0.001   0.000    0.000   \n",
       "Municipal Buildings Trash and Recycling Service...  0.000   0.000    0.000   \n",
       "\n",
       "                                                    bagging_op  gradboost  \\\n",
       "Tip Fee as of 1/1/2020                                   0.248      0.194   \n",
       "Households Served by Municipal Recycling Program         0.201      0.162   \n",
       "PAYT/ SMART                                              0.196      0.188   \n",
       "What is the transfer station access fee?                 0.069      0.051   \n",
       "What is the annual fee?                                  0.060      0.051   \n",
       "Recycling Collection Frequency_Weekly                    0.027      0.014   \n",
       "Does trash disposal tonnage include bulky waste?         0.027      0.016   \n",
       "# Hours Enforcement Personnel on Street                  0.027      0.013   \n",
       "Municipal Buildings Trash and Recycling Service...       0.026      0.022   \n",
       "Applies to Residential Generators not Eligible ...       0.025      0.015   \n",
       "Non-resident Trash and Recycling Service_Both            0.025      0.021   \n",
       "Maximum # bags/ barrels per week                         0.024      0.023   \n",
       "School Trash and Recycling Service_Both                  0.022      0.010   \n",
       "Recycle Bin Size Ranking                                 0.022      0.015   \n",
       "Business Trash and Recycling Service_Both                0.022      0.010   \n",
       "Solid Waste program funded by property tax?              0.021      0.008   \n",
       "Fee for bulky waste?                                     0.021      0.012   \n",
       "Solid Waste program funded by transfer station ...       0.020      0.014   \n",
       "Recycling Enforced by Muni                               0.020      0.013   \n",
       "Applies to Residential Generators Eligible to b...       0.020      0.013   \n",
       "SS Recycling                                             0.019      0.010   \n",
       "Annual Bulky Waste Limit                                 0.019      0.012   \n",
       "Recycling Enforced by Hauler                             0.017      0.021   \n",
       "Business Trash and Recycling Service_Recycling           0.017      0.010   \n",
       "Private Hauler regulations that require recycling        0.015      0.010   \n",
       "Recycling Collection Frequency_Bi-weekly                 0.014      0.010   \n",
       "Recycling Service Type_Both                              0.013      0.005   \n",
       "What is the per-visit fee?                               0.013      0.004   \n",
       "Dedicated Mandatory Recycling Enforcement Perso...       0.013      0.010   \n",
       "Carts for Recycling                                      0.012      0.004   \n",
       "Applies to Commercial Generators                         0.012      0.005   \n",
       "Trash Service Type_Both                                  0.011      0.008   \n",
       "Trash Service Type_Curbside                              0.010      0.005   \n",
       "Recycling Service Type_Curbside                          0.009      0.004   \n",
       "Carts for Trash                                          0.009      0.005   \n",
       "Trash Enforced by Hauler                                 0.006      0.001   \n",
       "Trash Enforced by Muni                                   0.006      0.003   \n",
       "School Trash and Recycling Service_Recycling             0.005      0.003   \n",
       "Municipal Buildings Trash and Recycling Service...       0.003      0.002   \n",
       "Dedicated Trash Enforcement Personnel                    0.002      0.001   \n",
       "Non-resident Trash and Recycling Service_Trash           0.000      0.000   \n",
       "Non-resident Trash and Recycling Service_Recycling       0.000      0.001   \n",
       "Municipal Buildings Trash and Recycling Service...       0.000      0.000   \n",
       "\n",
       "                                                    gradboost_op  \n",
       "Tip Fee as of 1/1/2020                                     0.172  \n",
       "Households Served by Municipal Recycling Program           0.192  \n",
       "PAYT/ SMART                                                0.212  \n",
       "What is the transfer station access fee?                   0.105  \n",
       "What is the annual fee?                                    0.021  \n",
       "Recycling Collection Frequency_Weekly                      0.025  \n",
       "Does trash disposal tonnage include bulky waste?           0.019  \n",
       "# Hours Enforcement Personnel on Street                    0.016  \n",
       "Municipal Buildings Trash and Recycling Service...         0.037  \n",
       "Applies to Residential Generators not Eligible ...         0.010  \n",
       "Non-resident Trash and Recycling Service_Both              0.014  \n",
       "Maximum # bags/ barrels per week                           0.030  \n",
       "School Trash and Recycling Service_Both                    0.007  \n",
       "Recycle Bin Size Ranking                                   0.005  \n",
       "Business Trash and Recycling Service_Both                  0.005  \n",
       "Solid Waste program funded by property tax?                0.003  \n",
       "Fee for bulky waste?                                       0.011  \n",
       "Solid Waste program funded by transfer station ...         0.000  \n",
       "Recycling Enforced by Muni                                 0.002  \n",
       "Applies to Residential Generators Eligible to b...         0.004  \n",
       "SS Recycling                                               0.005  \n",
       "Annual Bulky Waste Limit                                   0.012  \n",
       "Recycling Enforced by Hauler                               0.022  \n",
       "Business Trash and Recycling Service_Recycling             0.012  \n",
       "Private Hauler regulations that require recycling          0.002  \n",
       "Recycling Collection Frequency_Bi-weekly                   0.005  \n",
       "Recycling Service Type_Both                                0.004  \n",
       "What is the per-visit fee?                                 0.012  \n",
       "Dedicated Mandatory Recycling Enforcement Perso...         0.002  \n",
       "Carts for Recycling                                        0.011  \n",
       "Applies to Commercial Generators                           0.006  \n",
       "Trash Service Type_Both                                    0.002  \n",
       "Trash Service Type_Curbside                                0.000  \n",
       "Recycling Service Type_Curbside                            0.000  \n",
       "Carts for Trash                                            0.000  \n",
       "Trash Enforced by Hauler                                   0.012  \n",
       "Trash Enforced by Muni                                     0.002  \n",
       "School Trash and Recycling Service_Recycling               0.000  \n",
       "Municipal Buildings Trash and Recycling Service...         0.000  \n",
       "Dedicated Trash Enforcement Personnel                      0.000  \n",
       "Non-resident Trash and Recycling Service_Trash             0.000  \n",
       "Non-resident Trash and Recycling Service_Recycling         0.000  \n",
       "Municipal Buildings Trash and Recycling Service...         0.000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coefs = model_coefs.sort_values(by='bagging_op', ascending=False)\n",
    "model_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "Look at part3c.ipynb for attempting a baseline model with a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For saving files\n",
    "\n",
    "# model_coefs.to_csv('data/baseline_models_coefs.csv', index=True)\n",
    "# models_scores.to_csv('data/baseline_models_scores.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
